[["index.html", "Statistics for Linguists using R - Quantitative and qualitative approaches Chapter 1 Introduction", " Statistics for Linguists using R - Quantitative and qualitative approaches Jalal Al-Tamimi 2025-04-22 Chapter 1 Introduction This is still work in progress, with additional chapters being added. This book covers the basics of statistics and R programming for linguists. It is designed to be accessible to those with little or no prior experience in statistics or programming. The book is divided into two main parts: the first part covers the basics of statistics, including descriptive statistics, inferential statistics, and hypothesis testing; the second part covers the basics of R programming, including data manipulation, data visualization, and statistical modelling. The book applies these concepts to real-world examples from linguistics, including phonetics, syntax, and semantics. The book also includes exercises and solutions to help readers practice and reinforce their understanding of the material. The book then adds more advanced topics, including linear regression, logistic regression, cumulative logit link models and signal detection theory. It moves to mixed-effects regressions (linear, logisitc, cumulative, and additive). These topics are presented in a way that is accessible to those with little or no prior experience in statistics or programming. The book then moves to topics covered in qualitative research, including qualitative data analysis, coding, and thematic analysis. The book also includes examples of how to conduct qualitative research using R, including how to use R for text analysis and qualitative data visualization. Towards the end, an introduction to basics of machine learning is provided, including supervised and unsupervised learning, classification, and clustering. The book also includes examples of how to use R for machine learning, including how to use R for text classification and clustering. The structure is organised with each chapter being dedicated to a specific topic and can normally be covered in 1 or 2 sessions. It is hoped that this book allows students to specialise in the field of statistical analyses applied to linguistic data and to be able to use R for their own research. The book is designed to be a practical guide that can be used in the classroom or for self-study. It is hoped that this book will help students to develop the skills they need to conduct their own research and to understand the research of others. "],["2-Introduction_Tidyverse_Visualisation.html", "Chapter 2 Introduction to R, the Tidyverse - Visualisation ", " Chapter 2 Introduction to R, the Tidyverse - Visualisation "],["2.1-loading-packages.html", "2.1 Loading packages", " 2.1 Loading packages ###Use the code below to check if you have all required packages installed. If some are not installed already, the code below will install these. If you have all packages installed, then you could load them with the second code. requiredPackages = c(&#39;tidyverse&#39;, &#39;languageR&#39;, &#39;phonR&#39;, &#39;summarytools&#39;) for(p in requiredPackages){ if(!require(p,character.only = TRUE)) install.packages(p) library(p,character.only = TRUE) } ## Loading required package: tidyverse ## ── Attaching core tidyverse packages ────────────────────────────────────────────────────── tidyverse 2.0.0 ── ## ✔ dplyr 1.1.4 ✔ readr 2.1.5 ## ✔ forcats 1.0.0 ✔ stringr 1.5.1 ## ✔ ggplot2 3.5.1 ✔ tibble 3.2.1 ## ✔ lubridate 1.9.4 ✔ tidyr 1.3.1 ## ✔ purrr 1.0.2 ## ── Conflicts ──────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors ## Loading required package: languageR ## ## Loading required package: phonR ## ## Loading required package: summarytools ## ## ## Attaching package: &#39;summarytools&#39; ## ## ## The following object is masked from &#39;package:tibble&#39;: ## ## view "],["2.2-intro-r-markdown.html", "2.2 Intro R Markdown", " 2.2 Intro R Markdown 2.2.1 General This is an R Markdown Notebook. When you execute code within the notebook, the results appear beneath the code. Try executing this chunk by clicking the Run button within the chunk or by placing your cursor inside it and pressing Ctrl+Shift+Enter. plot(cars) Add a new chunk by clicking the Insert Chunk button on the toolbar or by pressing Ctrl+Alt+I. When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the Preview button or press Ctrl+Shift+K to preview the HTML file). The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike Knit, Preview does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed. 2.2.2 Knitting to other formats You can knit notebook into PDF or Word. Make sure to install the tinytex package using the following code: install.packages(\"tinytex\"). If you already use  with another distribution, then you do not need to install tinytex (though this works perfectly out of the bag). Then from the menu above (Knit), then choose Knit to PDF or Knit to Word. This is an excellent way to get your work fully written within RStudio: You will write a text (like this), have a specific structure and also have all your results in one place. This allows for transparency and replicability. "],["2.3-r-and-r-studio.html", "2.3 R and R Studio", " 2.3 R and R Studio 2.3.1 R R is the most influential statistical software that is widely used in data science. The R Project for Statistical Computing. R allows the user to take control of their analyses and being open about how the data were analysed, etc. R encourages transparency and reproducible research. ###Downloading base R If you are a windows user, download the latest version here R version 4.3.1. If you are a MacX user, download the latest version here R version 4.3.1. Other Linux versions available here. Using up-to-date versions of R is important as this allows you to use the latest developments of the software. You can have a look at what is new in this latest release here. ###Upgrading your current R installation You can download the latest version from above and update. Or you can use the package installr and upgrade to the latest available version. If the package is not installed, use this: install.packages(\"installr\") and then run with library(installr) then type installr in the console (what? what’s a console?). We’ll come to this later on! 2.3.2 R Studio R Studio is one of the mostly used free and open-source integrated development environment for R. It allows the user to have access to various information at the same time, e.g., the Source, the Console, the Environment and the Files, etc. When you open R studio, and if you have installed R appropriately, then R Studio will “talk” to R by sending it messages to execute commands. You can set up the layout to suit your needs. I always find the following layout best for my needs: The Source pane: the file where you write your code The Console where actual code is run The Environment pane, which shows you all variables/datasets, with the history of executed code, etc. The Files/Viewer pane, which shows you the files in the current folder, the plots, the installed packages, and help files, etc. If you click on Tools and Global options, then Pane Layout, you can change the order, and add/remove options from the two panes below. You will see that I use a specific formatting as this suits me best and also have a special colour-coding used (Theme Modern et Editor theme = Tomorrow Night Bright). Use the theme that works best for you!! 2.3.3 Other options? ###Text Editors I use Sublime Text to run Python, Praat and write in . I use R Markdown in R to publish my code and write notebooks. I am in the process of writing my first article with R Markdown for a fully reproducible research. There are many development environments that can be used to “talk” to R: TinnR, Visual Studio, etc… ###R GUIs GUIs (for Graphical User Interface) for R are available. I list below a few. However, after trying some, I found it much easier to get to code directly in R. I don’t remember all codes! I use these to my advantage, by saving my code into a script and using it later on in other scripts. Some of the GUIs are meant to make R like excel or SPSS, while others are more specialised. Here is a list of some of these GUIs… RCommander is the first GUI I used (and hated!). It is the one used in Discovering Statistics using R by Andy Field. There are compatibility issues between RCommander and RStudio… Install RCommander using install.packages(\"Rcmdr\"). Then using R base, run RCommander from using library(Rcmdr). rattle is more of use for data mining and advanced statistics (use library(rattle) then rattle() to run) Deducer. For basic and advanced statistics (run with library(Deducer) after installation) RKWard. For basic and advanced statistics. Not available on CRAN and should be downloaded and installed. Etc.. You can always start by using any of the above to familiarise yourself with the code, and then move to using R fully via code. My recommendation is to start coding first thing and search for help on how to write the specific code you are after. "],["2.4-am-i-ready-to-use-r-now.html", "2.4 Am I ready to use R now?", " 2.4 Am I ready to use R now? Well almost. There is one thing we need to consider: telling R where is our working directory. By default R saves this to your documents (or somewhere else). Here, this is generally OK, though when working on your own data, things get more complicated. There are two schools of thought here. 1. Create R scripts that run the analyses and saves the output(s) directly to your working directory. Does not save the .RData image at the end 2. Create a project: a self-contained folder, where all your scripts, figures, etc. will be automatically saved. Saves the .RData at the end I subscribe to the second, as some of the computations I run take ages to finish. 2.4.1 Setting working directory Click the menu Session -&gt; Set Workign Directory -&gt; Choose Directory or use setwd(\"path/to/directory\") (choose the location where you want to save the results) You can also use getwd() to know where is your current working directory. 2.4.2 Creating a project Look at the top-right hand where you can see Projects (none). You can create a new project in a new path or based on a specific folder. "],["2.5-how-to-use-packages.html", "2.5 How to use packages?", " 2.5 How to use packages? Base R comes with many packages already installed. Look at packages to see which ones are already installed. There are currently 18377 packages on Cran (repository for all packages). No one uses all packages so do not try to install all of them. Simply install what you need!! RMarkdown will let you know if you are running a specific code that lacks a package and asks you to download it. 2.5.1 Installation The best option is to use the menu above (under Tools) and click Install packages, or type in install.packages(“package.name”). Make sure to always have install dependencies ticked (using the first option). 2.5.2 Loading Use the following to load a package: library(package.name). Once the package is loaded, you can use any of its functions directly into your code. Sometimes you may need to specify to use a particular function from within a particular package, in this case use: package.name::function. We will most probably not use this today, but this is something you need to know about otherwise undesirable results may occur (or even errors!). 2.5.3 Finding packages and help Under the Files pane (right bottom), click on the menu Packages and you will have access to all installed packages. Click on a package and you can see the associated help files. You can also type the following to find help: ?package.name. ??function e.g., ?stats ## starting httpd help server ... done ??MASS Or try clicking on the function name to find details of what to specify: e.g., scroll on lmer (assuming lme4 is installed). Do a Ctrl/Cmd + left mouse click on a function to display options. lme4::lmer ## function (formula, data = NULL, REML = TRUE, control = lmerControl(), ## start = NULL, verbose = 0L, subset, weights, na.action, offset, ## contrasts = NULL, devFunOnly = FALSE) ## { ## mc &lt;- mcout &lt;- match.call() ## missCtrl &lt;- missing(control) ## if (!missCtrl &amp;&amp; !inherits(control, &quot;lmerControl&quot;)) { ## if (!is.list(control)) ## stop(&quot;&#39;control&#39; is not a list; use lmerControl()&quot;) ## warning(&quot;passing control as list is deprecated: please use lmerControl() instead&quot;, ## immediate. = TRUE) ## control &lt;- do.call(lmerControl, control) ## } ## mc$control &lt;- control ## mc[[1]] &lt;- quote(lme4::lFormula) ## lmod &lt;- eval(mc, parent.frame(1L)) ## mcout$formula &lt;- lmod$formula ## lmod$formula &lt;- NULL ## if (is.matrix(y &lt;- model.response(lmod$fr)) &amp;&amp; ncol(y) &gt; ## 1) { ## stop(&quot;can&#39;t handle matrix-valued responses: consider using refit()&quot;) ## } ## devfun &lt;- do.call(mkLmerDevfun, c(lmod, list(start = start, ## verbose = verbose, control = control))) ## if (devFunOnly) ## return(devfun) ## if (identical(control$optimizer, &quot;none&quot;)) ## stop(&quot;deprecated use of optimizer==&#39;none&#39;; use NULL instead&quot;) ## opt &lt;- if (length(control$optimizer) == 0) { ## s &lt;- getStart(start, environment(devfun)$pp) ## list(par = s, fval = devfun(s), conv = 1000, message = &quot;no optimization&quot;) ## } ## else { ## optimizeLmer(devfun, optimizer = control$optimizer, restart_edge = control$restart_edge, ## boundary.tol = control$boundary.tol, control = control$optCtrl, ## verbose = verbose, start = start, calc.derivs = control$calc.derivs, ## use.last.params = control$use.last.params) ## } ## cc &lt;- checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl = control$checkConv, ## lbound = environment(devfun)$lower) ## mkMerMod(environment(devfun), opt, lmod$reTrms, fr = lmod$fr, ## mc = mcout, lme4conv = cc) ## } ## &lt;bytecode: 0x0000014f28f17c08&gt; ## &lt;environment: namespace:lme4&gt; "],["2.6-lets-get-started-with-r.html", "2.6 Let’s get started with R", " 2.6 Let’s get started with R 2.6.1 R as a calculator 2.6.1.1 Simple calculations R can be used as a calculator. Try some of the following below: 1 + 2 ## [1] 3 1+2*3 ## [1] 7 Well wait a second! were you all expecting the result to be 7? how many expected the result to be 9? Check the following: (1+2)*3 ## [1] 9 1+(2*3) ## [1] 7 So parenthesis are important! Always use these to tell R (and any other software) the order of operations. This is the order (remember PEMDAS): Parentheses Exponents Multiplication and Division (from left to right) Addition and Subtraction (from left to right) 2.6.1.2 Functions There are many built-in functions in R to do some complicated mathematical calculations. 2.6.1.2.1 Basic functions Run some of the following. sqrt(3) ## [1] 1.732051 3^2 ## [1] 9 log(3) ## [1] 1.098612 exp(3) ## [1] 20.08554 2.6.1.2.2 Creating variables We can also create variables (aka temporary place holders). x &lt;- 2 y &lt;- 5 b &lt;- x*y x ## [1] 2 y ## [1] 5 b ## [1] 10 b+log(y)*x^2 ## [1] 16.43775 When you create a variable and assign to it a number (or characters), you can use it later on. 2.6.1.2.3 Sequences We can also create sequences of numbers seq(1, 10, 2) ## [1] 1 3 5 7 9 ?seq z &lt;- 1:10 And we can do the following.. Can you explain what we have done here? z2 &lt;- z+1 z*z2 ## [1] 2 6 12 20 30 42 56 72 90 110 Up to you… Write some more complex maths here just for fun! ## Add below 2.6.2 Objects 2.6.2.1 Basic objects Objects are related to variables (we created above), but can also be dataframes, and other things we create in R. All of these are stored in memory and are shown below (under environment). You can check the type of the “object” below in the list (look at “Type”) or by using class(). Let’s look at the variables we created so far.. We will create another one as well… class(b) ## [1] &quot;numeric&quot; class(x) ## [1] &quot;numeric&quot; class(y) ## [1] &quot;numeric&quot; class(z) ## [1] &quot;integer&quot; class(z2) ## [1] &quot;numeric&quot; a &lt;- &quot;test&quot; class(a) ## [1] &quot;character&quot; When we do calculations in R, we need to make sure we use numeric/integer variables only.. Try some of the below. Uncomment the following ##x + two and run the code. x+y ## [1] 7 two &lt;- &quot;2&quot; ##x + two Can you explain the error? We have tried to add a number to a (character) string which is clearly impossible. To do the maths, we need to change the class using any of the following commands: as.character, as.integer, as.numeric, as.factor, e.g.: two &lt;- as.numeric(two) x + two ## [1] 4 2.6.2.2 Other functions and objects 2.6.2.2.1 Some more calculations We can create a vector of objects to do various things on.. We use the function c() and do various things on: numbers &lt;- c(1,4,5,12,55,13,45,38,77,836,543) class(numbers) ## [1] &quot;numeric&quot; mean(numbers) ## [1] 148.0909 sd(numbers) ## [1] 276.6375 median(numbers) ## [1] 38 min(numbers) ## [1] 1 max(numbers) ## [1] 836 range(numbers) ## [1] 1 836 sum(numbers) ## [1] 1629 2.6.2.2.2 Referring to a specific position Sometimes we may want to refer to a specific position in the list of numbers we just created… Use the following: numbers[2] ## [1] 4 numbers[3:5] ## [1] 5 12 55 numbers[-4] ## [1] 1 4 5 55 13 45 38 77 836 543 numbers+numbers[6] ## [1] 14 17 18 25 68 26 58 51 90 849 556 Can you explain what we have done in the last operation? "],["2.7-matrices-and-dataframes.html", "2.7 Matrices and dataframes", " 2.7 Matrices and dataframes 2.7.1 Matrix 2.7.1.1 General x &lt;- 1:4 x &lt;- as.matrix(x) x ## [,1] ## [1,] 1 ## [2,] 2 ## [3,] 3 ## [4,] 4 dim(x) ## [1] 4 1 dim(x) &lt;- c(2,2) dim(x) ## [1] 2 2 x ## [,1] [,2] ## [1,] 1 3 ## [2,] 2 4 2.7.1.2 Referring to specific location x[1,] ## [1] 1 3 x[,1] ## [1] 1 2 x[1,2] ## [1] 3 x[,] ## = x ## [,1] [,2] ## [1,] 1 3 ## [2,] 2 4 2.7.2 Dataframes A dataframe is the most important object we will be using over and over again… It is an object that contains information in both rows and columns. 2.7.2.1 Creating a dataframe from scratch In this exercise, we will create a 4*9 dataframe. The code below creates four variables, and combines them together to make a dataframe. As you can see, variables can also be characters. To create the dataframe, we use the functions as.data.frame and cbind. word &lt;- c(&quot;a&quot;, &quot;the&quot;, &quot;lamp&quot;, &quot;not&quot;, &quot;jump&quot;, &quot;it&quot;, &quot;coffee&quot;, &quot;walk&quot;, &quot;on&quot;) freq &lt;- c(500, 600, 7, 200, 30, 450, 130, 33, 300) ## note this is completely made up!! functionword &lt;- c(&quot;y&quot;, &quot;y&quot;, &quot;n&quot;, &quot;y&quot;, &quot;n&quot;, &quot;y&quot;, &quot;n&quot;, &quot;n&quot;, &quot;y&quot;) length &lt;- c(1, 3, 4, 3, 4, 2, 6, 4, 2) df &lt;- as.data.frame(cbind(word,freq,functionword,length)) 2.7.2.2 Deleting variables from the Environment If you have created various variables you do not need any more, you can use rm to remove these rm(word,freq,functionword,length) BUT wait, did I remove these from my dataframe? Well no.. We have removed objects from within the R environment and not from the actual dataframe. Let’s check this up df ## word freq functionword length ## 1 a 500 y 1 ## 2 the 600 y 3 ## 3 lamp 7 n 4 ## 4 not 200 y 3 ## 5 jump 30 n 4 ## 6 it 450 y 2 ## 7 coffee 130 n 6 ## 8 walk 33 n 4 ## 9 on 300 y 2 2.7.2.3 Saving and reading the dataframe 2.7.2.4 Reading and Saving in .csv The code below allows you to save the dataframe and read it again. The extension .csv is for “comma delimited files”. This is the best format to use as it is simply a text file with no additional formatting. write.csv(df, paste0(&quot;outputs/df.csv&quot;)) dfNew &lt;- read.csv(paste0(&quot;outputs/df.csv&quot;)) df ## word freq functionword length ## 1 a 500 y 1 ## 2 the 600 y 3 ## 3 lamp 7 n 4 ## 4 not 200 y 3 ## 5 jump 30 n 4 ## 6 it 450 y 2 ## 7 coffee 130 n 6 ## 8 walk 33 n 4 ## 9 on 300 y 2 dfNew ## X word freq functionword length ## 1 1 a 500 y 1 ## 2 2 the 600 y 3 ## 3 3 lamp 7 n 4 ## 4 4 not 200 y 3 ## 5 5 jump 30 n 4 ## 6 6 it 450 y 2 ## 7 7 coffee 130 n 6 ## 8 8 walk 33 n 4 ## 9 9 on 300 y 2 The newly created object contains 5 columns rather than the 4 we initially created. This is normal. By default, R add a column that reflects the order of the list before it was saved. You can simply delete the column or keep as is (but be careful as this means you need to adjust any references to columns that we will use later on). 2.7.2.5 Reading and saving other formats R allows us to read data in any format. If you have a .txt, .sav, .xls, .xlsx, etc., then there are packages specific to do that (e.g., package xlsx to read/save .xlsx files, or the function haven from the package Tidyverse to read/save .sav files). You can use the built-in plugin in RStudio to import your dataset. See Import Dataset within the Environment. In general, any specific formatting is kept, but sometimes variable names associated with numbers (as in .sav files) will be lost. Hence, it is always preferable to do minimal formatting on the data.. Start with a .csv file, import it to R and do the magic! 2.7.2.6 Checking the structure The first thing we will do is to check the structure of our created dataset. We will use the originally created one (i.e., df and not the imported one (i.e., dfNew). str(df) ## &#39;data.frame&#39;: 9 obs. of 4 variables: ## $ word : chr &quot;a&quot; &quot;the&quot; &quot;lamp&quot; &quot;not&quot; ... ## $ freq : chr &quot;500&quot; &quot;600&quot; &quot;7&quot; &quot;200&quot; ... ## $ functionword: chr &quot;y&quot; &quot;y&quot; &quot;n&quot; &quot;y&quot; ... ## $ length : chr &quot;1&quot; &quot;3&quot; &quot;4&quot; &quot;3&quot; ... The function str gives us the following information: How many observations (i.e., rows) and variables (i.e., columns) The name of each variable (look at $ and what comes after it) Within each variable, we have the class with number of levels 2.7.2.7 Changing the class of a variable As we can see, the four created variables were added to the dataframe as factors. We need to change the class of the numeric variables: freq and length. Let’s do that: df$freq &lt;- as.numeric(df$freq) df$length &lt;- as.numeric(df$length) str(df) ## &#39;data.frame&#39;: 9 obs. of 4 variables: ## $ word : chr &quot;a&quot; &quot;the&quot; &quot;lamp&quot; &quot;not&quot; ... ## $ freq : num 500 600 7 200 30 450 130 33 300 ## $ functionword: chr &quot;y&quot; &quot;y&quot; &quot;n&quot; &quot;y&quot; ... ## $ length : num 1 3 4 3 4 2 6 4 2 2.7.2.8 Referring to particular variables, observations As you can see from the above, we can refer to a particular variable in the dataframe by its name and adding $. There are additional options to do that. Let’s see what we can do. Can you tell what each of the below does? chat to your neighbour…. df[1] ## word ## 1 a ## 2 the ## 3 lamp ## 4 not ## 5 jump ## 6 it ## 7 coffee ## 8 walk ## 9 on df[,1] ## [1] &quot;a&quot; &quot;the&quot; &quot;lamp&quot; &quot;not&quot; &quot;jump&quot; &quot;it&quot; &quot;coffee&quot; &quot;walk&quot; ## [9] &quot;on&quot; df[1,] ## word freq functionword length ## 1 a 500 y 1 df[1,1] ## [1] &quot;a&quot; Here are the answers: Refers to the full column 1 Refers to first variable Refers to first row Refers to first observation in first column Practice a bit and use other specifications to obtain specific observations, columns or rows… 2.7.3 Descriptive statistics 2.7.3.1 Basic summaries, tables We can use the function summary to do some basic summaries summary(df) ## word freq functionword length ## Length:9 Min. : 7 Length:9 Min. :1.000 ## Class :character 1st Qu.: 33 Class :character 1st Qu.:2.000 ## Mode :character Median :200 Mode :character Median :3.000 ## Mean :250 Mean :3.222 ## 3rd Qu.:450 3rd Qu.:4.000 ## Max. :600 Max. :6.000 We can create a table with the function table table(df$functionword, df$freq) ## ## 7 30 33 130 200 300 450 500 600 ## n 1 1 1 1 0 0 0 0 0 ## y 0 0 0 0 1 1 1 1 1 2.7.3.2 Basic manipulations 2.7.3.2.1 Creating variables We sometimes need to create and/or delete new variables.. Do you know how to do that? Let’s look at the structure again: str(df) ## &#39;data.frame&#39;: 9 obs. of 4 variables: ## $ word : chr &quot;a&quot; &quot;the&quot; &quot;lamp&quot; &quot;not&quot; ... ## $ freq : num 500 600 7 200 30 450 130 33 300 ## $ functionword: chr &quot;y&quot; &quot;y&quot; &quot;n&quot; &quot;y&quot; ... ## $ length : num 1 3 4 3 4 2 6 4 2 We said earlier that we can refer to a specific variable by using $ + the name of the variable. Let’s use this again and add a new name of variable not in the list of variables above df$newVariable ## NULL What does NULL mean? The variable does not exist! Let’s do something else df$newVariable &lt;- NA Ah no error messages! Let’s check the structure str(df) ## &#39;data.frame&#39;: 9 obs. of 5 variables: ## $ word : chr &quot;a&quot; &quot;the&quot; &quot;lamp&quot; &quot;not&quot; ... ## $ freq : num 500 600 7 200 30 450 130 33 300 ## $ functionword: chr &quot;y&quot; &quot;y&quot; &quot;n&quot; &quot;y&quot; ... ## $ length : num 1 3 4 3 4 2 6 4 2 ## $ newVariable : logi NA NA NA NA NA NA ... So we now have five variables and the last one is named “newVariable” and assigned “NA”. “NA” is used in R to refer to missing data or is a place holder. We can replace these with any calculations, or anything else. Let’s do that: df$newVariable &lt;- log(df$freq) str(df) ## &#39;data.frame&#39;: 9 obs. of 5 variables: ## $ word : chr &quot;a&quot; &quot;the&quot; &quot;lamp&quot; &quot;not&quot; ... ## $ freq : num 500 600 7 200 30 450 130 33 300 ## $ functionword: chr &quot;y&quot; &quot;y&quot; &quot;n&quot; &quot;y&quot; ... ## $ length : num 1 3 4 3 4 2 6 4 2 ## $ newVariable : num 6.21 6.4 1.95 5.3 3.4 ... We replaced “NA” with the log of the frequencies. Let’s check that this is correct only for one observation. Can you dissect the code below? what did I use to ask R to compute the log of the frequency (freq)? Remember rows and columns log(df[1,2]) ## [1] 6.214608 df[1,5] ## [1] 6.214608 So they are the same values. 2.7.3.2.2 Changing column names Now we need to change the name of the variable to reflect the computations. “newVariable” is meaningless as a name, but “logFreq” is informative. colnames(df)[5] &lt;- &quot;logFreq&quot; str(df) ## &#39;data.frame&#39;: 9 obs. of 5 variables: ## $ word : chr &quot;a&quot; &quot;the&quot; &quot;lamp&quot; &quot;not&quot; ... ## $ freq : num 500 600 7 200 30 450 130 33 300 ## $ functionword: chr &quot;y&quot; &quot;y&quot; &quot;n&quot; &quot;y&quot; ... ## $ length : num 1 3 4 3 4 2 6 4 2 ## $ logFreq : num 6.21 6.4 1.95 5.3 3.4 ... As can be seen from the above, using the command colnames(df)[5] &lt;- \"logFreq\" allows us to change the column name in position 5 of the dataframe. If we were to change all of the columns names, we could use colnames(df) &lt;- c(\"col1\",\"col2\",...)“. 2.7.3.2.3 Deleting variables Let us now create a new compound variable that we later delete. This new compound variable will the multiplication of two numeric variables. The result is meaningless of course, but will be used for this exercise. df$madeUpVariable &lt;- df$freq*df$length str(df) ## &#39;data.frame&#39;: 9 obs. of 6 variables: ## $ word : chr &quot;a&quot; &quot;the&quot; &quot;lamp&quot; &quot;not&quot; ... ## $ freq : num 500 600 7 200 30 450 130 33 300 ## $ functionword : chr &quot;y&quot; &quot;y&quot; &quot;n&quot; &quot;y&quot; ... ## $ length : num 1 3 4 3 4 2 6 4 2 ## $ logFreq : num 6.21 6.4 1.95 5.3 3.4 ... ## $ madeUpVariable: num 500 1800 28 600 120 900 780 132 600 Let us now delete this variable given that we are not interested in. Do you know how to do that? Think about how we referred to a variable before? We use df[colNumber]. What if we use df[-colNumebr], what would be the result? df[-6] ## word freq functionword length logFreq ## 1 a 500 y 1 6.214608 ## 2 the 600 y 3 6.396930 ## 3 lamp 7 n 4 1.945910 ## 4 not 200 y 3 5.298317 ## 5 jump 30 n 4 3.401197 ## 6 it 450 y 2 6.109248 ## 7 coffee 130 n 6 4.867534 ## 8 walk 33 n 4 3.496508 ## 9 on 300 y 2 5.703782 This shows all columns minus the one we are not interested in. If we rewrite the variable df and assign to it the newly created dataframe we just used above (with the minus sign), then the column we are not interested in will be deleted. df &lt;- df[-6] str(df) ## &#39;data.frame&#39;: 9 obs. of 5 variables: ## $ word : chr &quot;a&quot; &quot;the&quot; &quot;lamp&quot; &quot;not&quot; ... ## $ freq : num 500 600 7 200 30 450 130 33 300 ## $ functionword: chr &quot;y&quot; &quot;y&quot; &quot;n&quot; &quot;y&quot; ... ## $ length : num 1 3 4 3 4 2 6 4 2 ## $ logFreq : num 6.21 6.4 1.95 5.3 3.4 ... 2.7.3.2.4 Changing names of observations Let’s say that we want to change the names of our observations. For instance, the variable “functionword” has the levels “y” and “n”. Let us change the names to become “yes” and “no”. We first need to change the factor level variable into character and then change the observations. Then we need to transform back to a factor df$functionword &lt;- as.character(df$functionword) df$functionword[df$functionword == &quot;y&quot;] &lt;- &quot;yes&quot; df$functionword[df$functionword == &quot;n&quot;] &lt;- &quot;no&quot; df$functionword &lt;- as.factor(df$functionword) str(df) ## &#39;data.frame&#39;: 9 obs. of 5 variables: ## $ word : chr &quot;a&quot; &quot;the&quot; &quot;lamp&quot; &quot;not&quot; ... ## $ freq : num 500 600 7 200 30 450 130 33 300 ## $ functionword: Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 2 2 1 2 1 2 1 1 2 ## $ length : num 1 3 4 3 4 2 6 4 2 ## $ logFreq : num 6.21 6.4 1.95 5.3 3.4 ... 2.7.3.2.5 Checking levels of factors We can also check the levels of factor and change the reference value. This is useful when doing any type of statistics or when plotting the data. We use levels, relevel and ref levels(df$functionword) ## [1] &quot;no&quot; &quot;yes&quot; df$functionword &lt;-relevel(df$functionword, ref = &quot;yes&quot;) levels(df$functionword) ## [1] &quot;yes&quot; &quot;no&quot; We can also use the following code to change the order of the levels of a multilevel factor levels(df$word) ## NULL df$word &lt;- factor(df$word, levels = c(&quot;a&quot;,&quot;coffee&quot;,&quot;jump&quot;,&quot;lamp&quot;,&quot;not&quot;,&quot;it&quot;,&quot;on&quot;,&quot;walk&quot;,&quot;the&quot;)) levels(df$word) ## [1] &quot;a&quot; &quot;coffee&quot; &quot;jump&quot; &quot;lamp&quot; &quot;not&quot; &quot;it&quot; &quot;on&quot; &quot;walk&quot; ## [9] &quot;the&quot; 2.7.3.2.6 Subsetting the dataframe We may sometimes need to subset the dataframe and use parts of it. We use the function subset or which. df_Yes1 &lt;- df[which(df$functionword == &#39;yes&#39;),] ##or df_Yes2 &lt;- subset(df, functionword==&quot;yes&quot;) str(df_Yes1) ## &#39;data.frame&#39;: 5 obs. of 5 variables: ## $ word : Factor w/ 9 levels &quot;a&quot;,&quot;coffee&quot;,&quot;jump&quot;,..: 1 9 5 6 7 ## $ freq : num 500 600 200 450 300 ## $ functionword: Factor w/ 2 levels &quot;yes&quot;,&quot;no&quot;: 1 1 1 1 1 ## $ length : num 1 3 3 2 2 ## $ logFreq : num 6.21 6.4 5.3 6.11 5.7 str(df_Yes2) ## &#39;data.frame&#39;: 5 obs. of 5 variables: ## $ word : Factor w/ 9 levels &quot;a&quot;,&quot;coffee&quot;,&quot;jump&quot;,..: 1 9 5 6 7 ## $ freq : num 500 600 200 450 300 ## $ functionword: Factor w/ 2 levels &quot;yes&quot;,&quot;no&quot;: 1 1 1 1 1 ## $ length : num 1 3 3 2 2 ## $ logFreq : num 6.21 6.4 5.3 6.11 5.7 When we subset the data, the levels of a factor are kept as they are. levels(df_Yes1$functionword) ## [1] &quot;yes&quot; &quot;no&quot; levels(df_Yes2$functionword) ## [1] &quot;yes&quot; &quot;no&quot; But we only have one level of our factor.. df_Yes1$functionword ## [1] yes yes yes yes yes ## Levels: yes no df_Yes2$functionword ## [1] yes yes yes yes yes ## Levels: yes no By default, R keeps the levels of the factor as they are unless we change it by using the following: df_Yes1$functionword &lt;- factor(df_Yes1$functionword) df_Yes2$functionword &lt;- factor(df_Yes2$functionword) df_Yes1$functionword ## [1] yes yes yes yes yes ## Levels: yes df_Yes2$functionword ## [1] yes yes yes yes yes ## Levels: yes "],["2.8-the-tidyverse.html", "2.8 The Tidyverse", " 2.8 The Tidyverse 2.8.1 Introduction The Tidyverse is a family of packages used to speed up the use of R. You need to first install it (if you haven’t already done so) and then load it. To install, use Tools &gt; Install packages or install.packages() then add tidyverse. To load a package, use the library() function. Look at how many packages are installed within the Tidyverse. The messages you see are telling you which packages are loaded and which functions are in conflict (i.e., these are functions from other packages that are found within the Tidyverse). If you want to use the original function, simply add package_name::function. 2.8.2 Using piping The difference between base R and the Tidyverse’s way of doing things is that base R can sometimes be more complex, while tidyverse is more straightforward and allows you to “see” within a dataframe easily. You need to learn how to use the “pipe” in magrittr that is part of the Tidyverse. Pipes are written in R as %&gt;% (note you must use a percentage sign before and after the pipe). To demonstrate what pipes do, have a look at the following pseudo code. You can use a shortcut in your keyboard, type Ctrl+Shift+m to add a pipe (for mac users, it is Cmd+Shift+m). Since R version 4.1.0, there is a native pipe |&gt;. It seems to be doing almost the same thing as the %&gt;%. We will still use %&gt;% as this is integrated within the Tidyverse. 2.8.3 Demo subsetting Below are two code lines for how to subset the dataframe using base R and piping from the magrittr package. With base R, we always need to refer to the dataset twice: once at the beginning and then to look into the dataset to select a variable. df_Yes1 &lt;- df[which(df$functionword == &#39;yes&#39;),] df_Yes1 ## word freq functionword length logFreq ## 1 a 500 yes 1 6.214608 ## 2 the 600 yes 3 6.396930 ## 4 not 200 yes 3 5.298317 ## 6 it 450 yes 2 6.109248 ## 9 on 300 yes 2 5.703782 With the pipe, you only need to specify the dataset once: By adding the pipe, you can already look into the dataset and select the variable you need. df %&gt;% filter(functionword ==&#39;yes&#39;) ## word freq functionword length logFreq ## 1 a 500 yes 1 6.214608 ## 2 the 600 yes 3 6.396930 ## 3 not 200 yes 3 5.298317 ## 4 it 450 yes 2 6.109248 ## 5 on 300 yes 2 5.703782 And this is with the base R pipe (combined with code from the Tidyverse family) df |&gt; filter(functionword ==&#39;yes&#39;) ## word freq functionword length logFreq ## 1 a 500 yes 1 6.214608 ## 2 the 600 yes 3 6.396930 ## 3 not 200 yes 3 5.298317 ## 4 it 450 yes 2 6.109248 ## 5 on 300 yes 2 5.703782 As you can see, using the pipe (either within the Tidyverse or with base R) is a quick and easy way to do various operations. Out of convenience and because we will use other packages integrated within the Tidyverse, we will use its pipe. ReCap: %&gt;% is called a “pipe” It passes the previous line into the data argument of the next line It does not save any changes after output If you want to save the output of a particular manipulation, simply save it with xx &lt;- 2.8.4 Basic manipulations We will use the pipe with the Tidyverse to obtain summaries. We will use an R built-in dataset. Type data() to see the full list of datasets installed by default in R. You can use data(package = .packages(all.available = TRUE)) to see all datasets installed within all packages. 2.8.4.1 First steps Here is a list of all available datasets data() data(package = .packages(all.available = TRUE)) 2.8.4.2 Loading dataset We will use the dataset english from the package languageR. This is a package that contains many linguistically-oriented datasets. See details of the dataset here. Or by typing ?languageR::english (or simply ?english if the package is already loaded) in the console. You can load the dataset after loading the package. Simply refer to it by its name. ?english 2.8.4.3 View To see the dataset, run the code below to visualise it. english %&gt;% View() 2.8.4.4 Structure We can use str() to look at the structure of the dataset. Here we have a relatively large dataset with 4568 observations (=rows) and 36 variables (=columns). english %&gt;% str() ## &#39;data.frame&#39;: 4568 obs. of 36 variables: ## $ RTlexdec : num 6.54 6.4 6.3 6.42 6.45 ... ## $ RTnaming : num 6.15 6.25 6.14 6.13 6.2 ... ## $ Familiarity : num 2.37 4.43 5.6 3.87 3.93 3.27 3.73 5.67 3.1 4.43 ... ## $ Word : Factor w/ 2197 levels &quot;ace&quot;,&quot;act&quot;,&quot;add&quot;,..: 467 2124 1838 1321 1302 1347 434 468 15 1632 ... ## $ AgeSubject : Factor w/ 2 levels &quot;old&quot;,&quot;young&quot;: 2 2 2 2 2 2 2 2 2 2 ... ## $ WordCategory : Factor w/ 2 levels &quot;N&quot;,&quot;V&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ WrittenFrequency : num 3.91 4.52 6.51 5.02 4.89 ... ## $ WrittenSpokenFrequencyRatio : num 1.022 0.35 2.089 -0.526 -1.045 ... ## $ FamilySize : num 1.39 1.39 1.61 1.95 2.2 ... ## $ DerivationalEntropy : num 0.141 0.427 0.062 0.43 0.359 ... ## $ InflectionalEntropy : num 0.0211 0.942 1.4434 0 1.7539 ... ## $ NumberSimplexSynsets : num 0.693 1.099 2.485 1.099 2.485 ... ## $ NumberComplexSynsets : num 0 0 1.95 2.64 2.48 ... ## $ LengthInLetters : int 3 5 6 4 4 4 4 3 3 5 ... ## $ Ncount : int 8 5 0 8 3 9 6 13 3 3 ... ## $ MeanBigramFrequency : num 7.04 9.54 9.88 8.31 7.94 ... ## $ FrequencyInitialDiphone : num 12 12.6 13.3 12.1 11.9 ... ## $ ConspelV : int 10 20 10 5 17 19 10 13 1 7 ... ## $ ConspelN : num 3.74 7.87 6.69 6.68 4.76 ... ## $ ConphonV : int 41 38 13 6 17 21 13 7 11 14 ... ## $ ConphonN : num 8.84 9.78 7.04 3.83 4.76 ... ## $ ConfriendsV : int 8 20 10 4 17 19 10 6 0 7 ... ## $ ConfriendsN : num 3.3 7.87 6.69 3.53 4.76 ... ## $ ConffV : num 0.693 0 0 0.693 0 ... ## $ ConffN : num 2.71 0 0 6.63 0 ... ## $ ConfbV : num 3.5 2.94 1.39 1.1 0 ... ## $ ConfbN : num 8.83 9.61 5.82 2.56 0 ... ## $ NounFrequency : int 49 142 565 150 170 125 582 2061 144 522 ... ## $ VerbFrequency : int 0 0 473 0 120 280 110 76 4 86 ... ## $ CV : Factor w/ 2 levels &quot;C&quot;,&quot;V&quot;: 1 1 1 1 1 1 1 1 2 1 ... ## $ Obstruent : Factor w/ 2 levels &quot;cont&quot;,&quot;obst&quot;: 2 2 2 2 2 2 2 2 1 2 ... ## $ Frication : Factor w/ 4 levels &quot;burst&quot;,&quot;frication&quot;,..: 1 2 2 1 1 1 1 1 3 2 ... ## $ Voice : Factor w/ 2 levels &quot;voiced&quot;,&quot;voiceless&quot;: 1 2 2 2 2 2 1 1 1 2 ... ## $ FrequencyInitialDiphoneWord : num 10.13 9.05 12.42 10.05 11.8 ... ## $ FrequencyInitialDiphoneSyllable: num 10.41 9.15 13.13 11 12.16 ... ## $ CorrectLexdec : int 27 30 30 30 26 28 30 28 25 29 ... 2.8.4.5 See first 6 rows english %&gt;% head() ## RTlexdec RTnaming Familiarity Word AgeSubject WordCategory WrittenFrequency ## 1 6.543754 6.145044 2.37 doe young N 3.912023 ## 2 6.397596 6.246882 4.43 whore young N 4.521789 ## 3 6.304942 6.143756 5.60 stress young N 6.505784 ## 4 6.424221 6.131878 3.87 pork young N 5.017280 ## 5 6.450597 6.198479 3.93 plug young N 4.890349 ## 6 6.531970 6.167726 3.27 prop young N 4.770685 ## WrittenSpokenFrequencyRatio FamilySize DerivationalEntropy ## 1 1.0216512 1.386294 0.14144 ## 2 0.3504830 1.386294 0.42706 ## 3 2.0893560 1.609438 0.06197 ## 4 -0.5263339 1.945910 0.43035 ## 5 -1.0445451 2.197225 0.35920 ## 6 0.9248014 1.386294 0.06268 ## InflectionalEntropy NumberSimplexSynsets NumberComplexSynsets LengthInLetters ## 1 0.02114 0.6931472 0.000000 3 ## 2 0.94198 1.0986123 0.000000 5 ## 3 1.44339 2.4849066 1.945910 6 ## 4 0.00000 1.0986123 2.639057 4 ## 5 1.75393 2.4849066 2.484907 4 ## 6 1.74730 1.6094379 1.386294 4 ## Ncount MeanBigramFrequency FrequencyInitialDiphone ConspelV ConspelN ConphonV ## 1 8 7.036333 12.02268 10 3.737670 41 ## 2 5 9.537878 12.59780 20 7.870930 38 ## 3 0 9.883931 13.30069 10 6.693324 13 ## 4 8 8.309180 12.07807 5 6.677083 6 ## 5 3 7.943717 11.92678 17 4.762174 17 ## 6 9 8.349620 12.19724 19 6.234411 21 ## ConphonN ConfriendsV ConfriendsN ConffV ConffN ConfbV ConfbN ## 1 8.837826 8 3.295837 0.6931472 2.708050 3.496508 8.833900 ## 2 9.775825 20 7.870930 0.0000000 0.000000 2.944439 9.614738 ## 3 7.040536 10 6.693324 0.0000000 0.000000 1.386294 5.817111 ## 4 3.828641 4 3.526361 0.6931472 6.634633 1.098612 2.564949 ## 5 4.762174 17 4.762174 0.0000000 0.000000 0.000000 0.000000 ## 6 6.249975 19 6.234411 0.0000000 0.000000 1.098612 2.197225 ## NounFrequency VerbFrequency CV Obstruent Frication Voice ## 1 49 0 C obst burst voiced ## 2 142 0 C obst frication voiceless ## 3 565 473 C obst frication voiceless ## 4 150 0 C obst burst voiceless ## 5 170 120 C obst burst voiceless ## 6 125 280 C obst burst voiceless ## FrequencyInitialDiphoneWord FrequencyInitialDiphoneSyllable CorrectLexdec ## 1 10.129308 10.409763 27 ## 2 9.054388 9.148252 30 ## 3 12.422026 13.127395 30 ## 4 10.048151 11.003649 30 ## 5 11.796336 12.163092 26 ## 6 11.991567 12.436772 28 2.8.4.6 See last 6 rows english %&gt;% tail() ## RTlexdec RTnaming Familiarity Word AgeSubject WordCategory ## 4563 6.608770 6.503839 3.70 spy old V ## 4564 6.753998 6.446513 2.40 jag old V ## 4565 6.711022 6.506979 3.17 hash old V ## 4566 6.592332 6.386879 3.87 dash old V ## 4567 6.565561 6.519884 4.97 flirt old V ## 4568 6.667300 6.496624 3.03 hawk old V ## WrittenFrequency WrittenSpokenFrequencyRatio FamilySize ## 4563 5.023881 0.9703580 1.609438 ## 4564 2.079442 -1.6863990 1.386294 ## 4565 3.663562 0.4367177 1.609438 ## 4566 5.043425 0.5043947 1.945910 ## 4567 3.135494 0.0628009 1.945910 ## 4568 4.276666 1.0498221 1.945910 ## DerivationalEntropy InflectionalEntropy NumberSimplexSynsets ## 4563 0.08753 1.64317 1.609438 ## 4564 0.30954 1.85123 1.098612 ## 4565 0.15110 0.77890 1.386294 ## 4566 0.63316 1.65739 2.564949 ## 4567 0.99953 1.75885 1.609438 ## 4568 0.95422 1.81367 1.945910 ## NumberComplexSynsets LengthInLetters Ncount MeanBigramFrequency ## 4563 0.6931472 3 5 6.838235 ## 4564 0.0000000 3 18 6.229554 ## 4565 1.7917595 4 11 8.825582 ## 4566 1.6094379 4 10 8.356139 ## 4567 0.6931472 5 1 8.751224 ## 4568 3.0910425 4 4 7.426055 ## FrequencyInitialDiphone ConspelV ConspelN ConphonV ConphonN ConfriendsV ## 4563 11.50982 18 8.917981 42 9.516132 17 ## 4564 8.49433 20 4.744932 20 4.744932 19 ## 4565 13.49254 25 5.141664 23 4.890349 21 ## 4566 11.32815 25 5.141664 23 4.890349 21 ## 4567 10.59918 7 4.624973 14 5.164786 7 ## 4568 13.49254 3 2.772589 11 5.609472 3 ## ConfriendsN ConffV ConffN ConfbV ConfbN NounFrequency ## 4563 8.916774 0.000000 0.000000 3.218876 8.7181729 219 ## 4564 4.736198 0.000000 0.000000 0.000000 0.0000000 10 ## 4565 4.882802 1.609438 3.688879 1.098612 0.6931472 38 ## 4566 4.882802 1.609438 3.688879 1.098612 0.6931472 113 ## 4567 4.624973 0.000000 0.000000 2.079442 4.3040651 10 ## 4568 2.772589 0.000000 0.000000 2.197225 5.5529596 109 ## VerbFrequency CV Obstruent Frication Voice FrequencyInitialDiphoneWord ## 4563 88 C obst frication voiceless 12.030051 ## 4564 7 C obst frication voiced 8.311644 ## 4565 7 C obst frication voiceless 12.567203 ## 4566 231 C obst burst voiced 8.920923 ## 4567 66 C obst frication voiceless 10.425639 ## 4568 47 C obst frication voiceless 9.054388 ## FrequencyInitialDiphoneSyllable CorrectLexdec ## 4563 12.492844 30 ## 4564 8.390041 29 ## 4565 12.665546 29 ## 4566 9.287764 29 ## 4567 10.932142 29 ## 4568 9.148252 30 2.8.4.7 Selecting variables Here, we select a few variables to use. For variables or columns, use the function select english %&gt;% select(RTlexdec, RTnaming, Familiarity) %&gt;% head(10) ## RTlexdec RTnaming Familiarity ## 1 6.543754 6.145044 2.37 ## 2 6.397596 6.246882 4.43 ## 3 6.304942 6.143756 5.60 ## 4 6.424221 6.131878 3.87 ## 5 6.450597 6.198479 3.93 ## 6 6.531970 6.167726 3.27 ## 7 6.370586 6.123808 3.73 ## 8 6.266859 6.096050 5.67 ## 9 6.608648 6.117657 3.10 ## 10 6.284843 6.179188 4.43 2.8.4.8 Selecting observations If we want to select observations, we use the function filter. We will use select to select particular variables and then use filter to select specific observations. This example shows how the pipe chain works, by combining multiple functions and using pipes english %&gt;% select(RTlexdec, RTnaming, Familiarity, AgeSubject) %&gt;% filter(AgeSubject == &quot;old&quot;) %&gt;% head(10) ## RTlexdec RTnaming Familiarity AgeSubject ## 1453 6.664894 6.422597 2.37 old ## 1454 6.677209 6.636603 4.43 old ## 1455 6.538617 6.487075 5.60 old ## 1456 6.546943 6.404402 3.87 old ## 1457 6.637428 6.423409 3.93 old ## 1458 6.757444 6.529273 3.27 old ## 1459 6.598073 6.471728 3.73 old ## 1460 6.572464 6.424058 5.67 old ## 1461 6.817349 6.470645 3.10 old ## 1462 6.662877 6.549937 4.43 old 2.8.4.9 Changing order of levels Use some of the code above to manipulate the dataframe but now using code from the Tidyverse. As you will see, once you know how to manipulate a dataset with base R, you can easily apply the same techniques with the Tidyverse. The Tidyverse provides additional ways to manipulate a dataframe. For example, if I want to check levels of a variable and change the reference level, I will use the following code levels(english$AgeSubject) ## [1] &quot;old&quot; &quot;young&quot; To change levels of AgeSubject, we need to save a new dataset (do not override the original dataset!!). The mutate function means we are manipulating an object. english2&lt;- english %&gt;% mutate(AgeSubject = factor(AgeSubject, levels = c(&quot;young&quot;, &quot;old&quot;))) levels(english2$AgeSubject) ## [1] &quot;young&quot; &quot;old&quot; 2.8.4.10 Changing reference value You can change the reference value by using fct_relevel. This is useful if you have many levels in one of the factors you are working with and you simply need to change the reference. english2&lt;- english %&gt;% mutate(AgeSubject = fct_relevel(AgeSubject, &quot;old&quot;)) levels(english2$AgeSubject) ## [1] &quot;old&quot; &quot;young&quot; 2.8.5 String manipulation We use the str_func variants from the stringr package within the Tidyverse. topics &lt;- c(&quot;Phonetics&quot;, &quot;Phonology&quot;, &quot;Morphology&quot;, &quot;Syntax&quot;, &quot;Semantics&quot;, &quot;Pragmatics&quot;, &quot;Psycholinguistics&quot;) 2.8.5.1 str_sub Extracting substrings (2nd to 4th) str_sub(topics, 2, 4) ## [1] &quot;hon&quot; &quot;hon&quot; &quot;orp&quot; &quot;ynt&quot; &quot;ema&quot; &quot;rag&quot; &quot;syc&quot; 2.8.5.2 str_detect Detecting a particular pattern str_detect(topics, &quot;p&quot;) ## [1] FALSE FALSE TRUE FALSE FALSE FALSE FALSE str_detect(topics, &quot;n&quot;) ## [1] TRUE TRUE FALSE TRUE TRUE FALSE TRUE str_detect(topics, &quot;pho&quot;) ## [1] FALSE FALSE TRUE FALSE FALSE FALSE FALSE str_detect(topics, &quot;ling&quot;) ## [1] FALSE FALSE FALSE FALSE FALSE FALSE TRUE 2.8.5.3 str_locate Locate specific characters str_locate(topics, &quot;n&quot;) ## start end ## [1,] 4 4 ## [2,] 4 4 ## [3,] NA NA ## [4,] 3 3 ## [5,] 5 5 ## [6,] NA NA ## [7,] 9 9 2.8.5.4 str_locate_all Locate all instances of characters str_locate_all(topics, &quot;n&quot;) ## [[1]] ## start end ## [1,] 4 4 ## ## [[2]] ## start end ## [1,] 4 4 ## ## [[3]] ## start end ## ## [[4]] ## start end ## [1,] 3 3 ## ## [[5]] ## start end ## [1,] 5 5 ## ## [[6]] ## start end ## ## [[7]] ## start end ## [1,] 9 9 2.8.5.5 str_replace replaces a single instance str_replace(topics, &quot;o&quot;, &quot;O&quot;) ## [1] &quot;PhOnetics&quot; &quot;PhOnology&quot; &quot;MOrphology&quot; ## [4] &quot;Syntax&quot; &quot;Semantics&quot; &quot;Pragmatics&quot; ## [7] &quot;PsychOlinguistics&quot; 2.8.5.6 str_replace_all replaces all instances str_replace_all(topics, &quot;o&quot;, &quot;O&quot;) ## [1] &quot;PhOnetics&quot; &quot;PhOnOlOgy&quot; &quot;MOrphOlOgy&quot; ## [4] &quot;Syntax&quot; &quot;Semantics&quot; &quot;Pragmatics&quot; ## [7] &quot;PsychOlinguistics&quot; 2.8.6 Regular expressions Regular expressions are wildcards that can be used to search for particular patterns. We can use them to identify all words that begin with a “p” or end with a “y” or “cs”? Or any other changes? You can already consult this cheat sheet Also, here 2.8.6.1 Initial and final ^ used to identify initial position $ used to identify final position str_detect(topics, &quot;^[Pp]&quot;) ## [1] TRUE TRUE FALSE FALSE FALSE TRUE TRUE str_detect(topics, &quot;[y]$&quot;) ## [1] FALSE TRUE TRUE FALSE FALSE FALSE FALSE str_detect(topics, &quot;[cs]$&quot;) ## [1] TRUE FALSE FALSE FALSE TRUE TRUE TRUE 2.8.6.2 Other characters The . is used as a place holder asking for any character in the sequence str_detect(topics, &quot;Ph.n&quot;) ## [1] TRUE TRUE FALSE FALSE FALSE FALSE FALSE [a-z] will detect all characters between “a” and “z” str_detect(topics, &quot;[a-z]&quot;) ## [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE [M-P] will detect all characters between “M” and “P” str_detect(topics, &quot;[M-P]&quot;) ## [1] TRUE TRUE TRUE FALSE FALSE TRUE TRUE [:lower:] will detect all characters in lower case str_detect(topics, &quot;[:lower:]&quot;) ## [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE str_detect(topics, &quot;[:upper:]&quot;) ## [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE We can also use “[0-9]”, “[:digit:]”, “[:alpha:]”, “[:alnum:]”, “[:punct:]”, “[:graph:]”, “[:blank:]”, “[:space:]”, “[:print:]”, etc.. See PDF of cheat sheet! 2.8.7 Advanced manipulations Sometimes, you may have a dataset that comes in a wide format (i.e., columns contain data from participants) and you want to change to long format (i.e., each row contains one observation with minimal number of columns). Let’s look at the functions pivot_longer and pivot_wider 2.8.7.1 Columns to rows Let’s use the english dataset to transform it from wide to long and see the first 10 rows. english %&gt;% select(Word, RTlexdec, RTnaming, Familiarity) %&gt;% pivot_longer(cols = c(RTlexdec, RTnaming, Familiarity), ## you can also add index, i.e., 2:4 names_to = &quot;variable&quot;, values_to = &quot;values&quot;) %&gt;% head(10) ## # A tibble: 10 × 3 ## Word variable values ## &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 doe RTlexdec 6.54 ## 2 doe RTnaming 6.15 ## 3 doe Familiarity 2.37 ## 4 whore RTlexdec 6.40 ## 5 whore RTnaming 6.25 ## 6 whore Familiarity 4.43 ## 7 stress RTlexdec 6.30 ## 8 stress RTnaming 6.14 ## 9 stress Familiarity 5.6 ## 10 pork RTlexdec 6.42 2.8.7.2 Rows to columns Let’s use the same code above and change the code from long format, back to wide format. Pivot_wider allows you to go back to the original dataset. You will need to use unnest to get all rows in the correct place. Try without it to see the result. english %&gt;% select(Word, RTlexdec, RTnaming, Familiarity) %&gt;% pivot_longer(cols = c(RTlexdec, RTnaming, Familiarity), ## you can also add index, i.e., 2:4 names_to = &quot;variable&quot;, values_to = &quot;values&quot;) %&gt;% pivot_wider(names_from = &quot;variable&quot;, values_from = &quot;values&quot;) %&gt;% head(10) ## Warning: Values from `values` are not uniquely identified; output will contain list-cols. ## • Use `values_fn = list` to suppress this warning. ## • Use `values_fn = {summary_fun}` to summarise duplicates. ## • Use the following dplyr code to identify duplicates. ## {data} |&gt; ## dplyr::summarise(n = dplyr::n(), .by = c(Word, variable)) |&gt; ## dplyr::filter(n &gt; 1L) ## # A tibble: 10 × 4 ## Word RTlexdec RTnaming Familiarity ## &lt;fct&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; ## 1 doe &lt;dbl [2]&gt; &lt;dbl [2]&gt; &lt;dbl [2]&gt; ## 2 whore &lt;dbl [2]&gt; &lt;dbl [2]&gt; &lt;dbl [2]&gt; ## 3 stress &lt;dbl [2]&gt; &lt;dbl [2]&gt; &lt;dbl [2]&gt; ## 4 pork &lt;dbl [2]&gt; &lt;dbl [2]&gt; &lt;dbl [2]&gt; ## 5 plug &lt;dbl [2]&gt; &lt;dbl [2]&gt; &lt;dbl [2]&gt; ## 6 prop &lt;dbl [2]&gt; &lt;dbl [2]&gt; &lt;dbl [2]&gt; ## 7 dawn &lt;dbl [2]&gt; &lt;dbl [2]&gt; &lt;dbl [2]&gt; ## 8 dog &lt;dbl [2]&gt; &lt;dbl [2]&gt; &lt;dbl [2]&gt; ## 9 arc &lt;dbl [2]&gt; &lt;dbl [2]&gt; &lt;dbl [2]&gt; ## 10 skirt &lt;dbl [2]&gt; &lt;dbl [2]&gt; &lt;dbl [2]&gt; But wait, where are the results? They are added in lists. We need to use the function unnest() to obtain the full results. english %&gt;% select(Word, RTlexdec, RTnaming, Familiarity) %&gt;% pivot_longer(cols = c(RTlexdec, RTnaming, Familiarity), ## you can also add index, i.e., 2:4 names_to = &quot;variable&quot;, values_to = &quot;values&quot;) %&gt;% pivot_wider(names_from = &quot;variable&quot;, values_from = &quot;values&quot;) %&gt;% unnest() %&gt;% head(10) ## Warning: Values from `values` are not uniquely identified; output will contain list-cols. ## • Use `values_fn = list` to suppress this warning. ## • Use `values_fn = {summary_fun}` to summarise duplicates. ## • Use the following dplyr code to identify duplicates. ## {data} |&gt; ## dplyr::summarise(n = dplyr::n(), .by = c(Word, variable)) |&gt; ## dplyr::filter(n &gt; 1L) ## Warning: `cols` is now required when using `unnest()`. ## ℹ Please use `cols = c(RTlexdec, RTnaming, Familiarity)`. ## # A tibble: 10 × 4 ## Word RTlexdec RTnaming Familiarity ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 doe 6.54 6.15 2.37 ## 2 doe 6.66 6.42 2.37 ## 3 whore 6.40 6.25 4.43 ## 4 whore 6.68 6.64 4.43 ## 5 stress 6.30 6.14 5.6 ## 6 stress 6.54 6.49 5.6 ## 7 pork 6.42 6.13 3.87 ## 8 pork 6.55 6.40 3.87 ## 9 plug 6.45 6.20 3.93 ## 10 plug 6.64 6.42 3.93 Ah that is better. But we get warnings. What does the warnings tell us? These are simple warnings and not errors. You can use the suggestions the Tidyverse makes. By default, we are told that the results are shown as lists of columns (what we are after). The second warning tells you to use a specific specification with unnest(). 2.8.8 Basic descriptive statistics 2.8.8.1 Basic summaries We can use summary() to obtain basic summaries of the dataset. For numeric variables, this will give you the minimum, maximum, mean, median, 1st and 3rd quartiles; for factors/characters, this will be the count. If there are missing values, you will get number of NAs. Look at the summaries of the dataset below. english %&gt;% summary() ## RTlexdec RTnaming Familiarity Word AgeSubject ## Min. :6.205 Min. :6.022 Min. :1.100 arm : 4 old :2284 ## 1st Qu.:6.426 1st Qu.:6.149 1st Qu.:3.000 barge : 4 young:2284 ## Median :6.550 Median :6.342 Median :3.700 bark : 4 ## Mean :6.550 Mean :6.323 Mean :3.796 bear : 4 ## 3rd Qu.:6.653 3rd Qu.:6.490 3rd Qu.:4.570 beef : 4 ## Max. :7.188 Max. :6.696 Max. :6.970 bind : 4 ## (Other):4544 ## WordCategory WrittenFrequency WrittenSpokenFrequencyRatio FamilySize ## N:2904 Min. : 0.000 Min. :-6.55393 Min. :0.6931 ## V:1664 1st Qu.: 3.761 1st Qu.:-0.07402 1st Qu.:1.0986 ## Median : 4.832 Median : 0.68118 Median :1.7918 ## Mean : 5.021 Mean : 0.67763 Mean :1.8213 ## 3rd Qu.: 6.247 3rd Qu.: 1.44146 3rd Qu.:2.3026 ## Max. :11.357 Max. : 5.63071 Max. :5.5175 ## ## DerivationalEntropy InflectionalEntropy NumberSimplexSynsets ## Min. :0.00000 Min. :0.0000 Min. :0.000 ## 1st Qu.:0.03932 1st Qu.:0.7442 1st Qu.:1.099 ## Median :0.41097 Median :1.0982 Median :1.609 ## Mean :0.54089 Mean :1.1186 Mean :1.708 ## 3rd Qu.:0.89323 3rd Qu.:1.6325 3rd Qu.:2.197 ## Max. :5.20728 Max. :2.4514 Max. :4.357 ## ## NumberComplexSynsets LengthInLetters Ncount MeanBigramFrequency ## Min. :0.000 Min. :2.000 Min. : 0.000 Min. : 5.390 ## 1st Qu.:0.000 1st Qu.:4.000 1st Qu.: 2.000 1st Qu.: 8.100 ## Median :1.386 Median :4.000 Median : 5.000 Median : 8.559 ## Mean :1.568 Mean :4.342 Mean : 6.266 Mean : 8.490 ## 3rd Qu.:2.565 3rd Qu.:5.000 3rd Qu.: 9.000 3rd Qu.: 8.973 ## Max. :6.111 Max. :7.000 Max. :22.000 Max. :10.283 ## ## FrequencyInitialDiphone ConspelV ConspelN ConphonV ## Min. : 4.143 Min. : 0.00 Min. : 0.000 Min. : 0.00 ## 1st Qu.:11.277 1st Qu.: 6.00 1st Qu.: 4.519 1st Qu.:10.00 ## Median :12.023 Median :11.00 Median : 5.710 Median :16.00 ## Mean :11.963 Mean :11.71 Mean : 5.605 Mean :18.26 ## 3rd Qu.:12.697 3rd Qu.:17.00 3rd Qu.: 6.997 3rd Qu.:24.00 ## Max. :14.654 Max. :32.00 Max. :10.492 Max. :66.00 ## ## ConphonN ConfriendsV ConfriendsN ConffV ## Min. : 0.000 Min. : 0.00 Min. : 0.000 Min. :0.0000 ## 1st Qu.: 5.268 1st Qu.: 4.00 1st Qu.: 4.159 1st Qu.:0.0000 ## Median : 6.340 Median :10.00 Median : 5.487 Median :0.0000 ## Mean : 6.318 Mean :10.42 Mean : 5.265 Mean :0.4109 ## 3rd Qu.: 7.491 3rd Qu.:15.00 3rd Qu.: 6.642 3rd Qu.:0.6931 ## Max. :10.600 Max. :31.00 Max. :10.303 Max. :3.3322 ## ## ConffN ConfbV ConfbN NounFrequency ## Min. : 0.000 Min. :0.0000 Min. : 0.000 Min. : 0.00 ## 1st Qu.: 0.000 1st Qu.:0.6931 1st Qu.: 0.000 1st Qu.: 28.75 ## Median : 0.000 Median :1.3863 Median : 4.143 Median : 108.00 ## Mean : 1.308 Mean :1.5570 Mean : 3.890 Mean : 600.19 ## 3rd Qu.: 1.386 3rd Qu.:2.5649 3rd Qu.: 6.242 3rd Qu.: 424.75 ## Max. :10.347 Max. :4.1897 Max. :10.600 Max. :35351.00 ## ## VerbFrequency CV Obstruent Frication Voice ## Min. : 0.0 C:4446 cont:1068 burst :1840 voiced :2060 ## 1st Qu.: 0.0 V: 122 obst:3500 frication:1660 voiceless:2508 ## Median : 30.0 long : 88 ## Mean : 881.0 short : 980 ## 3rd Qu.: 164.2 ## Max. :242066.0 ## ## FrequencyInitialDiphoneWord FrequencyInitialDiphoneSyllable CorrectLexdec ## Min. : 3.091 Min. : 3.367 Min. : 1.00 ## 1st Qu.: 9.557 1st Qu.:10.000 1st Qu.:27.00 ## Median :10.517 Median :10.972 Median :29.00 ## Mean :10.359 Mean :10.789 Mean :27.05 ## 3rd Qu.:11.320 3rd Qu.:11.703 3rd Qu.:30.00 ## Max. :13.925 Max. :13.930 Max. :30.00 ## 2.8.8.2 Summary for a specific variable english %&gt;% summarise(count = n(), range_RTlexdec = range(RTlexdec), mean_RTlexdec = mean(RTlexdec), sd_RTlexdec = sd(RTlexdec), var_RTlexdec = var(RTlexdec), min_RTlexdec = min(RTlexdec), max_RTlexdec = max(RTlexdec), quart1_RTlexdec = quantile(RTlexdec, 0.25), quart1_RTlexdec = quantile(RTlexdec, 0.75), median_RTlexdec = median(RTlexdec)) ## Warning: Returning more (or less) than 1 row per `summarise()` group was deprecated in dplyr 1.1.0. ## ℹ Please use `reframe()` instead. ## ℹ When switching from `summarise()` to `reframe()`, remember that `reframe()` always returns an ungrouped ## data frame and adjust accordingly. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated. ## count range_RTlexdec mean_RTlexdec sd_RTlexdec var_RTlexdec min_RTlexdec ## 1 4568 6.205325 6.550097 0.1569188 0.02462351 6.205325 ## 2 4568 7.187808 6.550097 0.1569188 0.02462351 6.205325 ## max_RTlexdec quart1_RTlexdec median_RTlexdec ## 1 7.187808 6.653211 6.550466 ## 2 7.187808 6.653211 6.550466 As you can see, we can add use summarise to obtain summaries of the dataset. We asked here for the mean, sd, variance, minimum and maximum values, etc.. In the dataset english, we have many numeric variables, and if we want to obtain summaries for all of numeric variables, we can use summarise_all. 2.8.8.3 Summarise_all If you want to add another level of summaries, e.g., for length, you can either add them as another level (with a new variable name) or use summarise_all to do that for you. We need to select only numeric variables to do that. This is the function to only select numeric variables where(is.numeric). If you do not use it, you will get an error message english %&gt;% select(where(is.numeric)) %&gt;% summarise_all(funs(mean = mean, sd = sd, var = var, min = min, max = max, range = range, median = median, Q1 = quantile(., probs = 0.25), Q3 = quantile(., probs = 0.75))) ## Warning: `funs()` was deprecated in dplyr 0.8.0. ## ℹ Please use a list of either functions or lambdas: ## ## # Simple named list: list(mean = mean, median = median) ## ## # Auto named with `tibble::lst()`: tibble::lst(mean, median) ## ## # Using lambdas list(~ mean(., trim = .2), ~ median(., na.rm = TRUE)) ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated. ## RTlexdec_mean RTnaming_mean Familiarity_mean WrittenFrequency_mean ## 1 6.550097 6.322505 3.795582 5.021145 ## 2 6.550097 6.322505 3.795582 5.021145 ## WrittenSpokenFrequencyRatio_mean FamilySize_mean DerivationalEntropy_mean ## 1 0.6776251 1.821324 0.5408901 ## 2 0.6776251 1.821324 0.5408901 ## InflectionalEntropy_mean NumberSimplexSynsets_mean NumberComplexSynsets_mean ## 1 1.118614 1.707797 1.567777 ## 2 1.118614 1.707797 1.567777 ## LengthInLetters_mean Ncount_mean MeanBigramFrequency_mean ## 1 4.342382 6.265762 8.489792 ## 2 4.342382 6.265762 8.489792 ## FrequencyInitialDiphone_mean ConspelV_mean ConspelN_mean ConphonV_mean ## 1 11.96292 11.71235 5.605324 18.25963 ## 2 11.96292 11.71235 5.605324 18.25963 ## ConphonN_mean ConfriendsV_mean ConfriendsN_mean ConffV_mean ConffN_mean ## 1 6.317727 10.41813 5.265387 0.410887 1.308101 ## 2 6.317727 10.41813 5.265387 0.410887 1.308101 ## ConfbV_mean ConfbN_mean NounFrequency_mean VerbFrequency_mean ## 1 1.556996 3.889859 600.1883 881.0201 ## 2 1.556996 3.889859 600.1883 881.0201 ## FrequencyInitialDiphoneWord_mean FrequencyInitialDiphoneSyllable_mean ## 1 10.35905 10.7892 ## 2 10.35905 10.7892 ## CorrectLexdec_mean RTlexdec_sd RTnaming_sd Familiarity_sd WrittenFrequency_sd ## 1 27.05166 0.1569188 0.1784815 1.149326 1.843559 ## 2 27.05166 0.1569188 0.1784815 1.149326 1.843559 ## WrittenSpokenFrequencyRatio_sd FamilySize_sd DerivationalEntropy_sd ## 1 1.165004 0.8205113 0.5573451 ## 2 1.165004 0.8205113 0.5573451 ## InflectionalEntropy_sd NumberSimplexSynsets_sd NumberComplexSynsets_sd ## 1 0.5660556 0.6693279 1.308999 ## 2 0.5660556 0.6693279 1.308999 ## LengthInLetters_sd Ncount_sd MeanBigramFrequency_sd ## 1 0.8418279 4.893778 0.6982397 ## 2 0.8418279 4.893778 0.6982397 ## FrequencyInitialDiphone_sd ConspelV_sd ConspelN_sd ConphonV_sd ConphonN_sd ## 1 1.11962 7.090395 1.99571 11.83507 1.980334 ## 2 1.11962 7.090395 1.99571 11.83507 1.980334 ## ConfriendsV_sd ConfriendsN_sd ConffV_sd ConffN_sd ConfbV_sd ConfbN_sd ## 1 6.923388 2.076256 0.6881427 2.413261 1.125484 3.131148 ## 2 6.923388 2.076256 0.6881427 2.413261 1.125484 3.131148 ## NounFrequency_sd VerbFrequency_sd FrequencyInitialDiphoneWord_sd ## 1 1858.115 6852.356 1.583577 ## 2 1858.115 6852.356 1.583577 ## FrequencyInitialDiphoneSyllable_sd CorrectLexdec_sd RTlexdec_var RTnaming_var ## 1 1.598599 4.302697 0.02462351 0.03185564 ## 2 1.598599 4.302697 0.02462351 0.03185564 ## Familiarity_var WrittenFrequency_var WrittenSpokenFrequencyRatio_var ## 1 1.32095 3.39871 1.357234 ## 2 1.32095 3.39871 1.357234 ## FamilySize_var DerivationalEntropy_var InflectionalEntropy_var ## 1 0.6732388 0.3106336 0.320419 ## 2 0.6732388 0.3106336 0.320419 ## NumberSimplexSynsets_var NumberComplexSynsets_var LengthInLetters_var ## 1 0.4479998 1.713479 0.7086742 ## 2 0.4479998 1.713479 0.7086742 ## Ncount_var MeanBigramFrequency_var FrequencyInitialDiphone_var ConspelV_var ## 1 23.94906 0.4875387 1.25355 50.27371 ## 2 23.94906 0.4875387 1.25355 50.27371 ## ConspelN_var ConphonV_var ConphonN_var ConfriendsV_var ConfriendsN_var ## 1 3.982859 140.0688 3.921722 47.9333 4.31084 ## 2 3.982859 140.0688 3.921722 47.9333 4.31084 ## ConffV_var ConffN_var ConfbV_var ConfbN_var NounFrequency_var ## 1 0.4735403 5.823826 1.266714 9.804086 3452593 ## 2 0.4735403 5.823826 1.266714 9.804086 3452593 ## VerbFrequency_var FrequencyInitialDiphoneWord_var ## 1 46954789 2.507715 ## 2 46954789 2.507715 ## FrequencyInitialDiphoneSyllable_var CorrectLexdec_var RTlexdec_min ## 1 2.555518 18.51321 6.205325 ## 2 2.555518 18.51321 6.205325 ## RTnaming_min Familiarity_min WrittenFrequency_min ## 1 6.021751 1.1 0 ## 2 6.021751 1.1 0 ## WrittenSpokenFrequencyRatio_min FamilySize_min DerivationalEntropy_min ## 1 -6.553933 0.6931472 0 ## 2 -6.553933 0.6931472 0 ## InflectionalEntropy_min NumberSimplexSynsets_min NumberComplexSynsets_min ## 1 0 0 0 ## 2 0 0 0 ## LengthInLetters_min Ncount_min MeanBigramFrequency_min ## 1 2 0 5.390053 ## 2 2 0 5.390053 ## FrequencyInitialDiphone_min ConspelV_min ConspelN_min ConphonV_min ## 1 4.14313 0 0 0 ## 2 4.14313 0 0 0 ## ConphonN_min ConfriendsV_min ConfriendsN_min ConffV_min ConffN_min ConfbV_min ## 1 0 0 0 0 0 0 ## 2 0 0 0 0 0 0 ## ConfbN_min NounFrequency_min VerbFrequency_min ## 1 0 0 0 ## 2 0 0 0 ## FrequencyInitialDiphoneWord_min FrequencyInitialDiphoneSyllable_min ## 1 3.091042 3.367296 ## 2 3.091042 3.367296 ## CorrectLexdec_min RTlexdec_max RTnaming_max Familiarity_max ## 1 1 7.187808 6.695675 6.97 ## 2 1 7.187808 6.695675 6.97 ## WrittenFrequency_max WrittenSpokenFrequencyRatio_max FamilySize_max ## 1 11.35666 5.630714 5.517453 ## 2 11.35666 5.630714 5.517453 ## DerivationalEntropy_max InflectionalEntropy_max NumberSimplexSynsets_max ## 1 5.20728 2.45141 4.356709 ## 2 5.20728 2.45141 4.356709 ## NumberComplexSynsets_max LengthInLetters_max Ncount_max ## 1 6.111467 7 22 ## 2 6.111467 7 22 ## MeanBigramFrequency_max FrequencyInitialDiphone_max ConspelV_max ConspelN_max ## 1 10.28277 14.65437 32 10.49202 ## 2 10.28277 14.65437 32 10.49202 ## ConphonV_max ConphonN_max ConfriendsV_max ConfriendsN_max ConffV_max ## 1 66 10.59975 31 10.30304 3.332205 ## 2 66 10.59975 31 10.30304 3.332205 ## ConffN_max ConfbV_max ConfbN_max NounFrequency_max VerbFrequency_max ## 1 10.34744 4.189655 10.59975 35351 242066 ## 2 10.34744 4.189655 10.59975 35351 242066 ## FrequencyInitialDiphoneWord_max FrequencyInitialDiphoneSyllable_max ## 1 13.9249 13.92962 ## 2 13.9249 13.92962 ## CorrectLexdec_max RTlexdec_range RTnaming_range Familiarity_range ## 1 30 6.205325 6.021751 1.10 ## 2 30 7.187808 6.695675 6.97 ## WrittenFrequency_range WrittenSpokenFrequencyRatio_range FamilySize_range ## 1 0.00000 -6.553933 0.6931472 ## 2 11.35666 5.630714 5.5174529 ## DerivationalEntropy_range InflectionalEntropy_range ## 1 0.00000 0.00000 ## 2 5.20728 2.45141 ## NumberSimplexSynsets_range NumberComplexSynsets_range LengthInLetters_range ## 1 0.000000 0.000000 2 ## 2 4.356709 6.111467 7 ## Ncount_range MeanBigramFrequency_range FrequencyInitialDiphone_range ## 1 0 5.390053 4.14313 ## 2 22 10.282767 14.65437 ## ConspelV_range ConspelN_range ConphonV_range ConphonN_range ConfriendsV_range ## 1 0 0.00000 0 0.00000 0 ## 2 32 10.49202 66 10.59975 31 ## ConfriendsN_range ConffV_range ConffN_range ConfbV_range ConfbN_range ## 1 0.00000 0.000000 0.00000 0.000000 0.00000 ## 2 10.30304 3.332205 10.34744 4.189655 10.59975 ## NounFrequency_range VerbFrequency_range FrequencyInitialDiphoneWord_range ## 1 0 0 3.091042 ## 2 35351 242066 13.924902 ## FrequencyInitialDiphoneSyllable_range CorrectLexdec_range RTlexdec_median ## 1 3.367296 1 6.550466 ## 2 13.929620 30 6.550466 ## RTnaming_median Familiarity_median WrittenFrequency_median ## 1 6.342023 3.7 4.832298 ## 2 6.342023 3.7 4.832298 ## WrittenSpokenFrequencyRatio_median FamilySize_median ## 1 0.681184 1.791759 ## 2 0.681184 1.791759 ## DerivationalEntropy_median InflectionalEntropy_median ## 1 0.410975 1.09821 ## 2 0.410975 1.09821 ## NumberSimplexSynsets_median NumberComplexSynsets_median ## 1 1.609438 1.386294 ## 2 1.609438 1.386294 ## LengthInLetters_median Ncount_median MeanBigramFrequency_median ## 1 4 5 8.55855 ## 2 4 5 8.55855 ## FrequencyInitialDiphone_median ConspelV_median ConspelN_median ## 1 12.02268 11 5.710427 ## 2 12.02268 11 5.710427 ## ConphonV_median ConphonN_median ConfriendsV_median ConfriendsN_median ## 1 16 6.340359 10 5.48685 ## 2 16 6.340359 10 5.48685 ## ConffV_median ConffN_median ConfbV_median ConfbN_median NounFrequency_median ## 1 0 0 1.386294 4.143135 108 ## 2 0 0 1.386294 4.143135 108 ## VerbFrequency_median FrequencyInitialDiphoneWord_median ## 1 30 10.51651 ## 2 30 10.51651 ## FrequencyInitialDiphoneSyllable_median CorrectLexdec_median RTlexdec_Q1 ## 1 10.97207 29 6.425525 ## 2 10.97207 29 6.425525 ## RTnaming_Q1 Familiarity_Q1 WrittenFrequency_Q1 WrittenSpokenFrequencyRatio_Q1 ## 1 6.148682 3 3.7612 -0.07401695 ## 2 6.148682 3 3.7612 -0.07401695 ## FamilySize_Q1 DerivationalEntropy_Q1 InflectionalEntropy_Q1 ## 1 1.098612 0.039325 0.7441725 ## 2 1.098612 0.039325 0.7441725 ## NumberSimplexSynsets_Q1 NumberComplexSynsets_Q1 LengthInLetters_Q1 Ncount_Q1 ## 1 1.098612 0 4 2 ## 2 1.098612 0 4 2 ## MeanBigramFrequency_Q1 FrequencyInitialDiphone_Q1 ConspelV_Q1 ConspelN_Q1 ## 1 8.099924 11.27694 6 4.519056 ## 2 8.099924 11.27694 6 4.519056 ## ConphonV_Q1 ConphonN_Q1 ConfriendsV_Q1 ConfriendsN_Q1 ConffV_Q1 ConffN_Q1 ## 1 10 5.267858 4 4.158883 0 0 ## 2 10 5.267858 4 4.158883 0 0 ## ConfbV_Q1 ConfbN_Q1 NounFrequency_Q1 VerbFrequency_Q1 ## 1 0.6931472 0 28.75 0 ## 2 0.6931472 0 28.75 0 ## FrequencyInitialDiphoneWord_Q1 FrequencyInitialDiphoneSyllable_Q1 ## 1 9.556808 10.00048 ## 2 9.556808 10.00048 ## CorrectLexdec_Q1 RTlexdec_Q3 RTnaming_Q3 Familiarity_Q3 WrittenFrequency_Q3 ## 1 27 6.653211 6.489699 4.57 6.247074 ## 2 27 6.653211 6.489699 4.57 6.247074 ## WrittenSpokenFrequencyRatio_Q3 FamilySize_Q3 DerivationalEntropy_Q3 ## 1 1.44146 2.302585 0.893225 ## 2 1.44146 2.302585 0.893225 ## InflectionalEntropy_Q3 NumberSimplexSynsets_Q3 NumberComplexSynsets_Q3 ## 1 1.632455 2.197225 2.564949 ## 2 1.632455 2.197225 2.564949 ## LengthInLetters_Q3 Ncount_Q3 MeanBigramFrequency_Q3 ## 1 5 9 8.972658 ## 2 5 9 8.972658 ## FrequencyInitialDiphone_Q3 ConspelV_Q3 ConspelN_Q3 ConphonV_Q3 ConphonN_Q3 ## 1 12.69734 17 6.997358 24 7.491413 ## 2 12.69734 17 6.997358 24 7.491413 ## ConfriendsV_Q3 ConfriendsN_Q3 ConffV_Q3 ConffN_Q3 ConfbV_Q3 ConfbN_Q3 ## 1 15 6.642077 0.6931472 1.386294 2.564949 6.241734 ## 2 15 6.642077 0.6931472 1.386294 2.564949 6.241734 ## NounFrequency_Q3 VerbFrequency_Q3 FrequencyInitialDiphoneWord_Q3 ## 1 424.75 164.25 11.31995 ## 2 424.75 164.25 11.31995 ## FrequencyInitialDiphoneSyllable_Q3 CorrectLexdec_Q3 ## 1 11.70264 30 ## 2 11.70264 30 As you can see, in this example, we see the chains of commands in the Tidyverse. We can continue to add commands each time we want to investigate something in particular. Keep adding pipes and commands. The most important point is that the dataset english did not change at all. If you want to create a new dataset with the results, simply use the assignment function &lt;- at the beginning or -&gt; at the end and give a name to the new dataset. 2.8.8.4 Group_by 2.8.8.5 One variable What if you want to obtain all results summarised by a specific grouping? Let’s obtain the results grouped by the levels of AgeSubject. english %&gt;% group_by(AgeSubject) %&gt;% summarise(count = n(), range_RTlexdec = range(RTlexdec), mean_RTlexdec = mean(RTlexdec), sd_RTlexdec = sd(RTlexdec), var_RTlexdec = var(RTlexdec), min_RTlexdec = min(RTlexdec), max_RTlexdec = max(RTlexdec), quart1_RTlexdec = quantile(RTlexdec, 0.25), quart1_RTlexdec = quantile(RTlexdec, 0.75), median_RTlexdec = median(RTlexdec)) ## Warning: Returning more (or less) than 1 row per `summarise()` group was deprecated in dplyr 1.1.0. ## ℹ Please use `reframe()` instead. ## ℹ When switching from `summarise()` to `reframe()`, remember that `reframe()` always returns an ungrouped ## data frame and adjust accordingly. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated. ## `summarise()` has grouped output by &#39;AgeSubject&#39;. You can override using the ## `.groups` argument. ## # A tibble: 4 × 10 ## # Groups: AgeSubject [2] ## AgeSubject count range_RTlexdec mean_RTlexdec sd_RTlexdec var_RTlexdec ## &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 old 2284 6.40 6.66 0.116 0.0134 ## 2 old 2284 7.19 6.66 0.116 0.0134 ## 3 young 2284 6.21 6.44 0.106 0.0113 ## 4 young 2284 6.88 6.44 0.106 0.0113 ## # ℹ 4 more variables: min_RTlexdec &lt;dbl&gt;, max_RTlexdec &lt;dbl&gt;, ## # quart1_RTlexdec &lt;dbl&gt;, median_RTlexdec &lt;dbl&gt; 2.8.8.6 Multiple variables What if you want to obtain all results summarised by multiple groupings? Let’s obtain the results grouped by the levels of AgeSubject, WordCategory and Voice and we want to save the output. english %&gt;% group_by(AgeSubject, WordCategory, Voice) %&gt;% summarise(count = n(), range_RTlexdec = range(RTlexdec), mean_RTlexdec = mean(RTlexdec), sd_RTlexdec = sd(RTlexdec), var_RTlexdec = var(RTlexdec), min_RTlexdec = min(RTlexdec), max_RTlexdec = max(RTlexdec), quart1_RTlexdec = quantile(RTlexdec, 0.25), quart1_RTlexdec = quantile(RTlexdec, 0.75), median_RTlexdec = median(RTlexdec)) -&gt; dfMeans ## Warning: Returning more (or less) than 1 row per `summarise()` group was deprecated in dplyr 1.1.0. ## ℹ Please use `reframe()` instead. ## ℹ When switching from `summarise()` to `reframe()`, remember that `reframe()` always returns an ungrouped ## data frame and adjust accordingly. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated. ## `summarise()` has grouped output by &#39;AgeSubject&#39;, &#39;WordCategory&#39;, &#39;Voice&#39;. You can override using the ## `.groups` argument. dfMeans ## # A tibble: 16 × 12 ## # Groups: AgeSubject, WordCategory, Voice [8] ## AgeSubject WordCategory Voice count range_RTlexdec mean_RTlexdec sd_RTlexdec ## &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 old N voiced 676 6.45 6.67 0.121 ## 2 old N voiced 676 7.15 6.67 0.121 ## 3 old N voice… 776 6.45 6.66 0.120 ## 4 old N voice… 776 7.19 6.66 0.120 ## 5 old V voiced 354 6.40 6.66 0.112 ## 6 old V voiced 354 7.14 6.66 0.112 ## 7 old V voice… 478 6.46 6.65 0.101 ## 8 old V voice… 478 7.01 6.65 0.101 ## 9 young N voiced 676 6.21 6.45 0.116 ## 10 young N voiced 676 6.88 6.45 0.116 ## 11 young N voice… 776 6.21 6.44 0.102 ## 12 young N voice… 776 6.79 6.44 0.102 ## 13 young V voiced 354 6.24 6.43 0.106 ## 14 young V voiced 354 6.75 6.43 0.106 ## 15 young V voice… 478 6.21 6.43 0.0982 ## 16 young V voice… 478 6.83 6.43 0.0982 ## # ℹ 5 more variables: var_RTlexdec &lt;dbl&gt;, min_RTlexdec &lt;dbl&gt;, ## # max_RTlexdec &lt;dbl&gt;, quart1_RTlexdec &lt;dbl&gt;, median_RTlexdec &lt;dbl&gt; 2.8.9 Summary tables Using the package summarytools you can obtain nice table ready for publications! 2.8.9.1 Summary of full dataset with graphs english %&gt;% dfSummary(graph.col = TRUE, style = &quot;grid&quot;, graph.magnif = 0.75) %&gt;% stview(method = &quot;render&quot;) Data Frame Summary english Dimensions: 4568 x 36 Duplicates: 0 No Variable Stats / Values Freqs (% of Valid) Graph Valid Missing 1 RTlexdec [numeric] Mean (sd) : 6.6 (0.2)min &le; med &le; max:6.2 &le; 6.6 &le; 7.2IQR (CV) : 0.2 (0) 4019 distinct values 4568 (100.0%) 0 (0.0%) 2 RTnaming [numeric] Mean (sd) : 6.3 (0.2)min &le; med &le; max:6 &le; 6.3 &le; 6.7IQR (CV) : 0.3 (0) 1892 distinct values 4568 (100.0%) 0 (0.0%) 3 Familiarity [numeric] Mean (sd) : 3.8 (1.1)min &le; med &le; max:1.1 &le; 3.7 &le; 7IQR (CV) : 1.6 (0.3) 254 distinct values 4568 (100.0%) 0 (0.0%) 4 Word [factor] 1. ace2. act3. add4. age5. aid6. aide7. ail8. aim9. air10. aisle[ 2187 others ] 2(0.0%)2(0.0%)2(0.0%)2(0.0%)2(0.0%)2(0.0%)2(0.0%)2(0.0%)2(0.0%)2(0.0%)4548(99.6%) 4568 (100.0%) 0 (0.0%) 5 AgeSubject [factor] 1. old2. young 2284(50.0%)2284(50.0%) 4568 (100.0%) 0 (0.0%) 6 WordCategory [factor] 1. N2. V 2904(63.6%)1664(36.4%) 4568 (100.0%) 0 (0.0%) 7 WrittenFrequency [numeric] Mean (sd) : 5 (1.8)min &le; med &le; max:0 &le; 4.8 &le; 11.4IQR (CV) : 2.5 (0.4) 882 distinct values 4568 (100.0%) 0 (0.0%) 8 WrittenSpokenFrequencyRatio [numeric] Mean (sd) : 0.7 (1.2)min &le; med &le; max:-6.6 &le; 0.7 &le; 5.6IQR (CV) : 1.5 (1.7) 1595 distinct values 4568 (100.0%) 0 (0.0%) 9 FamilySize [numeric] Mean (sd) : 1.8 (0.8)min &le; med &le; max:0.7 &le; 1.8 &le; 5.5IQR (CV) : 1.2 (0.5) 75 distinct values 4568 (100.0%) 0 (0.0%) 10 DerivationalEntropy [numeric] Mean (sd) : 0.5 (0.6)min &le; med &le; max:0 &le; 0.4 &le; 5.2IQR (CV) : 0.9 (1) 1644 distinct values 4568 (100.0%) 0 (0.0%) 11 InflectionalEntropy [numeric] Mean (sd) : 1.1 (0.6)min &le; med &le; max:0 &le; 1.1 &le; 2.5IQR (CV) : 0.9 (0.5) 1966 distinct values 4568 (100.0%) 0 (0.0%) 12 NumberSimplexSynsets [numeric] Mean (sd) : 1.7 (0.7)min &le; med &le; max:0 &le; 1.6 &le; 4.4IQR (CV) : 1.1 (0.4) 47 distinct values 4568 (100.0%) 0 (0.0%) 13 NumberComplexSynsets [numeric] Mean (sd) : 1.6 (1.3)min &le; med &le; max:0 &le; 1.4 &le; 6.1IQR (CV) : 2.6 (0.8) 106 distinct values 4568 (100.0%) 0 (0.0%) 14 LengthInLetters [integer] Mean (sd) : 4.3 (0.8)min &le; med &le; max:2 &le; 4 &le; 7IQR (CV) : 1 (0.2) 2:6(0.1%)3:676(14.8%)4:2020(44.2%)5:1504(32.9%)6:338(7.4%)7:24(0.5%) 4568 (100.0%) 0 (0.0%) 15 Ncount [integer] Mean (sd) : 6.3 (4.9)min &le; med &le; max:0 &le; 5 &le; 22IQR (CV) : 7 (0.8) 23 distinct values 4568 (100.0%) 0 (0.0%) 16 MeanBigramFrequency [numeric] Mean (sd) : 8.5 (0.7)min &le; med &le; max:5.4 &le; 8.6 &le; 10.3IQR (CV) : 0.9 (0.1) 2196 distinct values 4568 (100.0%) 0 (0.0%) 17 FrequencyInitialDiphone [numeric] Mean (sd) : 12 (1.1)min &le; med &le; max:4.1 &le; 12 &le; 14.7IQR (CV) : 1.4 (0.1) 166 distinct values 4568 (100.0%) 0 (0.0%) 18 ConspelV [integer] Mean (sd) : 11.7 (7.1)min &le; med &le; max:0 &le; 11 &le; 32IQR (CV) : 11 (0.6) 29 distinct values 4568 (100.0%) 0 (0.0%) 19 ConspelN [numeric] Mean (sd) : 5.6 (2)min &le; med &le; max:0 &le; 5.7 &le; 10.5IQR (CV) : 2.5 (0.4) 310 distinct values 4568 (100.0%) 0 (0.0%) 20 ConphonV [integer] Mean (sd) : 18.3 (11.8)min &le; med &le; max:0 &le; 16 &le; 66IQR (CV) : 14 (0.6) 41 distinct values 4568 (100.0%) 0 (0.0%) 21 ConphonN [numeric] Mean (sd) : 6.3 (2)min &le; med &le; max:0 &le; 6.3 &le; 10.6IQR (CV) : 2.2 (0.3) 279 distinct values 4568 (100.0%) 0 (0.0%) 22 ConfriendsV [integer] Mean (sd) : 10.4 (6.9)min &le; med &le; max:0 &le; 10 &le; 31IQR (CV) : 11 (0.7) 31 distinct values 4568 (100.0%) 0 (0.0%) 23 ConfriendsN [numeric] Mean (sd) : 5.3 (2.1)min &le; med &le; max:0 &le; 5.5 &le; 10.3IQR (CV) : 2.5 (0.4) 485 distinct values 4568 (100.0%) 0 (0.0%) 24 ConffV [numeric] Mean (sd) : 0.4 (0.7)min &le; med &le; max:0 &le; 0 &le; 3.3IQR (CV) : 0.7 (1.7) 23 distinct values 4568 (100.0%) 0 (0.0%) 25 ConffN [numeric] Mean (sd) : 1.3 (2.4)min &le; med &le; max:0 &le; 0 &le; 10.3IQR (CV) : 1.4 (1.8) 141 distinct values 4568 (100.0%) 0 (0.0%) 26 ConfbV [numeric] Mean (sd) : 1.6 (1.1)min &le; med &le; max:0 &le; 1.4 &le; 4.2IQR (CV) : 1.9 (0.7) 48 distinct values 4568 (100.0%) 0 (0.0%) 27 ConfbN [numeric] Mean (sd) : 3.9 (3.1)min &le; med &le; max:0 &le; 4.1 &le; 10.6IQR (CV) : 6.2 (0.8) 365 distinct values 4568 (100.0%) 0 (0.0%) 28 NounFrequency [integer] Mean (sd) : 600.2 (1858.1)min &le; med &le; max:0 &le; 108 &le; 35351IQR (CV) : 396 (3.1) 822 distinct values 4568 (100.0%) 0 (0.0%) 29 VerbFrequency [integer] Mean (sd) : 881 (6852.4)min &le; med &le; max:0 &le; 30 &le; 242066IQR (CV) : 164.2 (7.8) 594 distinct values 4568 (100.0%) 0 (0.0%) 30 CV [factor] 1. C2. V 4446(97.3%)122(2.7%) 4568 (100.0%) 0 (0.0%) 31 Obstruent [factor] 1. cont2. obst 1068(23.4%)3500(76.6%) 4568 (100.0%) 0 (0.0%) 32 Frication [factor] 1. burst2. frication3. long4. short 1840(40.3%)1660(36.3%)88(1.9%)980(21.5%) 4568 (100.0%) 0 (0.0%) 33 Voice [factor] 1. voiced2. voiceless 2060(45.1%)2508(54.9%) 4568 (100.0%) 0 (0.0%) 34 FrequencyInitialDiphoneWord [numeric] Mean (sd) : 10.4 (1.6)min &le; med &le; max:3.1 &le; 10.5 &le; 13.9IQR (CV) : 1.8 (0.2) 401 distinct values 4568 (100.0%) 0 (0.0%) 35 FrequencyInitialDiphoneSyllable [numeric] Mean (sd) : 10.8 (1.6)min &le; med &le; max:3.4 &le; 11 &le; 13.9IQR (CV) : 1.7 (0.1) 402 distinct values 4568 (100.0%) 0 (0.0%) 36 CorrectLexdec [integer] Mean (sd) : 27.1 (4.3)min &le; med &le; max:1 &le; 29 &le; 30IQR (CV) : 3 (0.2) 30 distinct values 4568 (100.0%) 0 (0.0%) Generated by summarytools 1.0.1 (R version 4.4.2)2025-04-22 2.8.9.2 Descriptive statistics for numeric variables english %&gt;% descr() %&gt;% stview(method = &quot;render&quot;) ## Non-numerical variable(s) ignored: Word, AgeSubject, WordCategory, CV, Obstruent, Frication, Voice Descriptive Statistics english N: 4568 ConfbN ConfbV ConffN ConffV ConfriendsN ConfriendsV ConphonN ConphonV ConspelN ConspelV CorrectLexdec DerivationalEntropy Familiarity FamilySize FrequencyInitialDiphone FrequencyInitialDiphoneSyllable FrequencyInitialDiphoneWord InflectionalEntropy LengthInLetters MeanBigramFrequency Ncount NounFrequency NumberComplexSynsets NumberSimplexSynsets RTlexdec RTnaming VerbFrequency WrittenFrequency WrittenSpokenFrequencyRatio Mean 3.89 1.56 1.31 0.41 5.27 10.42 6.32 18.26 5.61 11.71 27.05 0.54 3.80 1.82 11.96 10.79 10.36 1.12 4.34 8.49 6.27 600.19 1.57 1.71 6.55 6.32 881.02 5.02 0.68 Std.Dev 3.13 1.13 2.41 0.69 2.08 6.92 1.98 11.84 2.00 7.09 4.30 0.56 1.15 0.82 1.12 1.60 1.58 0.57 0.84 0.70 4.89 1858.12 1.31 0.67 0.16 0.18 6852.36 1.84 1.17 Min 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 1.00 0.00 1.10 0.69 4.14 3.37 3.09 0.00 2.00 5.39 0.00 0.00 0.00 0.00 6.21 6.02 0.00 0.00 -6.55 Q1 0.00 0.69 0.00 0.00 4.16 4.00 5.27 10.00 4.52 6.00 27.00 0.04 3.00 1.10 11.28 10.00 9.55 0.74 4.00 8.10 2.00 28.50 0.00 1.10 6.43 6.15 0.00 3.76 -0.07 Median 4.14 1.39 0.00 0.00 5.49 10.00 6.34 16.00 5.71 11.00 29.00 0.41 3.70 1.79 12.02 10.97 10.52 1.10 4.00 8.56 5.00 108.00 1.39 1.61 6.55 6.34 30.00 4.83 0.68 Q3 6.24 2.56 1.39 0.69 6.65 15.00 7.51 24.00 7.00 17.00 30.00 0.89 4.57 2.30 12.70 11.70 11.32 1.63 5.00 8.97 9.00 425.50 2.56 2.20 6.65 6.49 164.50 6.25 1.44 Max 10.60 4.19 10.35 3.33 10.30 31.00 10.60 66.00 10.49 32.00 30.00 5.21 6.97 5.52 14.65 13.93 13.92 2.45 7.00 10.28 22.00 35351.00 6.11 4.36 7.19 6.70 242066.00 11.36 5.63 MAD 4.09 1.20 0.00 0.00 1.86 8.90 1.68 10.38 1.81 8.90 1.48 0.61 1.14 0.90 1.11 1.18 1.32 0.70 1.48 0.64 4.45 146.78 1.75 0.76 0.17 0.26 44.48 1.81 1.12 IQR 6.24 1.87 1.39 0.69 2.48 11.00 2.22 14.00 2.48 11.00 3.00 0.85 1.57 1.20 1.42 1.70 1.76 0.89 1.00 0.87 7.00 396.00 2.56 1.10 0.23 0.34 164.25 2.49 1.52 CV 0.80 0.72 1.84 1.67 0.39 0.66 0.31 0.65 0.36 0.61 0.16 1.03 0.30 0.45 0.09 0.15 0.15 0.51 0.19 0.08 0.78 3.10 0.83 0.39 0.02 0.03 7.78 0.37 1.72 Skewness 0.20 0.16 1.71 1.76 -0.41 0.44 -0.40 1.10 -0.41 0.39 -2.66 1.42 0.25 0.79 -0.60 -0.96 -0.86 -0.33 0.23 -0.53 0.75 9.08 0.45 0.39 0.35 0.06 22.80 0.30 -0.21 SE.Skewness 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 Kurtosis -1.11 -1.08 1.60 2.46 0.14 -0.47 0.72 1.74 0.23 -0.41 7.83 4.00 -0.41 0.59 1.94 1.88 1.72 -0.84 -0.20 0.46 -0.26 117.84 -0.71 0.01 -0.09 -1.67 705.39 -0.04 0.98 N.Valid 4568 4568 4568 4568 4568 4568 4568 4568 4568 4568 4568 4568 4568 4568 4568 4568 4568 4568 4568 4568 4568 4568 4568 4568 4568 4568 4568 4568 4568 Pct.Valid 100.00 100.00 100.00 100.00 100.00 100.00 100.00 100.00 100.00 100.00 100.00 100.00 100.00 100.00 100.00 100.00 100.00 100.00 100.00 100.00 100.00 100.00 100.00 100.00 100.00 100.00 100.00 100.00 100.00 Generated by summarytools 1.0.1 (R version 4.4.2)2025-04-22 2.8.9.3 Frequencies for non-numeric variables english %&gt;% freq() %&gt;% stview(method = &quot;render&quot;) ## Variable(s) ignored: RTlexdec, RTnaming, Familiarity, WrittenFrequency, WrittenSpokenFrequencyRatio, FamilySize, DerivationalEntropy, InflectionalEntropy, NumberSimplexSynsets, NumberComplexSynsets, MeanBigramFrequency, FrequencyInitialDiphone, ConspelV, ConspelN, ConphonV, ConphonN, ConfriendsV, ConfriendsN, ConffN, ConfbV, ConfbN, NounFrequency, VerbFrequency Frequencies english$Word Type: Factor Valid Total Word Freq % % Cum. % % Cum. ace 2 0.044 0.044 0.044 0.044 act 2 0.044 0.088 0.044 0.088 add 2 0.044 0.13 0.044 0.13 age 2 0.044 0.18 0.044 0.18 aid 2 0.044 0.22 0.044 0.22 aide 2 0.044 0.26 0.044 0.26 ail 2 0.044 0.31 0.044 0.31 aim 2 0.044 0.35 0.044 0.35 air 2 0.044 0.39 0.044 0.39 aisle 2 0.044 0.44 0.044 0.44 ale 2 0.044 0.48 0.044 0.48 angst 2 0.044 0.53 0.044 0.53 ant 2 0.044 0.57 0.044 0.57 ape 2 0.044 0.61 0.044 0.61 arc 2 0.044 0.66 0.044 0.66 arch 2 0.044 0.70 0.044 0.70 are 2 0.044 0.74 0.044 0.74 arm 4 0.088 0.83 0.088 0.83 art 2 0.044 0.88 0.044 0.88 ash 2 0.044 0.92 0.044 0.92 ask 2 0.044 0.96 0.044 0.96 ass 2 0.044 1.01 0.044 1.01 axe 2 0.044 1.05 0.044 1.05 babe 2 0.044 1.09 0.044 1.09 back 2 0.044 1.14 0.044 1.14 badge 2 0.044 1.18 0.044 1.18 bag 2 0.044 1.23 0.044 1.23 bail 2 0.044 1.27 0.044 1.27 bait 2 0.044 1.31 0.044 1.31 bale 2 0.044 1.36 0.044 1.36 ball 2 0.044 1.40 0.044 1.40 ban 2 0.044 1.44 0.044 1.44 band 2 0.044 1.49 0.044 1.49 bang 2 0.044 1.53 0.044 1.53 bank 2 0.044 1.58 0.044 1.58 bar 2 0.044 1.62 0.044 1.62 bard 2 0.044 1.66 0.044 1.66 barge 4 0.088 1.75 0.088 1.75 bark 4 0.088 1.84 0.088 1.84 barn 2 0.044 1.88 0.044 1.88 base 2 0.044 1.93 0.044 1.93 bash 2 0.044 1.97 0.044 1.97 bat 2 0.044 2.01 0.044 2.01 batch 2 0.044 2.06 0.044 2.06 bath 2 0.044 2.10 0.044 2.10 bay 2 0.044 2.15 0.044 2.15 beach 2 0.044 2.19 0.044 2.19 bead 2 0.044 2.23 0.044 2.23 beak 2 0.044 2.28 0.044 2.28 beam 2 0.044 2.32 0.044 2.32 bean 2 0.044 2.36 0.044 2.36 bear 4 0.088 2.45 0.088 2.45 beard 2 0.044 2.50 0.044 2.50 beast 2 0.044 2.54 0.044 2.54 beat 2 0.044 2.58 0.044 2.58 beau 2 0.044 2.63 0.044 2.63 beck 2 0.044 2.67 0.044 2.67 bed 2 0.044 2.71 0.044 2.71 bee 2 0.044 2.76 0.044 2.76 beech 2 0.044 2.80 0.044 2.80 beef 4 0.088 2.89 0.088 2.89 beep 2 0.044 2.93 0.044 2.93 beer 2 0.044 2.98 0.044 2.98 beet 2 0.044 3.02 0.044 3.02 beg 2 0.044 3.06 0.044 3.06 belch 2 0.044 3.11 0.044 3.11 bell 2 0.044 3.15 0.044 3.15 belt 2 0.044 3.20 0.044 3.20 bench 2 0.044 3.24 0.044 3.24 bend 2 0.044 3.28 0.044 3.28 berth 2 0.044 3.33 0.044 3.33 bet 2 0.044 3.37 0.044 3.37 bib 2 0.044 3.42 0.044 3.42 bid 2 0.044 3.46 0.044 3.46 bide 2 0.044 3.50 0.044 3.50 bile 2 0.044 3.55 0.044 3.55 bilge 2 0.044 3.59 0.044 3.59 bill 2 0.044 3.63 0.044 3.63 bin 2 0.044 3.68 0.044 3.68 bind 4 0.088 3.77 0.088 3.77 binge 2 0.044 3.81 0.044 3.81 birch 2 0.044 3.85 0.044 3.85 bird 2 0.044 3.90 0.044 3.90 bit 2 0.044 3.94 0.044 3.94 bitch 4 0.088 4.03 0.088 4.03 bite 2 0.044 4.07 0.044 4.07 blade 2 0.044 4.12 0.044 4.12 blame 2 0.044 4.16 0.044 4.16 blanch 2 0.044 4.20 0.044 4.20 blast 2 0.044 4.25 0.044 4.25 blaze 2 0.044 4.29 0.044 4.29 bleat 2 0.044 4.33 0.044 4.33 bleed 2 0.044 4.38 0.044 4.38 bleep 2 0.044 4.42 0.044 4.42 blend 2 0.044 4.47 0.044 4.47 bless 2 0.044 4.51 0.044 4.51 blight 2 0.044 4.55 0.044 4.55 blink 2 0.044 4.60 0.044 4.60 bliss 2 0.044 4.64 0.044 4.64 blitz 2 0.044 4.68 0.044 4.68 bloat 2 0.044 4.73 0.044 4.73 blob 2 0.044 4.77 0.044 4.77 block 2 0.044 4.82 0.044 4.82 bloke 2 0.044 4.86 0.044 4.86 blood 2 0.044 4.90 0.044 4.90 bloom 2 0.044 4.95 0.044 4.95 blot 2 0.044 4.99 0.044 4.99 blouse 2 0.044 5.04 0.044 5.04 blow 2 0.044 5.08 0.044 5.08 bluff 2 0.044 5.12 0.044 5.12 blur 2 0.044 5.17 0.044 5.17 blush 2 0.044 5.21 0.044 5.21 boar 2 0.044 5.25 0.044 5.25 board 2 0.044 5.30 0.044 5.30 boast 2 0.044 5.34 0.044 5.34 boat 2 0.044 5.39 0.044 5.39 bob 2 0.044 5.43 0.044 5.43 bog 2 0.044 5.47 0.044 5.47 boil 4 0.088 5.56 0.088 5.56 bolt 2 0.044 5.60 0.044 5.60 bomb 2 0.044 5.65 0.044 5.65 bond 2 0.044 5.69 0.044 5.69 bone 2 0.044 5.74 0.044 5.74 boo 2 0.044 5.78 0.044 5.78 book 2 0.044 5.82 0.044 5.82 boom 2 0.044 5.87 0.044 5.87 boon 2 0.044 5.91 0.044 5.91 boost 2 0.044 5.95 0.044 5.95 boot 2 0.044 6.00 0.044 6.00 booth 2 0.044 6.04 0.044 6.04 booze 2 0.044 6.09 0.044 6.09 bore 2 0.044 6.13 0.044 6.13 boss 2 0.044 6.17 0.044 6.17 bough 2 0.044 6.22 0.044 6.22 bounce 2 0.044 6.26 0.044 6.26 bound 2 0.044 6.30 0.044 6.30 bout 2 0.044 6.35 0.044 6.35 bowl 2 0.044 6.39 0.044 6.39 box 2 0.044 6.44 0.044 6.44 boy 2 0.044 6.48 0.044 6.48 brace 2 0.044 6.52 0.044 6.52 brad 2 0.044 6.57 0.044 6.57 brag 2 0.044 6.61 0.044 6.61 braid 2 0.044 6.65 0.044 6.65 brain 2 0.044 6.70 0.044 6.70 brake 2 0.044 6.74 0.044 6.74 bran 2 0.044 6.79 0.044 6.79 branch 2 0.044 6.83 0.044 6.83 brand 2 0.044 6.87 0.044 6.87 brass 2 0.044 6.92 0.044 6.92 brat 2 0.044 6.96 0.044 6.96 brawl 2 0.044 7.01 0.044 7.01 brawn 2 0.044 7.05 0.044 7.05 breach 2 0.044 7.09 0.044 7.09 bread 2 0.044 7.14 0.044 7.14 break 2 0.044 7.18 0.044 7.18 breast 2 0.044 7.22 0.044 7.22 breath 2 0.044 7.27 0.044 7.27 breed 2 0.044 7.31 0.044 7.31 breeze 2 0.044 7.36 0.044 7.36 brew 2 0.044 7.40 0.044 7.40 bribe 2 0.044 7.44 0.044 7.44 brick 2 0.044 7.49 0.044 7.49 bride 2 0.044 7.53 0.044 7.53 bridge 2 0.044 7.57 0.044 7.57 brig 2 0.044 7.62 0.044 7.62 brim 2 0.044 7.66 0.044 7.66 bring 2 0.044 7.71 0.044 7.71 brink 2 0.044 7.75 0.044 7.75 broach 2 0.044 7.79 0.044 7.79 broad 2 0.044 7.84 0.044 7.84 broil 2 0.044 7.88 0.044 7.88 bronze 2 0.044 7.92 0.044 7.92 brooch 2 0.044 7.97 0.044 7.97 brood 2 0.044 8.01 0.044 8.01 brook 4 0.088 8.10 0.088 8.10 broom 2 0.044 8.14 0.044 8.14 broth 2 0.044 8.19 0.044 8.19 brow 2 0.044 8.23 0.044 8.23 bruise 2 0.044 8.27 0.044 8.27 brunt 2 0.044 8.32 0.044 8.32 brush 2 0.044 8.36 0.044 8.36 brute 2 0.044 8.41 0.044 8.41 buck 2 0.044 8.45 0.044 8.45 bud 2 0.044 8.49 0.044 8.49 budge 2 0.044 8.54 0.044 8.54 buff 2 0.044 8.58 0.044 8.58 bug 2 0.044 8.63 0.044 8.63 build 2 0.044 8.67 0.044 8.67 bulb 2 0.044 8.71 0.044 8.71 bulge 2 0.044 8.76 0.044 8.76 bulk 2 0.044 8.80 0.044 8.80 bull 2 0.044 8.84 0.044 8.84 bum 2 0.044 8.89 0.044 8.89 bump 2 0.044 8.93 0.044 8.93 bun 2 0.044 8.98 0.044 8.98 bunch 2 0.044 9.02 0.044 9.02 bunk 2 0.044 9.06 0.044 9.06 burn 2 0.044 9.11 0.044 9.11 burr 2 0.044 9.15 0.044 9.15 burst 2 0.044 9.19 0.044 9.19 bus 2 0.044 9.24 0.044 9.24 bush 2 0.044 9.28 0.044 9.28 bust 4 0.088 9.37 0.088 9.37 butt 4 0.088 9.46 0.088 9.46 buy 2 0.044 9.50 0.044 9.50 buzz 2 0.044 9.54 0.044 9.54 cab 2 0.044 9.59 0.044 9.59 cad 2 0.044 9.63 0.044 9.63 cage 2 0.044 9.68 0.044 9.68 cake 2 0.044 9.72 0.044 9.72 calf 2 0.044 9.76 0.044 9.76 call 2 0.044 9.81 0.044 9.81 cam 2 0.044 9.85 0.044 9.85 camp 2 0.044 9.89 0.044 9.89 can 2 0.044 9.94 0.044 9.94 cane 2 0.044 9.98 0.044 9.98 cant 2 0.044 10.03 0.044 10.03 cap 2 0.044 10.07 0.044 10.07 cape 2 0.044 10.11 0.044 10.11 car 2 0.044 10.16 0.044 10.16 card 2 0.044 10.20 0.044 10.20 care 2 0.044 10.25 0.044 10.25 cart 2 0.044 10.29 0.044 10.29 carve 2 0.044 10.33 0.044 10.33 case 2 0.044 10.38 0.044 10.38 cash 2 0.044 10.42 0.044 10.42 cask 2 0.044 10.46 0.044 10.46 cast 2 0.044 10.51 0.044 10.51 caste 2 0.044 10.55 0.044 10.55 cat 2 0.044 10.60 0.044 10.60 catch 2 0.044 10.64 0.044 10.64 cause 2 0.044 10.68 0.044 10.68 cave 2 0.044 10.73 0.044 10.73 cease 2 0.044 10.77 0.044 10.77 cell 2 0.044 10.81 0.044 10.81 cent 2 0.044 10.86 0.044 10.86 chafe 2 0.044 10.90 0.044 10.90 chain 2 0.044 10.95 0.044 10.95 chair 2 0.044 10.99 0.044 10.99 chaise 2 0.044 11.03 0.044 11.03 chalk 2 0.044 11.08 0.044 11.08 champ 4 0.088 11.16 0.088 11.16 chance 2 0.044 11.21 0.044 11.21 change 2 0.044 11.25 0.044 11.25 chant 2 0.044 11.30 0.044 11.30 chap 2 0.044 11.34 0.044 11.34 char 2 0.044 11.38 0.044 11.38 charge 2 0.044 11.43 0.044 11.43 charm 2 0.044 11.47 0.044 11.47 chart 2 0.044 11.51 0.044 11.51 chase 2 0.044 11.56 0.044 11.56 chat 2 0.044 11.60 0.044 11.60 cheat 2 0.044 11.65 0.044 11.65 check 2 0.044 11.69 0.044 11.69 cheek 4 0.088 11.78 0.088 11.78 cheer 2 0.044 11.82 0.044 11.82 cheese 2 0.044 11.87 0.044 11.87 chef 2 0.044 11.91 0.044 11.91 chess 2 0.044 11.95 0.044 11.95 chest 2 0.044 12.00 0.044 12.00 chew 2 0.044 12.04 0.044 12.04 chide 2 0.044 12.08 0.044 12.08 chief 2 0.044 12.13 0.044 12.13 child 2 0.044 12.17 0.044 12.17 chime 2 0.044 12.22 0.044 12.22 chin 2 0.044 12.26 0.044 12.26 chip 2 0.044 12.30 0.044 12.30 chive 2 0.044 12.35 0.044 12.35 choice 2 0.044 12.39 0.044 12.39 choir 2 0.044 12.43 0.044 12.43 choke 2 0.044 12.48 0.044 12.48 chomp 2 0.044 12.52 0.044 12.52 choose 2 0.044 12.57 0.044 12.57 chop 4 0.088 12.65 0.088 12.65 chord 2 0.044 12.70 0.044 12.70 chore 2 0.044 12.74 0.044 12.74 chow 2 0.044 12.78 0.044 12.78 chrome 2 0.044 12.83 0.044 12.83 chuck 4 0.088 12.92 0.088 12.92 chum 2 0.044 12.96 0.044 12.96 chump 2 0.044 13.00 0.044 13.00 chunk 2 0.044 13.05 0.044 13.05 church 2 0.044 13.09 0.044 13.09 churn 2 0.044 13.13 0.044 13.13 chute 2 0.044 13.18 0.044 13.18 cinch 2 0.044 13.22 0.044 13.22 cite 2 0.044 13.27 0.044 13.27 claim 2 0.044 13.31 0.044 13.31 clam 2 0.044 13.35 0.044 13.35 clamp 2 0.044 13.40 0.044 13.40 clan 2 0.044 13.44 0.044 13.44 clang 2 0.044 13.49 0.044 13.49 clap 4 0.088 13.57 0.088 13.57 clash 2 0.044 13.62 0.044 13.62 class 2 0.044 13.66 0.044 13.66 clause 2 0.044 13.70 0.044 13.70 claw 2 0.044 13.75 0.044 13.75 clay 2 0.044 13.79 0.044 13.79 cleat 2 0.044 13.84 0.044 13.84 clench 2 0.044 13.88 0.044 13.88 clerk 2 0.044 13.92 0.044 13.92 click 2 0.044 13.97 0.044 13.97 cliff 2 0.044 14.01 0.044 14.01 climb 2 0.044 14.05 0.044 14.05 clinch 2 0.044 14.10 0.044 14.10 cling 2 0.044 14.14 0.044 14.14 clip 4 0.088 14.23 0.088 14.23 cloak 2 0.044 14.27 0.044 14.27 clock 2 0.044 14.32 0.044 14.32 clod 2 0.044 14.36 0.044 14.36 clog 2 0.044 14.40 0.044 14.40 clot 2 0.044 14.45 0.044 14.45 cloth 2 0.044 14.49 0.044 14.49 cloud 2 0.044 14.54 0.044 14.54 clout 2 0.044 14.58 0.044 14.58 clove 2 0.044 14.62 0.044 14.62 clown 2 0.044 14.67 0.044 14.67 club 2 0.044 14.71 0.044 14.71 cluck 2 0.044 14.75 0.044 14.75 clump 2 0.044 14.80 0.044 14.80 clutch 2 0.044 14.84 0.044 14.84 coach 2 0.044 14.89 0.044 14.89 coal 2 0.044 14.93 0.044 14.93 coast 2 0.044 14.97 0.044 14.97 coat 2 0.044 15.02 0.044 15.02 coax 2 0.044 15.06 0.044 15.06 cock 2 0.044 15.11 0.044 15.11 cod 4 0.088 15.19 0.088 15.19 code 2 0.044 15.24 0.044 15.24 coil 2 0.044 15.28 0.044 15.28 coin 2 0.044 15.32 0.044 15.32 coke 2 0.044 15.37 0.044 15.37 colt 2 0.044 15.41 0.044 15.41 comb 2 0.044 15.46 0.044 15.46 come 2 0.044 15.50 0.044 15.50 cone 2 0.044 15.54 0.044 15.54 cook 2 0.044 15.59 0.044 15.59 coop 2 0.044 15.63 0.044 15.63 cop 2 0.044 15.67 0.044 15.67 cope 4 0.088 15.76 0.088 15.76 cord 2 0.044 15.81 0.044 15.81 core 2 0.044 15.85 0.044 15.85 cork 2 0.044 15.89 0.044 15.89 corn 2 0.044 15.94 0.044 15.94 corps 2 0.044 15.98 0.044 15.98 corpse 2 0.044 16.02 0.044 16.02 cost 2 0.044 16.07 0.044 16.07 cot 2 0.044 16.11 0.044 16.11 couch 2 0.044 16.16 0.044 16.16 cough 2 0.044 16.20 0.044 16.20 count 4 0.088 16.29 0.088 16.29 coup 2 0.044 16.33 0.044 16.33 coupe 2 0.044 16.37 0.044 16.37 course 2 0.044 16.42 0.044 16.42 court 2 0.044 16.46 0.044 16.46 cove 2 0.044 16.51 0.044 16.51 cow 4 0.088 16.59 0.088 16.59 cowl 4 0.088 16.68 0.088 16.68 cox 2 0.044 16.73 0.044 16.73 crab 2 0.044 16.77 0.044 16.77 crack 2 0.044 16.81 0.044 16.81 craft 2 0.044 16.86 0.044 16.86 crag 2 0.044 16.90 0.044 16.90 cram 2 0.044 16.94 0.044 16.94 cramp 2 0.044 16.99 0.044 16.99 crane 2 0.044 17.03 0.044 17.03 crank 2 0.044 17.08 0.044 17.08 crap 2 0.044 17.12 0.044 17.12 crash 2 0.044 17.16 0.044 17.16 crate 2 0.044 17.21 0.044 17.21 crave 2 0.044 17.25 0.044 17.25 crawl 2 0.044 17.29 0.044 17.29 craze 4 0.088 17.38 0.088 17.38 creak 2 0.044 17.43 0.044 17.43 cream 2 0.044 17.47 0.044 17.47 crease 2 0.044 17.51 0.044 17.51 creed 2 0.044 17.56 0.044 17.56 creek 2 0.044 17.60 0.044 17.60 creep 2 0.044 17.64 0.044 17.64 crepe 2 0.044 17.69 0.044 17.69 crest 2 0.044 17.73 0.044 17.73 crew 2 0.044 17.78 0.044 17.78 crime 2 0.044 17.82 0.044 17.82 croak 2 0.044 17.86 0.044 17.86 crone 2 0.044 17.91 0.044 17.91 crook 2 0.044 17.95 0.044 17.95 croon 2 0.044 17.99 0.044 17.99 crop 2 0.044 18.04 0.044 18.04 cross 2 0.044 18.08 0.044 18.08 crouch 2 0.044 18.13 0.044 18.13 crow 4 0.088 18.21 0.088 18.21 crowd 2 0.044 18.26 0.044 18.26 crown 2 0.044 18.30 0.044 18.30 crumb 2 0.044 18.35 0.044 18.35 crunch 2 0.044 18.39 0.044 18.39 crush 2 0.044 18.43 0.044 18.43 crust 2 0.044 18.48 0.044 18.48 crutch 2 0.044 18.52 0.044 18.52 crux 2 0.044 18.56 0.044 18.56 cry 2 0.044 18.61 0.044 18.61 crypt 2 0.044 18.65 0.044 18.65 cub 2 0.044 18.70 0.044 18.70 cube 2 0.044 18.74 0.044 18.74 cud 2 0.044 18.78 0.044 18.78 cue 2 0.044 18.83 0.044 18.83 cuff 4 0.088 18.91 0.088 18.91 cull 2 0.044 18.96 0.044 18.96 cult 2 0.044 19.00 0.044 19.00 cup 2 0.044 19.05 0.044 19.05 cur 2 0.044 19.09 0.044 19.09 curb 2 0.044 19.13 0.044 19.13 curd 2 0.044 19.18 0.044 19.18 cure 4 0.088 19.26 0.088 19.26 curl 2 0.044 19.31 0.044 19.31 curse 2 0.044 19.35 0.044 19.35 curve 2 0.044 19.40 0.044 19.40 cusp 2 0.044 19.44 0.044 19.44 cut 2 0.044 19.48 0.044 19.48 cyst 2 0.044 19.53 0.044 19.53 czar 2 0.044 19.57 0.044 19.57 dad 2 0.044 19.61 0.044 19.61 dale 2 0.044 19.66 0.044 19.66 dam 2 0.044 19.70 0.044 19.70 dame 2 0.044 19.75 0.044 19.75 damn 2 0.044 19.79 0.044 19.79 damp 4 0.088 19.88 0.088 19.88 dance 2 0.044 19.92 0.044 19.92 dare 2 0.044 19.96 0.044 19.96 darn 2 0.044 20.01 0.044 20.01 dash 2 0.044 20.05 0.044 20.05 date 2 0.044 20.10 0.044 20.10 daunt 2 0.044 20.14 0.044 20.14 dawn 2 0.044 20.18 0.044 20.18 deal 2 0.044 20.23 0.044 20.23 dean 2 0.044 20.27 0.044 20.27 dearth 2 0.044 20.32 0.044 20.32 debt 2 0.044 20.36 0.044 20.36 deck 2 0.044 20.40 0.044 20.40 deed 2 0.044 20.45 0.044 20.45 deem 2 0.044 20.49 0.044 20.49 deer 2 0.044 20.53 0.044 20.53 dell 2 0.044 20.58 0.044 20.58 den 2 0.044 20.62 0.044 20.62 dent 2 0.044 20.67 0.044 20.67 desk 2 0.044 20.71 0.044 20.71 dial 2 0.044 20.75 0.044 20.75 dice 2 0.044 20.80 0.044 20.80 die 2 0.044 20.84 0.044 20.84 dig 2 0.044 20.88 0.044 20.88 dike 2 0.044 20.93 0.044 20.93 dill 2 0.044 20.97 0.044 20.97 dime 2 0.044 21.02 0.044 21.02 din 2 0.044 21.06 0.044 21.06 dine 2 0.044 21.10 0.044 21.10 dint 2 0.044 21.15 0.044 21.15 dip 2 0.044 21.19 0.044 21.19 dirge 2 0.044 21.23 0.044 21.23 dirt 2 0.044 21.28 0.044 21.28 disc 2 0.044 21.32 0.044 21.32 dish 4 0.088 21.41 0.088 21.41 ditch 2 0.044 21.45 0.044 21.45 dive 2 0.044 21.50 0.044 21.50 do 4 0.088 21.58 0.088 21.58 dock 4 0.088 21.67 0.088 21.67 dodge 2 0.044 21.72 0.044 21.72 doe 2 0.044 21.76 0.044 21.76 dog 2 0.044 21.80 0.044 21.80 dole 2 0.044 21.85 0.044 21.85 doll 2 0.044 21.89 0.044 21.89 dome 2 0.044 21.94 0.044 21.94 doom 2 0.044 21.98 0.044 21.98 door 2 0.044 22.02 0.044 22.02 dope 2 0.044 22.07 0.044 22.07 dose 2 0.044 22.11 0.044 22.11 doubt 2 0.044 22.15 0.044 22.15 dough 2 0.044 22.20 0.044 22.20 douse 2 0.044 22.24 0.044 22.24 draft 2 0.044 22.29 0.044 22.29 drag 2 0.044 22.33 0.044 22.33 drain 2 0.044 22.37 0.044 22.37 drake 2 0.044 22.42 0.044 22.42 dram 2 0.044 22.46 0.044 22.46 drape 2 0.044 22.50 0.044 22.50 draught 2 0.044 22.55 0.044 22.55 draw 2 0.044 22.59 0.044 22.59 drawl 2 0.044 22.64 0.044 22.64 dread 2 0.044 22.68 0.044 22.68 dream 2 0.044 22.72 0.044 22.72 dress 2 0.044 22.77 0.044 22.77 drift 2 0.044 22.81 0.044 22.81 drill 2 0.044 22.85 0.044 22.85 drink 2 0.044 22.90 0.044 22.90 drip 2 0.044 22.94 0.044 22.94 drive 2 0.044 22.99 0.044 22.99 drone 2 0.044 23.03 0.044 23.03 droop 2 0.044 23.07 0.044 23.07 drop 2 0.044 23.12 0.044 23.12 dross 2 0.044 23.16 0.044 23.16 drought 2 0.044 23.20 0.044 23.20 drove 2 0.044 23.25 0.044 23.25 drown 2 0.044 23.29 0.044 23.29 drum 2 0.044 23.34 0.044 23.34 duck 4 0.088 23.42 0.088 23.42 duct 2 0.044 23.47 0.044 23.47 dud 2 0.044 23.51 0.044 23.51 duel 2 0.044 23.56 0.044 23.56 dug 2 0.044 23.60 0.044 23.60 duke 2 0.044 23.64 0.044 23.64 dump 2 0.044 23.69 0.044 23.69 dun 2 0.044 23.73 0.044 23.73 dune 2 0.044 23.77 0.044 23.77 dung 2 0.044 23.82 0.044 23.82 dunk 2 0.044 23.86 0.044 23.86 dusk 2 0.044 23.91 0.044 23.91 dust 2 0.044 23.95 0.044 23.95 dwarf 2 0.044 23.99 0.044 23.99 dwell 2 0.044 24.04 0.044 24.04 ear 2 0.044 24.08 0.044 24.08 earl 2 0.044 24.12 0.044 24.12 earn 2 0.044 24.17 0.044 24.17 earth 2 0.044 24.21 0.044 24.21 ease 2 0.044 24.26 0.044 24.26 east 2 0.044 24.30 0.044 24.30 eat 2 0.044 24.34 0.044 24.34 ebb 2 0.044 24.39 0.044 24.39 edge 2 0.044 24.43 0.044 24.43 eel 2 0.044 24.47 0.044 24.47 egg 2 0.044 24.52 0.044 24.52 elk 2 0.044 24.56 0.044 24.56 elm 2 0.044 24.61 0.044 24.61 end 2 0.044 24.65 0.044 24.65 err 2 0.044 24.69 0.044 24.69 eve 2 0.044 24.74 0.044 24.74 ewe 2 0.044 24.78 0.044 24.78 face 2 0.044 24.82 0.044 24.82 fact 2 0.044 24.87 0.044 24.87 fad 2 0.044 24.91 0.044 24.91 fade 2 0.044 24.96 0.044 24.96 fail 2 0.044 25.00 0.044 25.00 fair 2 0.044 25.04 0.044 25.04 faith 2 0.044 25.09 0.044 25.09 fake 2 0.044 25.13 0.044 25.13 fame 2 0.044 25.18 0.044 25.18 fan 2 0.044 25.22 0.044 25.22 fang 2 0.044 25.26 0.044 25.26 farce 2 0.044 25.31 0.044 25.31 fare 4 0.088 25.39 0.088 25.39 farm 2 0.044 25.44 0.044 25.44 fast 2 0.044 25.48 0.044 25.48 fate 2 0.044 25.53 0.044 25.53 fault 2 0.044 25.57 0.044 25.57 fawn 4 0.088 25.66 0.088 25.66 faze 2 0.044 25.70 0.044 25.70 fear 2 0.044 25.74 0.044 25.74 feast 2 0.044 25.79 0.044 25.79 feat 2 0.044 25.83 0.044 25.83 fee 2 0.044 25.88 0.044 25.88 feed 2 0.044 25.92 0.044 25.92 feel 2 0.044 25.96 0.044 25.96 feint 2 0.044 26.01 0.044 26.01 fell 4 0.088 26.09 0.088 26.09 fen 2 0.044 26.14 0.044 26.14 fence 2 0.044 26.18 0.044 26.18 fern 2 0.044 26.23 0.044 26.23 fetch 2 0.044 26.27 0.044 26.27 feud 2 0.044 26.31 0.044 26.31 fiend 2 0.044 26.36 0.044 26.36 fife 2 0.044 26.40 0.044 26.40 fig 2 0.044 26.44 0.044 26.44 fight 2 0.044 26.49 0.044 26.49 file 2 0.044 26.53 0.044 26.53 fill 2 0.044 26.58 0.044 26.58 film 2 0.044 26.62 0.044 26.62 filth 2 0.044 26.66 0.044 26.66 fin 2 0.044 26.71 0.044 26.71 find 2 0.044 26.75 0.044 26.75 fine 2 0.044 26.80 0.044 26.80 fink 2 0.044 26.84 0.044 26.84 fir 2 0.044 26.88 0.044 26.88 fire 2 0.044 26.93 0.044 26.93 firm 2 0.044 26.97 0.044 26.97 fish 2 0.044 27.01 0.044 27.01 fist 2 0.044 27.06 0.044 27.06 fix 2 0.044 27.10 0.044 27.10 flag 2 0.044 27.15 0.044 27.15 flail 2 0.044 27.19 0.044 27.19 flair 2 0.044 27.23 0.044 27.23 flake 2 0.044 27.28 0.044 27.28 flame 2 0.044 27.32 0.044 27.32 flange 2 0.044 27.36 0.044 27.36 flank 2 0.044 27.41 0.044 27.41 flare 2 0.044 27.45 0.044 27.45 flask 2 0.044 27.50 0.044 27.50 flaw 2 0.044 27.54 0.044 27.54 flax 2 0.044 27.58 0.044 27.58 flea 2 0.044 27.63 0.044 27.63 fleck 2 0.044 27.67 0.044 27.67 flee 2 0.044 27.71 0.044 27.71 fleet 4 0.088 27.80 0.088 27.80 flesh 2 0.044 27.85 0.044 27.85 flex 4 0.088 27.93 0.088 27.93 flick 2 0.044 27.98 0.044 27.98 flight 2 0.044 28.02 0.044 28.02 fling 2 0.044 28.06 0.044 28.06 flint 2 0.044 28.11 0.044 28.11 flip 2 0.044 28.15 0.044 28.15 flirt 2 0.044 28.20 0.044 28.20 float 2 0.044 28.24 0.044 28.24 flock 2 0.044 28.28 0.044 28.28 floe 2 0.044 28.33 0.044 28.33 flog 2 0.044 28.37 0.044 28.37 flood 2 0.044 28.42 0.044 28.42 floor 2 0.044 28.46 0.044 28.46 flop 2 0.044 28.50 0.044 28.50 flour 2 0.044 28.55 0.044 28.55 flow 2 0.044 28.59 0.044 28.59 fluff 2 0.044 28.63 0.044 28.63 fluke 2 0.044 28.68 0.044 28.68 flush 2 0.044 28.72 0.044 28.72 flute 2 0.044 28.77 0.044 28.77 flux 2 0.044 28.81 0.044 28.81 fly 4 0.088 28.90 0.088 28.90 foal 2 0.044 28.94 0.044 28.94 foam 2 0.044 28.98 0.044 28.98 foe 2 0.044 29.03 0.044 29.03 fog 2 0.044 29.07 0.044 29.07 foil 4 0.088 29.16 0.088 29.16 fold 2 0.044 29.20 0.044 29.20 folk 2 0.044 29.25 0.044 29.25 font 2 0.044 29.29 0.044 29.29 food 2 0.044 29.33 0.044 29.33 fool 2 0.044 29.38 0.044 29.38 foot 2 0.044 29.42 0.044 29.42 force 2 0.044 29.47 0.044 29.47 ford 2 0.044 29.51 0.044 29.51 forge 2 0.044 29.55 0.044 29.55 fork 2 0.044 29.60 0.044 29.60 form 2 0.044 29.64 0.044 29.64 fort 2 0.044 29.68 0.044 29.68 found 2 0.044 29.73 0.044 29.73 fowl 2 0.044 29.77 0.044 29.77 fox 2 0.044 29.82 0.044 29.82 frame 2 0.044 29.86 0.044 29.86 fraud 2 0.044 29.90 0.044 29.90 fray 2 0.044 29.95 0.044 29.95 freak 2 0.044 29.99 0.044 29.99 freeze 2 0.044 30.04 0.044 30.04 freight 2 0.044 30.08 0.044 30.08 fret 4 0.088 30.17 0.088 30.17 friend 2 0.044 30.21 0.044 30.21 frieze 2 0.044 30.25 0.044 30.25 fright 2 0.044 30.30 0.044 30.30 frill 2 0.044 30.34 0.044 30.34 fringe 2 0.044 30.39 0.044 30.39 frock 2 0.044 30.43 0.044 30.43 frog 2 0.044 30.47 0.044 30.47 front 2 0.044 30.52 0.044 30.52 frost 2 0.044 30.56 0.044 30.56 froth 2 0.044 30.60 0.044 30.60 frown 2 0.044 30.65 0.044 30.65 fruit 2 0.044 30.69 0.044 30.69 fry 4 0.088 30.78 0.088 30.78 fuel 2 0.044 30.82 0.044 30.82 full 2 0.044 30.87 0.044 30.87 fun 2 0.044 30.91 0.044 30.91 fund 2 0.044 30.95 0.044 30.95 funk 2 0.044 31.00 0.044 31.00 fur 2 0.044 31.04 0.044 31.04 fuse 2 0.044 31.09 0.044 31.09 fuss 2 0.044 31.13 0.044 31.13 fuzz 2 0.044 31.17 0.044 31.17 gab 2 0.044 31.22 0.044 31.22 gag 2 0.044 31.26 0.044 31.26 gain 2 0.044 31.30 0.044 31.30 gait 2 0.044 31.35 0.044 31.35 gal 2 0.044 31.39 0.044 31.39 gale 2 0.044 31.44 0.044 31.44 gall 2 0.044 31.48 0.044 31.48 game 2 0.044 31.52 0.044 31.52 gang 2 0.044 31.57 0.044 31.57 gap 2 0.044 31.61 0.044 31.61 garb 2 0.044 31.65 0.044 31.65 gas 2 0.044 31.70 0.044 31.70 gash 2 0.044 31.74 0.044 31.74 gasp 2 0.044 31.79 0.044 31.79 gate 2 0.044 31.83 0.044 31.83 gauge 2 0.044 31.87 0.044 31.87 gauze 2 0.044 31.92 0.044 31.92 gay 2 0.044 31.96 0.044 31.96 gaze 2 0.044 32.01 0.044 32.01 gear 2 0.044 32.05 0.044 32.05 gel 2 0.044 32.09 0.044 32.09 gem 2 0.044 32.14 0.044 32.14 gene 2 0.044 32.18 0.044 32.18 get 2 0.044 32.22 0.044 32.22 ghost 2 0.044 32.27 0.044 32.27 ghoul 2 0.044 32.31 0.044 32.31 gibe 2 0.044 32.36 0.044 32.36 gift 2 0.044 32.40 0.044 32.40 gig 2 0.044 32.44 0.044 32.44 gill 2 0.044 32.49 0.044 32.49 gilt 2 0.044 32.53 0.044 32.53 gin 2 0.044 32.57 0.044 32.57 gird 2 0.044 32.62 0.044 32.62 girl 2 0.044 32.66 0.044 32.66 gist 2 0.044 32.71 0.044 32.71 give 2 0.044 32.75 0.044 32.75 glance 2 0.044 32.79 0.044 32.79 gland 2 0.044 32.84 0.044 32.84 glare 2 0.044 32.88 0.044 32.88 glass 2 0.044 32.92 0.044 32.92 glaze 2 0.044 32.97 0.044 32.97 gleam 2 0.044 33.01 0.044 33.01 glean 2 0.044 33.06 0.044 33.06 glee 2 0.044 33.10 0.044 33.10 glen 2 0.044 33.14 0.044 33.14 glide 2 0.044 33.19 0.044 33.19 glimpse 2 0.044 33.23 0.044 33.23 glint 2 0.044 33.27 0.044 33.27 gloat 2 0.044 33.32 0.044 33.32 globe 2 0.044 33.36 0.044 33.36 gloom 2 0.044 33.41 0.044 33.41 gloss 2 0.044 33.45 0.044 33.45 glove 2 0.044 33.49 0.044 33.49 glow 2 0.044 33.54 0.044 33.54 glue 2 0.044 33.58 0.044 33.58 gnaw 2 0.044 33.63 0.044 33.63 gnome 2 0.044 33.67 0.044 33.67 go 2 0.044 33.71 0.044 33.71 goad 2 0.044 33.76 0.044 33.76 goal 2 0.044 33.80 0.044 33.80 goat 2 0.044 33.84 0.044 33.84 gob 2 0.044 33.89 0.044 33.89 god 2 0.044 33.93 0.044 33.93 gold 2 0.044 33.98 0.044 33.98 golf 2 0.044 34.02 0.044 34.02 gong 2 0.044 34.06 0.044 34.06 goon 2 0.044 34.11 0.044 34.11 goose 2 0.044 34.15 0.044 34.15 gore 4 0.088 34.24 0.088 34.24 gouge 2 0.044 34.28 0.044 34.28 gourd 2 0.044 34.33 0.044 34.33 gout 2 0.044 34.37 0.044 34.37 gown 2 0.044 34.41 0.044 34.41 grab 2 0.044 34.46 0.044 34.46 grace 2 0.044 34.50 0.044 34.50 grade 2 0.044 34.54 0.044 34.54 graft 2 0.044 34.59 0.044 34.59 grail 2 0.044 34.63 0.044 34.63 grain 2 0.044 34.68 0.044 34.68 gram 2 0.044 34.72 0.044 34.72 grant 2 0.044 34.76 0.044 34.76 grape 2 0.044 34.81 0.044 34.81 graph 2 0.044 34.85 0.044 34.85 grasp 2 0.044 34.89 0.044 34.89 grass 2 0.044 34.94 0.044 34.94 grate 4 0.088 35.03 0.088 35.03 grave 2 0.044 35.07 0.044 35.07 graze 2 0.044 35.11 0.044 35.11 grease 2 0.044 35.16 0.044 35.16 greed 2 0.044 35.20 0.044 35.20 greet 2 0.044 35.25 0.044 35.25 grid 2 0.044 35.29 0.044 35.29 grill 2 0.044 35.33 0.044 35.33 grille 2 0.044 35.38 0.044 35.38 grime 2 0.044 35.42 0.044 35.42 grin 2 0.044 35.46 0.044 35.46 grind 2 0.044 35.51 0.044 35.51 grip 2 0.044 35.55 0.044 35.55 gripe 2 0.044 35.60 0.044 35.60 grist 2 0.044 35.64 0.044 35.64 grit 2 0.044 35.68 0.044 35.68 groan 2 0.044 35.73 0.044 35.73 groin 2 0.044 35.77 0.044 35.77 groom 2 0.044 35.81 0.044 35.81 groove 2 0.044 35.86 0.044 35.86 grope 2 0.044 35.90 0.044 35.90 grouch 2 0.044 35.95 0.044 35.95 ground 2 0.044 35.99 0.044 35.99 group 2 0.044 36.03 0.044 36.03 grouse 2 0.044 36.08 0.044 36.08 grove 2 0.044 36.12 0.044 36.12 grow 2 0.044 36.16 0.044 36.16 growl 2 0.044 36.21 0.044 36.21 grub 4 0.088 36.30 0.088 36.30 grudge 2 0.044 36.34 0.044 36.34 grunt 2 0.044 36.38 0.044 36.38 guard 2 0.044 36.43 0.044 36.43 guess 2 0.044 36.47 0.044 36.47 guest 2 0.044 36.51 0.044 36.51 guide 2 0.044 36.56 0.044 36.56 guild 2 0.044 36.60 0.044 36.60 guile 2 0.044 36.65 0.044 36.65 guilt 2 0.044 36.69 0.044 36.69 guise 2 0.044 36.73 0.044 36.73 gulf 2 0.044 36.78 0.044 36.78 gull 2 0.044 36.82 0.044 36.82 gulp 2 0.044 36.87 0.044 36.87 gum 2 0.044 36.91 0.044 36.91 gun 2 0.044 36.95 0.044 36.95 gush 2 0.044 37.00 0.044 37.00 gust 2 0.044 37.04 0.044 37.04 gut 2 0.044 37.08 0.044 37.08 guy 2 0.044 37.13 0.044 37.13 gyp 2 0.044 37.17 0.044 37.17 hack 2 0.044 37.22 0.044 37.22 hag 2 0.044 37.26 0.044 37.26 hail 4 0.088 37.35 0.088 37.35 hair 2 0.044 37.39 0.044 37.39 hall 2 0.044 37.43 0.044 37.43 halt 2 0.044 37.48 0.044 37.48 ham 2 0.044 37.52 0.044 37.52 hand 2 0.044 37.57 0.044 37.57 hang 2 0.044 37.61 0.044 37.61 hank 2 0.044 37.65 0.044 37.65 hark 2 0.044 37.70 0.044 37.70 harm 2 0.044 37.74 0.044 37.74 harp 2 0.044 37.78 0.044 37.78 hart 2 0.044 37.83 0.044 37.83 hash 2 0.044 37.87 0.044 37.87 haste 2 0.044 37.92 0.044 37.92 hat 2 0.044 37.96 0.044 37.96 hatch 4 0.088 38.05 0.088 38.05 hate 2 0.044 38.09 0.044 38.09 haul 2 0.044 38.13 0.044 38.13 haunt 2 0.044 38.18 0.044 38.18 have 2 0.044 38.22 0.044 38.22 haw 4 0.088 38.31 0.088 38.31 hawk 4 0.088 38.40 0.088 38.40 hay 2 0.044 38.44 0.044 38.44 haze 4 0.088 38.53 0.088 38.53 head 2 0.044 38.57 0.044 38.57 heal 2 0.044 38.62 0.044 38.62 heap 2 0.044 38.66 0.044 38.66 hear 2 0.044 38.70 0.044 38.70 heart 2 0.044 38.75 0.044 38.75 hearth 2 0.044 38.79 0.044 38.79 heat 2 0.044 38.84 0.044 38.84 heave 2 0.044 38.88 0.044 38.88 heck 2 0.044 38.92 0.044 38.92 hedge 2 0.044 38.97 0.044 38.97 heed 2 0.044 39.01 0.044 39.01 heel 2 0.044 39.05 0.044 39.05 height 2 0.044 39.10 0.044 39.10 heir 2 0.044 39.14 0.044 39.14 hell 2 0.044 39.19 0.044 39.19 helm 2 0.044 39.23 0.044 39.23 help 2 0.044 39.27 0.044 39.27 hem 2 0.044 39.32 0.044 39.32 hen 2 0.044 39.36 0.044 39.36 herb 2 0.044 39.40 0.044 39.40 herd 2 0.044 39.45 0.044 39.45 hick 2 0.044 39.49 0.044 39.49 hide 4 0.088 39.58 0.088 39.58 hike 2 0.044 39.62 0.044 39.62 hill 2 0.044 39.67 0.044 39.67 hilt 2 0.044 39.71 0.044 39.71 hind 2 0.044 39.75 0.044 39.75 hinge 2 0.044 39.80 0.044 39.80 hint 2 0.044 39.84 0.044 39.84 hip 2 0.044 39.89 0.044 39.89 hire 2 0.044 39.93 0.044 39.93 hiss 2 0.044 39.97 0.044 39.97 hit 2 0.044 40.02 0.044 40.02 hitch 2 0.044 40.06 0.044 40.06 hive 2 0.044 40.11 0.044 40.11 hob 2 0.044 40.15 0.044 40.15 hoe 2 0.044 40.19 0.044 40.19 hog 4 0.088 40.28 0.088 40.28 hoist 2 0.044 40.32 0.044 40.32 hold 2 0.044 40.37 0.044 40.37 hole 2 0.044 40.41 0.044 40.41 home 2 0.044 40.46 0.044 40.46 hone 2 0.044 40.50 0.044 40.50 hooch 2 0.044 40.54 0.044 40.54 hood 2 0.044 40.59 0.044 40.59 hoof 2 0.044 40.63 0.044 40.63 hook 2 0.044 40.67 0.044 40.67 hoop 2 0.044 40.72 0.044 40.72 hoot 2 0.044 40.76 0.044 40.76 hop 2 0.044 40.81 0.044 40.81 hope 2 0.044 40.85 0.044 40.85 horn 2 0.044 40.89 0.044 40.89 horse 2 0.044 40.94 0.044 40.94 hose 2 0.044 40.98 0.044 40.98 host 2 0.044 41.02 0.044 41.02 hound 2 0.044 41.07 0.044 41.07 hour 2 0.044 41.11 0.044 41.11 house 2 0.044 41.16 0.044 41.16 howl 2 0.044 41.20 0.044 41.20 hub 2 0.044 41.24 0.044 41.24 hue 2 0.044 41.29 0.044 41.29 huff 2 0.044 41.33 0.044 41.33 hug 2 0.044 41.37 0.044 41.37 hulk 2 0.044 41.42 0.044 41.42 hull 2 0.044 41.46 0.044 41.46 hum 2 0.044 41.51 0.044 41.51 hump 2 0.044 41.55 0.044 41.55 hunch 2 0.044 41.59 0.044 41.59 hunk 2 0.044 41.64 0.044 41.64 hunt 2 0.044 41.68 0.044 41.68 hurl 2 0.044 41.73 0.044 41.73 hurt 2 0.044 41.77 0.044 41.77 hush 2 0.044 41.81 0.044 41.81 hut 2 0.044 41.86 0.044 41.86 hymn 2 0.044 41.90 0.044 41.90 ice 2 0.044 41.94 0.044 41.94 inch 2 0.044 41.99 0.044 41.99 ink 2 0.044 42.03 0.044 42.03 inn 2 0.044 42.08 0.044 42.08 ire 2 0.044 42.12 0.044 42.12 isle 2 0.044 42.16 0.044 42.16 itch 2 0.044 42.21 0.044 42.21 jab 2 0.044 42.25 0.044 42.25 jack 2 0.044 42.29 0.044 42.29 jade 2 0.044 42.34 0.044 42.34 jag 2 0.044 42.38 0.044 42.38 jail 2 0.044 42.43 0.044 42.43 jam 2 0.044 42.47 0.044 42.47 jape 2 0.044 42.51 0.044 42.51 jar 2 0.044 42.56 0.044 42.56 jaw 2 0.044 42.60 0.044 42.60 jazz 2 0.044 42.64 0.044 42.64 jeep 2 0.044 42.69 0.044 42.69 jeer 2 0.044 42.73 0.044 42.73 jerk 2 0.044 42.78 0.044 42.78 jest 2 0.044 42.82 0.044 42.82 jet 2 0.044 42.86 0.044 42.86 jig 2 0.044 42.91 0.044 42.91 job 2 0.044 42.95 0.044 42.95 jog 2 0.044 42.99 0.044 42.99 join 2 0.044 43.04 0.044 43.04 joke 2 0.044 43.08 0.044 43.08 jolt 2 0.044 43.13 0.044 43.13 jot 2 0.044 43.17 0.044 43.17 joust 2 0.044 43.21 0.044 43.21 jowl 2 0.044 43.26 0.044 43.26 joy 2 0.044 43.30 0.044 43.30 judge 2 0.044 43.35 0.044 43.35 jug 2 0.044 43.39 0.044 43.39 juice 2 0.044 43.43 0.044 43.43 jump 2 0.044 43.48 0.044 43.48 junk 2 0.044 43.52 0.044 43.52 jute 2 0.044 43.56 0.044 43.56 kale 2 0.044 43.61 0.044 43.61 keel 2 0.044 43.65 0.044 43.65 keen 2 0.044 43.70 0.044 43.70 keep 2 0.044 43.74 0.044 43.74 keg 2 0.044 43.78 0.044 43.78 kelp 2 0.044 43.83 0.044 43.83 ken 2 0.044 43.87 0.044 43.87 key 2 0.044 43.91 0.044 43.91 kick 2 0.044 43.96 0.044 43.96 kid 4 0.088 44.05 0.088 44.05 kill 2 0.044 44.09 0.044 44.09 kilt 2 0.044 44.13 0.044 44.13 kin 2 0.044 44.18 0.044 44.18 kind 2 0.044 44.22 0.044 44.22 king 2 0.044 44.26 0.044 44.26 kiss 2 0.044 44.31 0.044 44.31 kit 2 0.044 44.35 0.044 44.35 kite 2 0.044 44.40 0.044 44.40 knack 2 0.044 44.44 0.044 44.44 knead 2 0.044 44.48 0.044 44.48 knee 2 0.044 44.53 0.044 44.53 kneel 2 0.044 44.57 0.044 44.57 knife 2 0.044 44.61 0.044 44.61 knight 2 0.044 44.66 0.044 44.66 knit 2 0.044 44.70 0.044 44.70 knob 2 0.044 44.75 0.044 44.75 knock 2 0.044 44.79 0.044 44.79 knoll 2 0.044 44.83 0.044 44.83 knot 2 0.044 44.88 0.044 44.88 know 2 0.044 44.92 0.044 44.92 lace 2 0.044 44.96 0.044 44.96 lack 2 0.044 45.01 0.044 45.01 lad 2 0.044 45.05 0.044 45.05 lag 2 0.044 45.10 0.044 45.10 lake 2 0.044 45.14 0.044 45.14 lamb 2 0.044 45.18 0.044 45.18 lame 2 0.044 45.23 0.044 45.23 lamp 2 0.044 45.27 0.044 45.27 lance 4 0.088 45.36 0.088 45.36 land 2 0.044 45.40 0.044 45.40 lane 2 0.044 45.45 0.044 45.45 lap 4 0.088 45.53 0.088 45.53 lapse 2 0.044 45.58 0.044 45.58 lard 2 0.044 45.62 0.044 45.62 lark 2 0.044 45.67 0.044 45.67 lash 2 0.044 45.71 0.044 45.71 lass 2 0.044 45.75 0.044 45.75 last 2 0.044 45.80 0.044 45.80 latch 2 0.044 45.84 0.044 45.84 lath 2 0.044 45.88 0.044 45.88 lathe 2 0.044 45.93 0.044 45.93 laugh 2 0.044 45.97 0.044 45.97 launch 4 0.088 46.06 0.088 46.06 law 2 0.044 46.10 0.044 46.10 lawn 2 0.044 46.15 0.044 46.15 lay 2 0.044 46.19 0.044 46.19 laze 2 0.044 46.23 0.044 46.23 leaf 2 0.044 46.28 0.044 46.28 leak 2 0.044 46.32 0.044 46.32 lean 2 0.044 46.37 0.044 46.37 leap 2 0.044 46.41 0.044 46.41 learn 2 0.044 46.45 0.044 46.45 lease 2 0.044 46.50 0.044 46.50 leash 2 0.044 46.54 0.044 46.54 leave 4 0.088 46.63 0.088 46.63 ledge 2 0.044 46.67 0.044 46.67 lee 2 0.044 46.72 0.044 46.72 leg 2 0.044 46.76 0.044 46.76 lend 2 0.044 46.80 0.044 46.80 lens 2 0.044 46.85 0.044 46.85 let 2 0.044 46.89 0.044 46.89 lick 2 0.044 46.94 0.044 46.94 lid 2 0.044 46.98 0.044 46.98 lie 2 0.044 47.02 0.044 47.02 life 2 0.044 47.07 0.044 47.07 lift 2 0.044 47.11 0.044 47.11 light 2 0.044 47.15 0.044 47.15 like 2 0.044 47.20 0.044 47.20 lilt 2 0.044 47.24 0.044 47.24 limb 2 0.044 47.29 0.044 47.29 lime 2 0.044 47.33 0.044 47.33 limp 2 0.044 47.37 0.044 47.37 line 2 0.044 47.42 0.044 47.42 link 2 0.044 47.46 0.044 47.46 lint 2 0.044 47.50 0.044 47.50 lip 2 0.044 47.55 0.044 47.55 lisle 2 0.044 47.59 0.044 47.59 list 4 0.088 47.68 0.088 47.68 load 2 0.044 47.72 0.044 47.72 loaf 4 0.088 47.81 0.088 47.81 loan 2 0.044 47.85 0.044 47.85 lob 2 0.044 47.90 0.044 47.90 lobe 2 0.044 47.94 0.044 47.94 lock 2 0.044 47.99 0.044 47.99 lodge 2 0.044 48.03 0.044 48.03 loft 2 0.044 48.07 0.044 48.07 log 2 0.044 48.12 0.044 48.12 loin 2 0.044 48.16 0.044 48.16 look 2 0.044 48.20 0.044 48.20 loom 4 0.088 48.29 0.088 48.29 loon 2 0.044 48.34 0.044 48.34 loop 2 0.044 48.38 0.044 48.38 loot 2 0.044 48.42 0.044 48.42 lop 2 0.044 48.47 0.044 48.47 lope 2 0.044 48.51 0.044 48.51 lord 2 0.044 48.56 0.044 48.56 lore 2 0.044 48.60 0.044 48.60 lose 2 0.044 48.64 0.044 48.64 loss 2 0.044 48.69 0.044 48.69 lot 2 0.044 48.73 0.044 48.73 lounge 2 0.044 48.77 0.044 48.77 louse 2 0.044 48.82 0.044 48.82 love 2 0.044 48.86 0.044 48.86 low 2 0.044 48.91 0.044 48.91 luck 2 0.044 48.95 0.044 48.95 lug 4 0.088 49.04 0.088 49.04 lull 2 0.044 49.08 0.044 49.08 lump 4 0.088 49.17 0.088 49.17 lung 2 0.044 49.21 0.044 49.21 lurch 2 0.044 49.26 0.044 49.26 lure 2 0.044 49.30 0.044 49.30 lurk 2 0.044 49.34 0.044 49.34 lust 2 0.044 49.39 0.044 49.39 lute 2 0.044 49.43 0.044 49.43 lye 2 0.044 49.47 0.044 49.47 lymph 2 0.044 49.52 0.044 49.52 lynch 2 0.044 49.56 0.044 49.56 maid 2 0.044 49.61 0.044 49.61 mail 2 0.044 49.65 0.044 49.65 make 2 0.044 49.69 0.044 49.69 mall 2 0.044 49.74 0.044 49.74 malt 2 0.044 49.78 0.044 49.78 man 2 0.044 49.82 0.044 49.82 mane 2 0.044 49.87 0.044 49.87 manse 2 0.044 49.91 0.044 49.91 map 2 0.044 49.96 0.044 49.96 mar 2 0.044 50.00 0.044 50.00 march 4 0.088 50.09 0.088 50.09 mare 2 0.044 50.13 0.044 50.13 mark 2 0.044 50.18 0.044 50.18 marsh 2 0.044 50.22 0.044 50.22 mart 2 0.044 50.26 0.044 50.26 mash 2 0.044 50.31 0.044 50.31 mask 2 0.044 50.35 0.044 50.35 mass 2 0.044 50.39 0.044 50.39 mast 2 0.044 50.44 0.044 50.44 mat 2 0.044 50.48 0.044 50.48 match 2 0.044 50.53 0.044 50.53 mate 2 0.044 50.57 0.044 50.57 maw 2 0.044 50.61 0.044 50.61 may 2 0.044 50.66 0.044 50.66 maze 2 0.044 50.70 0.044 50.70 mead 2 0.044 50.74 0.044 50.74 meal 2 0.044 50.79 0.044 50.79 mean 2 0.044 50.83 0.044 50.83 meat 2 0.044 50.88 0.044 50.88 meet 2 0.044 50.92 0.044 50.92 meld 2 0.044 50.96 0.044 50.96 melt 2 0.044 51.01 0.044 51.01 mend 2 0.044 51.05 0.044 51.05 merge 2 0.044 51.09 0.044 51.09 mesh 2 0.044 51.14 0.044 51.14 mess 2 0.044 51.18 0.044 51.18 mew 2 0.044 51.23 0.044 51.23 might 2 0.044 51.27 0.044 51.27 mile 2 0.044 51.31 0.044 51.31 milk 2 0.044 51.36 0.044 51.36 mill 2 0.044 51.40 0.044 51.40 mime 2 0.044 51.44 0.044 51.44 mince 2 0.044 51.49 0.044 51.49 mind 2 0.044 51.53 0.044 51.53 mine 2 0.044 51.58 0.044 51.58 mink 2 0.044 51.62 0.044 51.62 mint 2 0.044 51.66 0.044 51.66 mirth 2 0.044 51.71 0.044 51.71 miss 2 0.044 51.75 0.044 51.75 mist 2 0.044 51.80 0.044 51.80 mite 2 0.044 51.84 0.044 51.84 mitt 2 0.044 51.88 0.044 51.88 mix 2 0.044 51.93 0.044 51.93 moan 2 0.044 51.97 0.044 51.97 mob 2 0.044 52.01 0.044 52.01 mock 2 0.044 52.06 0.044 52.06 mode 2 0.044 52.10 0.044 52.10 mole 2 0.044 52.15 0.044 52.15 moll 2 0.044 52.19 0.044 52.19 mom 2 0.044 52.23 0.044 52.23 monk 2 0.044 52.28 0.044 52.28 month 2 0.044 52.32 0.044 52.32 moo 2 0.044 52.36 0.044 52.36 mood 2 0.044 52.41 0.044 52.41 moon 2 0.044 52.45 0.044 52.45 moose 2 0.044 52.50 0.044 52.50 moot 2 0.044 52.54 0.044 52.54 mop 2 0.044 52.58 0.044 52.58 moss 2 0.044 52.63 0.044 52.63 moth 2 0.044 52.67 0.044 52.67 mould 2 0.044 52.71 0.044 52.71 mount 2 0.044 52.76 0.044 52.76 mourn 2 0.044 52.80 0.044 52.80 mouse 2 0.044 52.85 0.044 52.85 mouth 2 0.044 52.89 0.044 52.89 move 2 0.044 52.93 0.044 52.93 mow 2 0.044 52.98 0.044 52.98 muck 2 0.044 53.02 0.044 53.02 mud 2 0.044 53.06 0.044 53.06 muff 2 0.044 53.11 0.044 53.11 mug 2 0.044 53.15 0.044 53.15 mulch 2 0.044 53.20 0.044 53.20 mule 2 0.044 53.24 0.044 53.24 mum 2 0.044 53.28 0.044 53.28 munch 2 0.044 53.33 0.044 53.33 muse 2 0.044 53.37 0.044 53.37 mush 2 0.044 53.42 0.044 53.42 must 2 0.044 53.46 0.044 53.46 myth 2 0.044 53.50 0.044 53.50 nab 2 0.044 53.55 0.044 53.55 nail 2 0.044 53.59 0.044 53.59 name 2 0.044 53.63 0.044 53.63 nap 2 0.044 53.68 0.044 53.68 nape 2 0.044 53.72 0.044 53.72 naught 2 0.044 53.77 0.044 53.77 neck 2 0.044 53.81 0.044 53.81 need 2 0.044 53.85 0.044 53.85 nerve 2 0.044 53.90 0.044 53.90 nest 2 0.044 53.94 0.044 53.94 news 2 0.044 53.98 0.044 53.98 newt 2 0.044 54.03 0.044 54.03 nick 2 0.044 54.07 0.044 54.07 niece 2 0.044 54.12 0.044 54.12 night 2 0.044 54.16 0.044 54.16 nil 2 0.044 54.20 0.044 54.20 nip 2 0.044 54.25 0.044 54.25 nod 2 0.044 54.29 0.044 54.29 node 2 0.044 54.33 0.044 54.33 noise 2 0.044 54.38 0.044 54.38 nonce 2 0.044 54.42 0.044 54.42 nook 2 0.044 54.47 0.044 54.47 noon 2 0.044 54.51 0.044 54.51 noose 2 0.044 54.55 0.044 54.55 norm 2 0.044 54.60 0.044 54.60 north 2 0.044 54.64 0.044 54.64 nose 2 0.044 54.68 0.044 54.68 notch 2 0.044 54.73 0.044 54.73 note 2 0.044 54.77 0.044 54.77 noun 2 0.044 54.82 0.044 54.82 nudge 2 0.044 54.86 0.044 54.86 nun 2 0.044 54.90 0.044 54.90 nurse 2 0.044 54.95 0.044 54.95 nut 2 0.044 54.99 0.044 54.99 nymph 2 0.044 55.04 0.044 55.04 oak 2 0.044 55.08 0.044 55.08 oath 2 0.044 55.12 0.044 55.12 oil 2 0.044 55.17 0.044 55.17 ooze 2 0.044 55.21 0.044 55.21 orb 2 0.044 55.25 0.044 55.25 ore 2 0.044 55.30 0.044 55.30 ought 2 0.044 55.34 0.044 55.34 ounce 2 0.044 55.39 0.044 55.39 oust 2 0.044 55.43 0.044 55.43 owl 2 0.044 55.47 0.044 55.47 pace 2 0.044 55.52 0.044 55.52 pack 2 0.044 55.56 0.044 55.56 pact 2 0.044 55.60 0.044 55.60 pad 2 0.044 55.65 0.044 55.65 page 2 0.044 55.69 0.044 55.69 pail 2 0.044 55.74 0.044 55.74 pain 2 0.044 55.78 0.044 55.78 paint 2 0.044 55.82 0.044 55.82 pair 2 0.044 55.87 0.044 55.87 pal 2 0.044 55.91 0.044 55.91 pale 2 0.044 55.95 0.044 55.95 pall 4 0.088 56.04 0.088 56.04 palm 2 0.044 56.09 0.044 56.09 pan 2 0.044 56.13 0.044 56.13 pane 2 0.044 56.17 0.044 56.17 pang 2 0.044 56.22 0.044 56.22 pant 2 0.044 56.26 0.044 56.26 pap 2 0.044 56.30 0.044 56.30 par 2 0.044 56.35 0.044 56.35 pare 2 0.044 56.39 0.044 56.39 park 2 0.044 56.44 0.044 56.44 part 2 0.044 56.48 0.044 56.48 pass 2 0.044 56.52 0.044 56.52 paste 2 0.044 56.57 0.044 56.57 pat 2 0.044 56.61 0.044 56.61 patch 2 0.044 56.65 0.044 56.65 pate 2 0.044 56.70 0.044 56.70 path 2 0.044 56.74 0.044 56.74 paunch 2 0.044 56.79 0.044 56.79 pause 2 0.044 56.83 0.044 56.83 pave 2 0.044 56.87 0.044 56.87 paw 2 0.044 56.92 0.044 56.92 pawn 2 0.044 56.96 0.044 56.96 pay 2 0.044 57.01 0.044 57.01 pea 2 0.044 57.05 0.044 57.05 peace 2 0.044 57.09 0.044 57.09 peach 2 0.044 57.14 0.044 57.14 peak 2 0.044 57.18 0.044 57.18 peal 2 0.044 57.22 0.044 57.22 pear 2 0.044 57.27 0.044 57.27 pearl 2 0.044 57.31 0.044 57.31 peat 2 0.044 57.36 0.044 57.36 peck 2 0.044 57.40 0.044 57.40 pee 2 0.044 57.44 0.044 57.44 peel 2 0.044 57.49 0.044 57.49 peep 2 0.044 57.53 0.044 57.53 peer 4 0.088 57.62 0.088 57.62 peg 2 0.044 57.66 0.044 57.66 pelt 4 0.088 57.75 0.088 57.75 pen 2 0.044 57.79 0.044 57.79 perch 2 0.044 57.84 0.044 57.84 perk 2 0.044 57.88 0.044 57.88 pest 2 0.044 57.92 0.044 57.92 pet 2 0.044 57.97 0.044 57.97 pew 2 0.044 58.01 0.044 58.01 phase 2 0.044 58.06 0.044 58.06 phrase 2 0.044 58.10 0.044 58.10 pick 2 0.044 58.14 0.044 58.14 pie 2 0.044 58.19 0.044 58.19 piece 2 0.044 58.23 0.044 58.23 pier 2 0.044 58.27 0.044 58.27 pierce 2 0.044 58.32 0.044 58.32 pig 2 0.044 58.36 0.044 58.36 pike 2 0.044 58.41 0.044 58.41 pile 2 0.044 58.45 0.044 58.45 pill 2 0.044 58.49 0.044 58.49 pimp 2 0.044 58.54 0.044 58.54 pin 2 0.044 58.58 0.044 58.58 pinch 2 0.044 58.63 0.044 58.63 pine 4 0.088 58.71 0.088 58.71 pint 2 0.044 58.76 0.044 58.76 pip 2 0.044 58.80 0.044 58.80 pipe 2 0.044 58.84 0.044 58.84 piss 2 0.044 58.89 0.044 58.89 pit 2 0.044 58.93 0.044 58.93 pitch 2 0.044 58.98 0.044 58.98 pith 2 0.044 59.02 0.044 59.02 place 2 0.044 59.06 0.044 59.06 plaid 2 0.044 59.11 0.044 59.11 plain 2 0.044 59.15 0.044 59.15 plan 2 0.044 59.19 0.044 59.19 plane 2 0.044 59.24 0.044 59.24 plank 2 0.044 59.28 0.044 59.28 plant 2 0.044 59.33 0.044 59.33 plate 2 0.044 59.37 0.044 59.37 play 2 0.044 59.41 0.044 59.41 plea 2 0.044 59.46 0.044 59.46 plead 2 0.044 59.50 0.044 59.50 please 2 0.044 59.54 0.044 59.54 pleat 2 0.044 59.59 0.044 59.59 pledge 2 0.044 59.63 0.044 59.63 plod 2 0.044 59.68 0.044 59.68 plot 2 0.044 59.72 0.044 59.72 plough 2 0.044 59.76 0.044 59.76 pluck 2 0.044 59.81 0.044 59.81 plug 2 0.044 59.85 0.044 59.85 plum 2 0.044 59.89 0.044 59.89 plume 2 0.044 59.94 0.044 59.94 plunge 2 0.044 59.98 0.044 59.98 plush 2 0.044 60.03 0.044 60.03 poach 2 0.044 60.07 0.044 60.07 pod 2 0.044 60.11 0.044 60.11 point 2 0.044 60.16 0.044 60.16 poise 2 0.044 60.20 0.044 60.20 poke 2 0.044 60.25 0.044 60.25 pole 2 0.044 60.29 0.044 60.29 poll 2 0.044 60.33 0.044 60.33 pomp 2 0.044 60.38 0.044 60.38 pond 2 0.044 60.42 0.044 60.42 pool 2 0.044 60.46 0.044 60.46 pop 2 0.044 60.51 0.044 60.51 pope 2 0.044 60.55 0.044 60.55 porch 2 0.044 60.60 0.044 60.60 pore 2 0.044 60.64 0.044 60.64 pork 2 0.044 60.68 0.044 60.68 port 2 0.044 60.73 0.044 60.73 pose 2 0.044 60.77 0.044 60.77 post 2 0.044 60.81 0.044 60.81 pot 2 0.044 60.86 0.044 60.86 pouch 2 0.044 60.90 0.044 60.90 pound 4 0.088 60.99 0.088 60.99 pour 2 0.044 61.03 0.044 61.03 pout 2 0.044 61.08 0.044 61.08 praise 2 0.044 61.12 0.044 61.12 prank 2 0.044 61.16 0.044 61.16 pray 2 0.044 61.21 0.044 61.21 preach 2 0.044 61.25 0.044 61.25 prep 2 0.044 61.30 0.044 61.30 press 2 0.044 61.34 0.044 61.34 prey 2 0.044 61.38 0.044 61.38 price 2 0.044 61.43 0.044 61.43 prick 2 0.044 61.47 0.044 61.47 pride 2 0.044 61.51 0.044 61.51 priest 2 0.044 61.56 0.044 61.56 prime 2 0.044 61.60 0.044 61.60 prince 2 0.044 61.65 0.044 61.65 print 2 0.044 61.69 0.044 61.69 prize 2 0.044 61.73 0.044 61.73 probe 2 0.044 61.78 0.044 61.78 prod 2 0.044 61.82 0.044 61.82 prop 2 0.044 61.87 0.044 61.87 prose 2 0.044 61.91 0.044 61.91 prove 2 0.044 61.95 0.044 61.95 prow 2 0.044 62.00 0.044 62.00 prowl 2 0.044 62.04 0.044 62.04 pry 2 0.044 62.08 0.044 62.08 psalm 2 0.044 62.13 0.044 62.13 pub 2 0.044 62.17 0.044 62.17 puck 2 0.044 62.22 0.044 62.22 puff 2 0.044 62.26 0.044 62.26 puke 2 0.044 62.30 0.044 62.30 pull 2 0.044 62.35 0.044 62.35 pulp 2 0.044 62.39 0.044 62.39 pulse 2 0.044 62.43 0.044 62.43 pump 2 0.044 62.48 0.044 62.48 pun 2 0.044 62.52 0.044 62.52 punch 2 0.044 62.57 0.044 62.57 punk 2 0.044 62.61 0.044 62.61 punt 2 0.044 62.65 0.044 62.65 pup 2 0.044 62.70 0.044 62.70 purge 2 0.044 62.74 0.044 62.74 purse 2 0.044 62.78 0.044 62.78 pus 2 0.044 62.83 0.044 62.83 push 2 0.044 62.87 0.044 62.87 put 2 0.044 62.92 0.044 62.92 putt 2 0.044 62.96 0.044 62.96 pyre 2 0.044 63.00 0.044 63.00 quack 2 0.044 63.05 0.044 63.05 quake 2 0.044 63.09 0.044 63.09 quart 2 0.044 63.13 0.044 63.13 quartz 2 0.044 63.18 0.044 63.18 quay 2 0.044 63.22 0.044 63.22 queen 2 0.044 63.27 0.044 63.27 quell 2 0.044 63.31 0.044 63.31 quench 2 0.044 63.35 0.044 63.35 quest 2 0.044 63.40 0.044 63.40 queue 2 0.044 63.44 0.044 63.44 quill 2 0.044 63.49 0.044 63.49 quince 2 0.044 63.53 0.044 63.53 quirk 2 0.044 63.57 0.044 63.57 quiz 2 0.044 63.62 0.044 63.62 quote 2 0.044 63.66 0.044 63.66 race 2 0.044 63.70 0.044 63.70 rack 2 0.044 63.75 0.044 63.75 raft 2 0.044 63.79 0.044 63.79 rag 2 0.044 63.84 0.044 63.84 rage 2 0.044 63.88 0.044 63.88 raid 2 0.044 63.92 0.044 63.92 rail 2 0.044 63.97 0.044 63.97 rain 2 0.044 64.01 0.044 64.01 raise 2 0.044 64.05 0.044 64.05 rake 2 0.044 64.10 0.044 64.10 ram 2 0.044 64.14 0.044 64.14 ranch 2 0.044 64.19 0.044 64.19 range 2 0.044 64.23 0.044 64.23 rank 2 0.044 64.27 0.044 64.27 rant 2 0.044 64.32 0.044 64.32 rap 2 0.044 64.36 0.044 64.36 rape 2 0.044 64.40 0.044 64.40 rash 2 0.044 64.45 0.044 64.45 rasp 2 0.044 64.49 0.044 64.49 rat 2 0.044 64.54 0.044 64.54 rate 2 0.044 64.58 0.044 64.58 rave 2 0.044 64.62 0.044 64.62 ray 2 0.044 64.67 0.044 64.67 reach 2 0.044 64.71 0.044 64.71 realm 2 0.044 64.75 0.044 64.75 ream 2 0.044 64.80 0.044 64.80 reap 2 0.044 64.84 0.044 64.84 rear 2 0.044 64.89 0.044 64.89 reed 2 0.044 64.93 0.044 64.93 reef 2 0.044 64.97 0.044 64.97 reek 2 0.044 65.02 0.044 65.02 reel 2 0.044 65.06 0.044 65.06 reign 2 0.044 65.11 0.044 65.11 rein 2 0.044 65.15 0.044 65.15 rend 2 0.044 65.19 0.044 65.19 rent 2 0.044 65.24 0.044 65.24 rest 2 0.044 65.28 0.044 65.28 retch 2 0.044 65.32 0.044 65.32 rhyme 2 0.044 65.37 0.044 65.37 rib 2 0.044 65.41 0.044 65.41 rice 2 0.044 65.46 0.044 65.46 ride 2 0.044 65.50 0.044 65.50 ridge 2 0.044 65.54 0.044 65.54 rift 2 0.044 65.59 0.044 65.59 rig 2 0.044 65.63 0.044 65.63 right 2 0.044 65.67 0.044 65.67 rile 2 0.044 65.72 0.044 65.72 rim 2 0.044 65.76 0.044 65.76 rime 2 0.044 65.81 0.044 65.81 rind 2 0.044 65.85 0.044 65.85 ring 4 0.088 65.94 0.088 65.94 rink 2 0.044 65.98 0.044 65.98 rinse 2 0.044 66.02 0.044 66.02 rip 2 0.044 66.07 0.044 66.07 rise 2 0.044 66.11 0.044 66.11 risk 2 0.044 66.16 0.044 66.16 rite 2 0.044 66.20 0.044 66.20 roach 2 0.044 66.24 0.044 66.24 road 2 0.044 66.29 0.044 66.29 roam 2 0.044 66.33 0.044 66.33 roar 2 0.044 66.37 0.044 66.37 roast 2 0.044 66.42 0.044 66.42 rob 2 0.044 66.46 0.044 66.46 robe 2 0.044 66.51 0.044 66.51 rock 4 0.088 66.59 0.088 66.59 rod 2 0.044 66.64 0.044 66.64 roe 2 0.044 66.68 0.044 66.68 role 2 0.044 66.73 0.044 66.73 roll 2 0.044 66.77 0.044 66.77 romp 2 0.044 66.81 0.044 66.81 roof 2 0.044 66.86 0.044 66.86 rook 2 0.044 66.90 0.044 66.90 room 2 0.044 66.94 0.044 66.94 roost 2 0.044 66.99 0.044 66.99 root 2 0.044 67.03 0.044 67.03 rope 2 0.044 67.08 0.044 67.08 rose 2 0.044 67.12 0.044 67.12 rot 2 0.044 67.16 0.044 67.16 rouse 2 0.044 67.21 0.044 67.21 rout 2 0.044 67.25 0.044 67.25 rove 2 0.044 67.29 0.044 67.29 rub 2 0.044 67.34 0.044 67.34 rue 2 0.044 67.38 0.044 67.38 rug 2 0.044 67.43 0.044 67.43 rule 2 0.044 67.47 0.044 67.47 rum 2 0.044 67.51 0.044 67.51 rump 2 0.044 67.56 0.044 67.56 run 2 0.044 67.60 0.044 67.60 rung 2 0.044 67.64 0.044 67.64 runt 2 0.044 67.69 0.044 67.69 ruse 2 0.044 67.73 0.044 67.73 rush 2 0.044 67.78 0.044 67.78 rust 2 0.044 67.82 0.044 67.82 rut 2 0.044 67.86 0.044 67.86 rye 2 0.044 67.91 0.044 67.91 sack 2 0.044 67.95 0.044 67.95 sag 2 0.044 67.99 0.044 67.99 sail 2 0.044 68.04 0.044 68.04 saint 2 0.044 68.08 0.044 68.08 sake 2 0.044 68.13 0.044 68.13 sale 2 0.044 68.17 0.044 68.17 salt 2 0.044 68.21 0.044 68.21 salve 2 0.044 68.26 0.044 68.26 sand 2 0.044 68.30 0.044 68.30 sap 2 0.044 68.35 0.044 68.35 sash 2 0.044 68.39 0.044 68.39 sauce 2 0.044 68.43 0.044 68.43 save 2 0.044 68.48 0.044 68.48 saw 2 0.044 68.52 0.044 68.52 sax 2 0.044 68.56 0.044 68.56 say 2 0.044 68.61 0.044 68.61 scald 2 0.044 68.65 0.044 68.65 scale 2 0.044 68.70 0.044 68.70 scalp 2 0.044 68.74 0.044 68.74 scan 2 0.044 68.78 0.044 68.78 scar 2 0.044 68.83 0.044 68.83 scare 2 0.044 68.87 0.044 68.87 scarf 2 0.044 68.91 0.044 68.91 scene 2 0.044 68.96 0.044 68.96 scent 2 0.044 69.00 0.044 69.00 scheme 2 0.044 69.05 0.044 69.05 school 2 0.044 69.09 0.044 69.09 scoop 2 0.044 69.13 0.044 69.13 scope 2 0.044 69.18 0.044 69.18 score 2 0.044 69.22 0.044 69.22 scorn 2 0.044 69.26 0.044 69.26 scotch 2 0.044 69.31 0.044 69.31 scour 2 0.044 69.35 0.044 69.35 scourge 2 0.044 69.40 0.044 69.40 scout 2 0.044 69.44 0.044 69.44 scrap 2 0.044 69.48 0.044 69.48 scrape 2 0.044 69.53 0.044 69.53 scratch 2 0.044 69.57 0.044 69.57 scream 2 0.044 69.61 0.044 69.61 screech 2 0.044 69.66 0.044 69.66 screen 2 0.044 69.70 0.044 69.70 screw 2 0.044 69.75 0.044 69.75 scribe 4 0.088 69.83 0.088 69.83 script 2 0.044 69.88 0.044 69.88 scrub 2 0.044 69.92 0.044 69.92 scuff 2 0.044 69.96 0.044 69.96 sea 2 0.044 70.01 0.044 70.01 seal 2 0.044 70.05 0.044 70.05 seam 2 0.044 70.10 0.044 70.10 sear 2 0.044 70.14 0.044 70.14 search 2 0.044 70.18 0.044 70.18 seat 2 0.044 70.23 0.044 70.23 sect 2 0.044 70.27 0.044 70.27 see 2 0.044 70.32 0.044 70.32 seed 2 0.044 70.36 0.044 70.36 seek 2 0.044 70.40 0.044 70.40 seem 2 0.044 70.45 0.044 70.45 seep 2 0.044 70.49 0.044 70.49 seize 2 0.044 70.53 0.044 70.53 self 2 0.044 70.58 0.044 70.58 sell 2 0.044 70.62 0.044 70.62 send 2 0.044 70.67 0.044 70.67 sense 2 0.044 70.71 0.044 70.71 serf 2 0.044 70.75 0.044 70.75 serge 2 0.044 70.80 0.044 70.80 serve 2 0.044 70.84 0.044 70.84 set 4 0.088 70.93 0.088 70.93 sew 2 0.044 70.97 0.044 70.97 sex 2 0.044 71.02 0.044 71.02 shack 2 0.044 71.06 0.044 71.06 shade 2 0.044 71.10 0.044 71.10 shaft 2 0.044 71.15 0.044 71.15 shag 4 0.088 71.23 0.088 71.23 shah 2 0.044 71.28 0.044 71.28 shake 2 0.044 71.32 0.044 71.32 shall 2 0.044 71.37 0.044 71.37 sham 2 0.044 71.41 0.044 71.41 shame 2 0.044 71.45 0.044 71.45 shank 2 0.044 71.50 0.044 71.50 shape 2 0.044 71.54 0.044 71.54 shard 2 0.044 71.58 0.044 71.58 share 2 0.044 71.63 0.044 71.63 shark 2 0.044 71.67 0.044 71.67 shave 2 0.044 71.72 0.044 71.72 shawl 2 0.044 71.76 0.044 71.76 shay 2 0.044 71.80 0.044 71.80 sheaf 2 0.044 71.85 0.044 71.85 shear 2 0.044 71.89 0.044 71.89 sheath 2 0.044 71.94 0.044 71.94 shed 4 0.088 72.02 0.088 72.02 sheen 2 0.044 72.07 0.044 72.07 sheep 2 0.044 72.11 0.044 72.11 sheer 2 0.044 72.15 0.044 72.15 sheet 2 0.044 72.20 0.044 72.20 shelf 2 0.044 72.24 0.044 72.24 shell 2 0.044 72.29 0.044 72.29 shield 2 0.044 72.33 0.044 72.33 shift 2 0.044 72.37 0.044 72.37 shin 2 0.044 72.42 0.044 72.42 shine 2 0.044 72.46 0.044 72.46 ship 2 0.044 72.50 0.044 72.50 shirt 2 0.044 72.55 0.044 72.55 shoal 2 0.044 72.59 0.044 72.59 shock 2 0.044 72.64 0.044 72.64 shoe 2 0.044 72.68 0.044 72.68 shoot 2 0.044 72.72 0.044 72.72 shop 2 0.044 72.77 0.044 72.77 shore 2 0.044 72.81 0.044 72.81 shot 2 0.044 72.85 0.044 72.85 should 2 0.044 72.90 0.044 72.90 shout 2 0.044 72.94 0.044 72.94 shove 2 0.044 72.99 0.044 72.99 show 2 0.044 73.03 0.044 73.03 shred 2 0.044 73.07 0.044 73.07 shrimp 2 0.044 73.12 0.044 73.12 shrine 2 0.044 73.16 0.044 73.16 shrink 2 0.044 73.20 0.044 73.20 shrub 2 0.044 73.25 0.044 73.25 shrug 2 0.044 73.29 0.044 73.29 shuck 2 0.044 73.34 0.044 73.34 shun 2 0.044 73.38 0.044 73.38 shunt 2 0.044 73.42 0.044 73.42 shut 2 0.044 73.47 0.044 73.47 side 2 0.044 73.51 0.044 73.51 siege 2 0.044 73.56 0.044 73.56 sigh 2 0.044 73.60 0.044 73.60 sight 2 0.044 73.64 0.044 73.64 sign 2 0.044 73.69 0.044 73.69 silk 2 0.044 73.73 0.044 73.73 sill 2 0.044 73.77 0.044 73.77 sin 2 0.044 73.82 0.044 73.82 sine 2 0.044 73.86 0.044 73.86 sing 2 0.044 73.91 0.044 73.91 sink 2 0.044 73.95 0.044 73.95 sip 2 0.044 73.99 0.044 73.99 sir 2 0.044 74.04 0.044 74.04 sit 2 0.044 74.08 0.044 74.08 site 2 0.044 74.12 0.044 74.12 size 2 0.044 74.17 0.044 74.17 skate 2 0.044 74.21 0.044 74.21 skeet 2 0.044 74.26 0.044 74.26 sketch 2 0.044 74.30 0.044 74.30 ski 2 0.044 74.34 0.044 74.34 skid 2 0.044 74.39 0.044 74.39 skiff 2 0.044 74.43 0.044 74.43 skill 2 0.044 74.47 0.044 74.47 skin 2 0.044 74.52 0.044 74.52 skip 2 0.044 74.56 0.044 74.56 skirt 2 0.044 74.61 0.044 74.61 skit 2 0.044 74.65 0.044 74.65 skulk 2 0.044 74.69 0.044 74.69 skull 2 0.044 74.74 0.044 74.74 skunk 2 0.044 74.78 0.044 74.78 sky 2 0.044 74.82 0.044 74.82 slab 2 0.044 74.87 0.044 74.87 slam 2 0.044 74.91 0.044 74.91 slang 2 0.044 74.96 0.044 74.96 slant 2 0.044 75.00 0.044 75.00 slap 2 0.044 75.04 0.044 75.04 slash 2 0.044 75.09 0.044 75.09 slat 2 0.044 75.13 0.044 75.13 slate 2 0.044 75.18 0.044 75.18 slave 2 0.044 75.22 0.044 75.22 sleep 2 0.044 75.26 0.044 75.26 sleeve 2 0.044 75.31 0.044 75.31 slice 2 0.044 75.35 0.044 75.35 slide 2 0.044 75.39 0.044 75.39 slip 2 0.044 75.44 0.044 75.44 slit 2 0.044 75.48 0.044 75.48 slob 2 0.044 75.53 0.044 75.53 sloe 2 0.044 75.57 0.044 75.57 sloop 2 0.044 75.61 0.044 75.61 slop 2 0.044 75.66 0.044 75.66 slope 2 0.044 75.70 0.044 75.70 slot 2 0.044 75.74 0.044 75.74 slouch 2 0.044 75.79 0.044 75.79 slough 2 0.044 75.83 0.044 75.83 sludge 2 0.044 75.88 0.044 75.88 slug 2 0.044 75.92 0.044 75.92 sluice 2 0.044 75.96 0.044 75.96 slum 2 0.044 76.01 0.044 76.01 slump 2 0.044 76.05 0.044 76.05 smack 2 0.044 76.09 0.044 76.09 smart 2 0.044 76.14 0.044 76.14 smash 2 0.044 76.18 0.044 76.18 smear 2 0.044 76.23 0.044 76.23 smell 2 0.044 76.27 0.044 76.27 smelt 4 0.088 76.36 0.088 76.36 smile 2 0.044 76.40 0.044 76.40 smirk 2 0.044 76.44 0.044 76.44 smoke 2 0.044 76.49 0.044 76.49 snack 2 0.044 76.53 0.044 76.53 snag 2 0.044 76.58 0.044 76.58 snail 2 0.044 76.62 0.044 76.62 snake 2 0.044 76.66 0.044 76.66 snap 2 0.044 76.71 0.044 76.71 snare 2 0.044 76.75 0.044 76.75 snatch 2 0.044 76.80 0.044 76.80 sneak 2 0.044 76.84 0.044 76.84 sneer 2 0.044 76.88 0.044 76.88 sniff 2 0.044 76.93 0.044 76.93 snip 2 0.044 76.97 0.044 76.97 snob 2 0.044 77.01 0.044 77.01 snoop 2 0.044 77.06 0.044 77.06 snort 2 0.044 77.10 0.044 77.10 snout 2 0.044 77.15 0.044 77.15 snow 2 0.044 77.19 0.044 77.19 snug 2 0.044 77.23 0.044 77.23 soak 2 0.044 77.28 0.044 77.28 soap 2 0.044 77.32 0.044 77.32 sob 2 0.044 77.36 0.044 77.36 sock 2 0.044 77.41 0.044 77.41 sod 2 0.044 77.45 0.044 77.45 sole 2 0.044 77.50 0.044 77.50 solve 2 0.044 77.54 0.044 77.54 son 2 0.044 77.58 0.044 77.58 song 2 0.044 77.63 0.044 77.63 soot 2 0.044 77.67 0.044 77.67 soothe 2 0.044 77.71 0.044 77.71 sop 2 0.044 77.76 0.044 77.76 sort 2 0.044 77.80 0.044 77.80 soul 2 0.044 77.85 0.044 77.85 sound 2 0.044 77.89 0.044 77.89 soup 2 0.044 77.93 0.044 77.93 source 2 0.044 77.98 0.044 77.98 south 2 0.044 78.02 0.044 78.02 soy 2 0.044 78.06 0.044 78.06 spa 2 0.044 78.11 0.044 78.11 space 2 0.044 78.15 0.044 78.15 spade 2 0.044 78.20 0.044 78.20 span 2 0.044 78.24 0.044 78.24 spare 2 0.044 78.28 0.044 78.28 spark 2 0.044 78.33 0.044 78.33 spat 2 0.044 78.37 0.044 78.37 spate 2 0.044 78.42 0.044 78.42 speak 2 0.044 78.46 0.044 78.46 spear 2 0.044 78.50 0.044 78.50 speck 2 0.044 78.55 0.044 78.55 speech 2 0.044 78.59 0.044 78.59 speed 2 0.044 78.63 0.044 78.63 spell 4 0.088 78.72 0.088 78.72 spend 2 0.044 78.77 0.044 78.77 sphere 2 0.044 78.81 0.044 78.81 sphinx 2 0.044 78.85 0.044 78.85 spice 2 0.044 78.90 0.044 78.90 spike 2 0.044 78.94 0.044 78.94 spill 2 0.044 78.98 0.044 78.98 spin 2 0.044 79.03 0.044 79.03 spine 2 0.044 79.07 0.044 79.07 spire 2 0.044 79.12 0.044 79.12 spit 4 0.088 79.20 0.088 79.20 spite 2 0.044 79.25 0.044 79.25 splash 2 0.044 79.29 0.044 79.29 spleen 2 0.044 79.33 0.044 79.33 splice 2 0.044 79.38 0.044 79.38 split 2 0.044 79.42 0.044 79.42 splurge 2 0.044 79.47 0.044 79.47 spoil 2 0.044 79.51 0.044 79.51 spoke 2 0.044 79.55 0.044 79.55 spoof 2 0.044 79.60 0.044 79.60 spool 2 0.044 79.64 0.044 79.64 spoon 2 0.044 79.68 0.044 79.68 sport 2 0.044 79.73 0.044 79.73 spot 2 0.044 79.77 0.044 79.77 spouse 2 0.044 79.82 0.044 79.82 spout 2 0.044 79.86 0.044 79.86 sprawl 2 0.044 79.90 0.044 79.90 spray 2 0.044 79.95 0.044 79.95 spread 2 0.044 79.99 0.044 79.99 spree 2 0.044 80.04 0.044 80.04 sprig 2 0.044 80.08 0.044 80.08 spring 2 0.044 80.12 0.044 80.12 sprite 2 0.044 80.17 0.044 80.17 sprout 2 0.044 80.21 0.044 80.21 spur 2 0.044 80.25 0.044 80.25 spurt 2 0.044 80.30 0.044 80.30 spy 2 0.044 80.34 0.044 80.34 squad 2 0.044 80.39 0.044 80.39 squall 2 0.044 80.43 0.044 80.43 square 2 0.044 80.47 0.044 80.47 squash 4 0.088 80.56 0.088 80.56 squat 2 0.044 80.60 0.044 80.60 squaw 2 0.044 80.65 0.044 80.65 squawk 2 0.044 80.69 0.044 80.69 squeak 2 0.044 80.74 0.044 80.74 squeal 2 0.044 80.78 0.044 80.78 squeeze 2 0.044 80.82 0.044 80.82 squint 2 0.044 80.87 0.044 80.87 squire 2 0.044 80.91 0.044 80.91 squirm 2 0.044 80.95 0.044 80.95 squirt 2 0.044 81.00 0.044 81.00 stab 2 0.044 81.04 0.044 81.04 stack 2 0.044 81.09 0.044 81.09 staff 2 0.044 81.13 0.044 81.13 stag 2 0.044 81.17 0.044 81.17 stage 2 0.044 81.22 0.044 81.22 stain 2 0.044 81.26 0.044 81.26 stair 2 0.044 81.30 0.044 81.30 stake 2 0.044 81.35 0.044 81.35 stalk 2 0.044 81.39 0.044 81.39 stall 2 0.044 81.44 0.044 81.44 stamp 2 0.044 81.48 0.044 81.48 stance 2 0.044 81.52 0.044 81.52 stanch 2 0.044 81.57 0.044 81.57 stand 2 0.044 81.61 0.044 81.61 star 2 0.044 81.65 0.044 81.65 starch 2 0.044 81.70 0.044 81.70 stare 2 0.044 81.74 0.044 81.74 start 2 0.044 81.79 0.044 81.79 starve 2 0.044 81.83 0.044 81.83 state 4 0.088 81.92 0.088 81.92 staunch 2 0.044 81.96 0.044 81.96 stave 2 0.044 82.01 0.044 82.01 stay 2 0.044 82.05 0.044 82.05 stead 2 0.044 82.09 0.044 82.09 steak 2 0.044 82.14 0.044 82.14 steal 2 0.044 82.18 0.044 82.18 steam 2 0.044 82.22 0.044 82.22 steed 2 0.044 82.27 0.044 82.27 steel 2 0.044 82.31 0.044 82.31 steer 4 0.088 82.40 0.088 82.40 stem 2 0.044 82.44 0.044 82.44 stench 2 0.044 82.49 0.044 82.49 step 2 0.044 82.53 0.044 82.53 stew 2 0.044 82.57 0.044 82.57 stick 2 0.044 82.62 0.044 82.62 still 2 0.044 82.66 0.044 82.66 stilt 2 0.044 82.71 0.044 82.71 sting 2 0.044 82.75 0.044 82.75 stink 2 0.044 82.79 0.044 82.79 stint 2 0.044 82.84 0.044 82.84 stir 2 0.044 82.88 0.044 82.88 stitch 2 0.044 82.92 0.044 82.92 stock 2 0.044 82.97 0.044 82.97 stole 2 0.044 83.01 0.044 83.01 stone 2 0.044 83.06 0.044 83.06 stool 2 0.044 83.10 0.044 83.10 stoop 2 0.044 83.14 0.044 83.14 stop 2 0.044 83.19 0.044 83.19 store 2 0.044 83.23 0.044 83.23 stork 2 0.044 83.27 0.044 83.27 storm 2 0.044 83.32 0.044 83.32 stout 2 0.044 83.36 0.044 83.36 stove 2 0.044 83.41 0.044 83.41 stow 2 0.044 83.45 0.044 83.45 strafe 2 0.044 83.49 0.044 83.49 strain 2 0.044 83.54 0.044 83.54 strand 4 0.088 83.63 0.088 83.63 strap 2 0.044 83.67 0.044 83.67 straw 2 0.044 83.71 0.044 83.71 stray 2 0.044 83.76 0.044 83.76 streak 2 0.044 83.80 0.044 83.80 stream 2 0.044 83.84 0.044 83.84 street 2 0.044 83.89 0.044 83.89 stress 2 0.044 83.93 0.044 83.93 stretch 2 0.044 83.98 0.044 83.98 stride 2 0.044 84.02 0.044 84.02 strife 2 0.044 84.06 0.044 84.06 strike 2 0.044 84.11 0.044 84.11 string 2 0.044 84.15 0.044 84.15 strip 2 0.044 84.19 0.044 84.19 stripe 2 0.044 84.24 0.044 84.24 strive 2 0.044 84.28 0.044 84.28 stroke 2 0.044 84.33 0.044 84.33 stroll 2 0.044 84.37 0.044 84.37 strut 2 0.044 84.41 0.044 84.41 stub 2 0.044 84.46 0.044 84.46 stud 2 0.044 84.50 0.044 84.50 stuff 2 0.044 84.54 0.044 84.54 stump 2 0.044 84.59 0.044 84.59 stunt 4 0.088 84.68 0.088 84.68 style 2 0.044 84.72 0.044 84.72 sub 2 0.044 84.76 0.044 84.76 suck 2 0.044 84.81 0.044 84.81 sue 2 0.044 84.85 0.044 84.85 suit 2 0.044 84.89 0.044 84.89 suite 2 0.044 84.94 0.044 84.94 sulk 2 0.044 84.98 0.044 84.98 sum 2 0.044 85.03 0.044 85.03 sun 2 0.044 85.07 0.044 85.07 sup 2 0.044 85.11 0.044 85.11 surf 2 0.044 85.16 0.044 85.16 surge 2 0.044 85.20 0.044 85.20 swamp 2 0.044 85.25 0.044 85.25 swan 2 0.044 85.29 0.044 85.29 swap 2 0.044 85.33 0.044 85.33 swarm 2 0.044 85.38 0.044 85.38 swath 2 0.044 85.42 0.044 85.42 sway 2 0.044 85.46 0.044 85.46 swear 2 0.044 85.51 0.044 85.51 sweat 2 0.044 85.55 0.044 85.55 sweep 2 0.044 85.60 0.044 85.60 swell 2 0.044 85.64 0.044 85.64 swerve 2 0.044 85.68 0.044 85.68 swig 2 0.044 85.73 0.044 85.73 swim 2 0.044 85.77 0.044 85.77 swine 2 0.044 85.81 0.044 85.81 swing 2 0.044 85.86 0.044 85.86 swipe 2 0.044 85.90 0.044 85.90 swirl 2 0.044 85.95 0.044 85.95 switch 2 0.044 85.99 0.044 85.99 swoop 2 0.044 86.03 0.044 86.03 sword 2 0.044 86.08 0.044 86.08 tab 2 0.044 86.12 0.044 86.12 tack 2 0.044 86.16 0.044 86.16 tact 2 0.044 86.21 0.044 86.21 tag 2 0.044 86.25 0.044 86.25 tail 2 0.044 86.30 0.044 86.30 taint 2 0.044 86.34 0.044 86.34 take 2 0.044 86.38 0.044 86.38 tale 2 0.044 86.43 0.044 86.43 talk 2 0.044 86.47 0.044 86.47 tamp 2 0.044 86.51 0.044 86.51 tan 2 0.044 86.56 0.044 86.56 tang 2 0.044 86.60 0.044 86.60 tank 2 0.044 86.65 0.044 86.65 tape 2 0.044 86.69 0.044 86.69 tar 2 0.044 86.73 0.044 86.73 tart 2 0.044 86.78 0.044 86.78 task 2 0.044 86.82 0.044 86.82 taste 2 0.044 86.87 0.044 86.87 taunt 2 0.044 86.91 0.044 86.91 tax 2 0.044 86.95 0.044 86.95 tea 2 0.044 87.00 0.044 87.00 teach 2 0.044 87.04 0.044 87.04 teak 2 0.044 87.08 0.044 87.08 team 2 0.044 87.13 0.044 87.13 tease 2 0.044 87.17 0.044 87.17 tech 2 0.044 87.22 0.044 87.22 tee 2 0.044 87.26 0.044 87.26 teens 2 0.044 87.30 0.044 87.30 tell 2 0.044 87.35 0.044 87.35 tempt 2 0.044 87.39 0.044 87.39 tend 2 0.044 87.43 0.044 87.43 tense 2 0.044 87.48 0.044 87.48 tent 2 0.044 87.52 0.044 87.52 test 2 0.044 87.57 0.044 87.57 text 2 0.044 87.61 0.044 87.61 thank 2 0.044 87.65 0.044 87.65 thaw 2 0.044 87.70 0.044 87.70 theft 2 0.044 87.74 0.044 87.74 theme 2 0.044 87.78 0.044 87.78 thief 2 0.044 87.83 0.044 87.83 thigh 2 0.044 87.87 0.044 87.87 thin 2 0.044 87.92 0.044 87.92 thing 2 0.044 87.96 0.044 87.96 think 2 0.044 88.00 0.044 88.00 thirst 2 0.044 88.05 0.044 88.05 thong 2 0.044 88.09 0.044 88.09 thorn 2 0.044 88.13 0.044 88.13 thought 2 0.044 88.18 0.044 88.18 thrash 2 0.044 88.22 0.044 88.22 thread 2 0.044 88.27 0.044 88.27 threat 2 0.044 88.31 0.044 88.31 thrift 2 0.044 88.35 0.044 88.35 thrill 2 0.044 88.40 0.044 88.40 thrive 2 0.044 88.44 0.044 88.44 throat 2 0.044 88.49 0.044 88.49 throne 2 0.044 88.53 0.044 88.53 throng 2 0.044 88.57 0.044 88.57 throw 2 0.044 88.62 0.044 88.62 thrush 2 0.044 88.66 0.044 88.66 thrust 2 0.044 88.70 0.044 88.70 thud 2 0.044 88.75 0.044 88.75 thug 2 0.044 88.79 0.044 88.79 thumb 2 0.044 88.84 0.044 88.84 thump 2 0.044 88.88 0.044 88.88 thwack 2 0.044 88.92 0.044 88.92 thwart 2 0.044 88.97 0.044 88.97 tick 2 0.044 89.01 0.044 89.01 tide 2 0.044 89.05 0.044 89.05 tie 2 0.044 89.10 0.044 89.10 tile 2 0.044 89.14 0.044 89.14 till 2 0.044 89.19 0.044 89.19 tilt 2 0.044 89.23 0.044 89.23 time 2 0.044 89.27 0.044 89.27 tin 2 0.044 89.32 0.044 89.32 tint 2 0.044 89.36 0.044 89.36 tip 2 0.044 89.40 0.044 89.40 tire 2 0.044 89.45 0.044 89.45 toad 2 0.044 89.49 0.044 89.49 toast 2 0.044 89.54 0.044 89.54 toe 2 0.044 89.58 0.044 89.58 toil 2 0.044 89.62 0.044 89.62 toll 2 0.044 89.67 0.044 89.67 tomb 2 0.044 89.71 0.044 89.71 tome 2 0.044 89.75 0.044 89.75 ton 2 0.044 89.80 0.044 89.80 tone 2 0.044 89.84 0.044 89.84 tongue 2 0.044 89.89 0.044 89.89 tool 2 0.044 89.93 0.044 89.93 toot 2 0.044 89.97 0.044 89.97 tooth 2 0.044 90.02 0.044 90.02 top 2 0.044 90.06 0.044 90.06 torch 2 0.044 90.11 0.044 90.11 torque 2 0.044 90.15 0.044 90.15 toss 2 0.044 90.19 0.044 90.19 tote 4 0.088 90.28 0.088 90.28 touch 2 0.044 90.32 0.044 90.32 tour 2 0.044 90.37 0.044 90.37 tout 2 0.044 90.41 0.044 90.41 town 2 0.044 90.46 0.044 90.46 toy 2 0.044 90.50 0.044 90.50 trace 2 0.044 90.54 0.044 90.54 track 2 0.044 90.59 0.044 90.59 tract 2 0.044 90.63 0.044 90.63 trade 2 0.044 90.67 0.044 90.67 trail 2 0.044 90.72 0.044 90.72 train 4 0.088 90.81 0.088 90.81 trait 2 0.044 90.85 0.044 90.85 tramp 2 0.044 90.89 0.044 90.89 trance 2 0.044 90.94 0.044 90.94 trap 2 0.044 90.98 0.044 90.98 trash 2 0.044 91.02 0.044 91.02 tray 2 0.044 91.07 0.044 91.07 tread 2 0.044 91.11 0.044 91.11 treat 2 0.044 91.16 0.044 91.16 tree 2 0.044 91.20 0.044 91.20 trench 2 0.044 91.24 0.044 91.24 trend 2 0.044 91.29 0.044 91.29 tribe 2 0.044 91.33 0.044 91.33 trick 2 0.044 91.37 0.044 91.37 trill 2 0.044 91.42 0.044 91.42 trip 2 0.044 91.46 0.044 91.46 tripe 2 0.044 91.51 0.044 91.51 troll 2 0.044 91.55 0.044 91.55 troop 2 0.044 91.59 0.044 91.59 trot 2 0.044 91.64 0.044 91.64 trough 2 0.044 91.68 0.044 91.68 trout 2 0.044 91.73 0.044 91.73 truce 2 0.044 91.77 0.044 91.77 truck 2 0.044 91.81 0.044 91.81 trump 2 0.044 91.86 0.044 91.86 trunk 2 0.044 91.90 0.044 91.90 trust 2 0.044 91.94 0.044 91.94 try 2 0.044 91.99 0.044 91.99 tryst 2 0.044 92.03 0.044 92.03 tub 2 0.044 92.08 0.044 92.08 tube 4 0.088 92.16 0.088 92.16 tuck 2 0.044 92.21 0.044 92.21 tug 2 0.044 92.25 0.044 92.25 tune 2 0.044 92.29 0.044 92.29 turf 2 0.044 92.34 0.044 92.34 turn 2 0.044 92.38 0.044 92.38 tusk 2 0.044 92.43 0.044 92.43 twain 2 0.044 92.47 0.044 92.47 tweed 2 0.044 92.51 0.044 92.51 twin 2 0.044 92.56 0.044 92.56 twinge 2 0.044 92.60 0.044 92.60 twist 2 0.044 92.64 0.044 92.64 twitch 2 0.044 92.69 0.044 92.69 type 2 0.044 92.73 0.044 92.73 urge 2 0.044 92.78 0.044 92.78 urn 2 0.044 92.82 0.044 92.82 use 2 0.044 92.86 0.044 92.86 vale 2 0.044 92.91 0.044 92.91 valve 2 0.044 92.95 0.044 92.95 vamp 2 0.044 92.99 0.044 92.99 van 2 0.044 93.04 0.044 93.04 vase 2 0.044 93.08 0.044 93.08 vault 2 0.044 93.13 0.044 93.13 veal 2 0.044 93.17 0.044 93.17 veer 2 0.044 93.21 0.044 93.21 veil 2 0.044 93.26 0.044 93.26 vein 2 0.044 93.30 0.044 93.30 vent 2 0.044 93.35 0.044 93.35 verb 2 0.044 93.39 0.044 93.39 verge 2 0.044 93.43 0.044 93.43 verse 2 0.044 93.48 0.044 93.48 verve 2 0.044 93.52 0.044 93.52 vest 2 0.044 93.56 0.044 93.56 vet 2 0.044 93.61 0.044 93.61 vex 2 0.044 93.65 0.044 93.65 vice 2 0.044 93.70 0.044 93.70 vie 2 0.044 93.74 0.044 93.74 view 2 0.044 93.78 0.044 93.78 vine 2 0.044 93.83 0.044 93.83 voice 2 0.044 93.87 0.044 93.87 volt 2 0.044 93.91 0.044 93.91 vote 2 0.044 93.96 0.044 93.96 vow 2 0.044 94.00 0.044 94.00 wad 2 0.044 94.05 0.044 94.05 wade 2 0.044 94.09 0.044 94.09 wag 2 0.044 94.13 0.044 94.13 wage 2 0.044 94.18 0.044 94.18 wail 2 0.044 94.22 0.044 94.22 waist 2 0.044 94.26 0.044 94.26 wait 2 0.044 94.31 0.044 94.31 waive 2 0.044 94.35 0.044 94.35 wake 2 0.044 94.40 0.044 94.40 walk 2 0.044 94.44 0.044 94.44 wall 2 0.044 94.48 0.044 94.48 waltz 2 0.044 94.53 0.044 94.53 wand 2 0.044 94.57 0.044 94.57 wane 2 0.044 94.61 0.044 94.61 want 2 0.044 94.66 0.044 94.66 war 2 0.044 94.70 0.044 94.70 ward 2 0.044 94.75 0.044 94.75 ware 2 0.044 94.79 0.044 94.79 warn 2 0.044 94.83 0.044 94.83 warp 2 0.044 94.88 0.044 94.88 wart 2 0.044 94.92 0.044 94.92 wash 2 0.044 94.96 0.044 94.96 wasp 2 0.044 95.01 0.044 95.01 waste 2 0.044 95.05 0.044 95.05 watch 2 0.044 95.10 0.044 95.10 watt 2 0.044 95.14 0.044 95.14 wave 2 0.044 95.18 0.044 95.18 wax 2 0.044 95.23 0.044 95.23 way 2 0.044 95.27 0.044 95.27 wealth 2 0.044 95.32 0.044 95.32 wear 2 0.044 95.36 0.044 95.36 weave 2 0.044 95.40 0.044 95.40 web 2 0.044 95.45 0.044 95.45 wed 2 0.044 95.49 0.044 95.49 wedge 2 0.044 95.53 0.044 95.53 weed 2 0.044 95.58 0.044 95.58 week 2 0.044 95.62 0.044 95.62 weep 2 0.044 95.67 0.044 95.67 weigh 2 0.044 95.71 0.044 95.71 weight 2 0.044 95.75 0.044 95.75 weld 4 0.088 95.84 0.088 95.84 well 2 0.044 95.88 0.044 95.88 welt 2 0.044 95.93 0.044 95.93 west 2 0.044 95.97 0.044 95.97 whack 4 0.088 96.06 0.088 96.06 wharf 2 0.044 96.10 0.044 96.10 wheat 2 0.044 96.15 0.044 96.15 wheel 2 0.044 96.19 0.044 96.19 whelp 2 0.044 96.23 0.044 96.23 whiff 2 0.044 96.28 0.044 96.28 while 2 0.044 96.32 0.044 96.32 whim 2 0.044 96.37 0.044 96.37 whine 2 0.044 96.41 0.044 96.41 whip 2 0.044 96.45 0.044 96.45 whirl 2 0.044 96.50 0.044 96.50 whit 2 0.044 96.54 0.044 96.54 whiz 2 0.044 96.58 0.044 96.58 whoop 2 0.044 96.63 0.044 96.63 whoosh 2 0.044 96.67 0.044 96.67 whore 2 0.044 96.72 0.044 96.72 whorl 2 0.044 96.76 0.044 96.76 wick 2 0.044 96.80 0.044 96.80 wield 2 0.044 96.85 0.044 96.85 wife 2 0.044 96.89 0.044 96.89 wig 2 0.044 96.94 0.044 96.94 will 2 0.044 96.98 0.044 96.98 wilt 2 0.044 97.02 0.044 97.02 win 2 0.044 97.07 0.044 97.07 wine 2 0.044 97.11 0.044 97.11 wing 2 0.044 97.15 0.044 97.15 wink 2 0.044 97.20 0.044 97.20 wipe 2 0.044 97.24 0.044 97.24 wire 2 0.044 97.29 0.044 97.29 wish 2 0.044 97.33 0.044 97.33 wisp 2 0.044 97.37 0.044 97.37 wit 4 0.088 97.46 0.088 97.46 witch 2 0.044 97.50 0.044 97.50 woe 2 0.044 97.55 0.044 97.55 wolf 2 0.044 97.59 0.044 97.59 womb 2 0.044 97.64 0.044 97.64 woo 2 0.044 97.68 0.044 97.68 wood 2 0.044 97.72 0.044 97.72 wool 2 0.044 97.77 0.044 97.77 word 2 0.044 97.81 0.044 97.81 work 2 0.044 97.85 0.044 97.85 world 2 0.044 97.90 0.044 97.90 worm 2 0.044 97.94 0.044 97.94 would 2 0.044 97.99 0.044 97.99 wow 2 0.044 98.03 0.044 98.03 wrack 2 0.044 98.07 0.044 98.07 wrap 2 0.044 98.12 0.044 98.12 wrath 2 0.044 98.16 0.044 98.16 wreak 2 0.044 98.20 0.044 98.20 wreath 2 0.044 98.25 0.044 98.25 wreck 2 0.044 98.29 0.044 98.29 wren 2 0.044 98.34 0.044 98.34 wrest 2 0.044 98.38 0.044 98.38 wretch 2 0.044 98.42 0.044 98.42 wring 2 0.044 98.47 0.044 98.47 wrist 2 0.044 98.51 0.044 98.51 writ 2 0.044 98.56 0.044 98.56 write 2 0.044 98.60 0.044 98.60 writhe 2 0.044 98.64 0.044 98.64 yacht 2 0.044 98.69 0.044 98.69 yak 4 0.088 98.77 0.088 98.77 yam 2 0.044 98.82 0.044 98.82 yang 2 0.044 98.86 0.044 98.86 yank 2 0.044 98.91 0.044 98.91 yard 2 0.044 98.95 0.044 98.95 yarn 2 0.044 98.99 0.044 98.99 yaw 2 0.044 99.04 0.044 99.04 yawl 2 0.044 99.08 0.044 99.08 yawn 2 0.044 99.12 0.044 99.12 yea 2 0.044 99.17 0.044 99.17 year 2 0.044 99.21 0.044 99.21 yearn 2 0.044 99.26 0.044 99.26 yeast 2 0.044 99.30 0.044 99.30 yell 2 0.044 99.34 0.044 99.34 yelp 2 0.044 99.39 0.044 99.39 yen 2 0.044 99.43 0.044 99.43 yes 2 0.044 99.47 0.044 99.47 yield 2 0.044 99.52 0.044 99.52 yoke 2 0.044 99.56 0.044 99.56 yolk 2 0.044 99.61 0.044 99.61 yore 2 0.044 99.65 0.044 99.65 youth 2 0.044 99.69 0.044 99.69 zeal 2 0.044 99.74 0.044 99.74 zest 2 0.044 99.78 0.044 99.78 zinc 2 0.044 99.82 0.044 99.82 zing 2 0.044 99.87 0.044 99.87 zip 2 0.044 99.91 0.044 99.91 zone 2 0.044 99.96 0.044 99.96 zoo 2 0.044 100.00 0.044 100.00 &lt;NA&gt; 0 0.00 100.00 Total 4568 100.00 100.00 100.00 100.00 english$AgeSubject Type: Factor Valid Total AgeSubject Freq % % Cum. % % Cum. old 2284 50.00 50.00 50.00 50.00 young 2284 50.00 100.00 50.00 100.00 &lt;NA&gt; 0 0.00 100.00 Total 4568 100.00 100.00 100.00 100.00 english$WordCategory Type: Factor Valid Total WordCategory Freq % % Cum. % % Cum. N 2904 63.57 63.57 63.57 63.57 V 1664 36.43 100.00 36.43 100.00 &lt;NA&gt; 0 0.00 100.00 Total 4568 100.00 100.00 100.00 100.00 english$LengthInLetters Type: Integer Valid Total LengthInLetters Freq % % Cum. % % Cum. 2 6 0.13 0.13 0.13 0.13 3 676 14.80 14.93 14.80 14.93 4 2020 44.22 59.15 44.22 59.15 5 1504 32.92 92.08 32.92 92.08 6 338 7.40 99.47 7.40 99.47 7 24 0.53 100.00 0.53 100.00 &lt;NA&gt; 0 0.00 100.00 Total 4568 100.00 100.00 100.00 100.00 english$Ncount Type: Integer Valid Total Ncount Freq % % Cum. % % Cum. 0 348 7.62 7.62 7.62 7.62 1 444 9.72 17.34 9.72 17.34 2 448 9.81 27.15 9.81 27.15 3 440 9.63 36.78 9.63 36.78 4 420 9.19 45.97 9.19 45.97 5 296 6.48 52.45 6.48 52.45 6 308 6.74 59.19 6.74 59.19 7 252 5.52 64.71 5.52 64.71 8 254 5.56 70.27 5.56 70.27 9 226 4.95 75.22 4.95 75.22 10 174 3.81 79.03 3.81 79.03 11 160 3.50 82.53 3.50 82.53 12 184 4.03 86.56 4.03 86.56 13 140 3.06 89.62 3.06 89.62 14 128 2.80 92.43 2.80 92.43 15 96 2.10 94.53 2.10 94.53 16 88 1.93 96.45 1.93 96.45 17 60 1.31 97.77 1.31 97.77 18 54 1.18 98.95 1.18 98.95 19 24 0.53 99.47 0.53 99.47 20 6 0.13 99.61 0.13 99.61 21 8 0.18 99.78 0.18 99.78 22 10 0.22 100.00 0.22 100.00 &lt;NA&gt; 0 0.00 100.00 Total 4568 100.00 100.00 100.00 100.00 english$ConffV Type: Numeric Valid Total ConffV Freq % % Cum. % % Cum. 0 3030 66.33 66.33 66.33 66.33 0.693147180559945 748 16.37 82.71 16.37 82.71 1.09861228866811 182 3.98 86.69 3.98 86.69 1.38629436111989 126 2.76 89.45 2.76 89.45 1.6094379124341 190 4.16 93.61 4.16 93.61 1.79175946922805 54 1.18 94.79 1.18 94.79 1.94591014905531 34 0.74 95.53 0.74 95.53 2.07944154167984 12 0.26 95.80 0.26 95.80 2.19722457733622 28 0.61 96.41 0.61 96.41 2.30258509299405 40 0.88 97.29 0.88 97.29 2.39789527279837 12 0.26 97.55 0.26 97.55 2.484906649788 8 0.18 97.72 0.18 97.72 2.56494935746154 34 0.74 98.47 0.74 98.47 2.63905732961526 4 0.088 98.56 0.088 98.56 2.70805020110221 12 0.26 98.82 0.26 98.82 2.77258872223978 6 0.13 98.95 0.13 98.95 2.83321334405622 24 0.53 99.47 0.53 99.47 2.89037175789616 10 0.22 99.69 0.22 99.69 3.04452243772342 2 0.044 99.74 0.044 99.74 3.09104245335832 4 0.088 99.82 0.088 99.82 3.13549421592915 4 0.088 99.91 0.088 99.91 3.2188758248682 2 0.044 99.96 0.044 99.96 3.3322045101752 2 0.044 100.00 0.044 100.00 &lt;NA&gt; 0 0.00 100.00 Total 4568 100.00 100.00 100.00 100.00 english$CV Type: Factor Valid Total CV Freq % % Cum. % % Cum. C 4446 97.33 97.33 97.33 97.33 V 122 2.67 100.00 2.67 100.00 &lt;NA&gt; 0 0.00 100.00 Total 4568 100.00 100.00 100.00 100.00 english$Obstruent Type: Factor Valid Total Obstruent Freq % % Cum. % % Cum. cont 1068 23.38 23.38 23.38 23.38 obst 3500 76.62 100.00 76.62 100.00 &lt;NA&gt; 0 0.00 100.00 Total 4568 100.00 100.00 100.00 100.00 english$Frication Type: Factor Valid Total Frication Freq % % Cum. % % Cum. burst 1840 40.28 40.28 40.28 40.28 frication 1660 36.34 76.62 36.34 76.62 long 88 1.93 78.55 1.93 78.55 short 980 21.45 100.00 21.45 100.00 &lt;NA&gt; 0 0.00 100.00 Total 4568 100.00 100.00 100.00 100.00 english$Voice Type: Factor Valid Total Voice Freq % % Cum. % % Cum. voiced 2060 45.10 45.10 45.10 45.10 voiceless 2508 54.90 100.00 54.90 100.00 &lt;NA&gt; 0 0.00 100.00 Total 4568 100.00 100.00 100.00 100.00 Generated by summarytools 1.0.1 (R version 4.4.2)2025-04-22 2.8.10 Visualisation In the tidyverse, the package for making elegant plots is called ggplot2. It works a lot like how pipes work, but since it was originally designed as a separate package, it uses + instead of %&gt;%. 2.8.10.1 First steps 2.8.10.1.1 Empty plot area Let’s produce a basic plot with nothing drawn on it. This is the basic plotting area in R. We need to then add layers on top of it to show our plot english %&gt;% ggplot() + theme_bw() 2.8.10.1.2 Adding x and y values Let’s add the x and y values from our dataset. X = subjective familiarity rating, y = RT in Visual Lexical Decision task english %&gt;% ggplot(aes(x = Familiarity, y = RTlexdec)) + theme_bw() There are no differences between the two. We need to tell ggplot2 to add a geometric function for plotting 2.8.10.1.3 Adding geoms Geoms are integrated within ggplot2 to obtain various types of plots. english %&gt;% ggplot(aes(x = Familiarity, y = RTlexdec)) + theme_bw() + geom_point() 2.8.10.1.4 Adding line of best fit We will add a line of best fit. This is used to evaluate presence/absence of a relationship between two numeric variables english %&gt;% ggplot(aes(x = Familiarity, y = RTlexdec)) + theme_bw() + geom_point() + geom_smooth(method = &quot;lm&quot;) ## line of best fit based on the lm() method ## `geom_smooth()` using formula = &#39;y ~ x&#39; The result shows a nice negative correlation! RT lexical decision decreases when familiarity rating increases. We can ask, are there differences related to the word category, i.e., verb vs noun? 2.8.10.1.5 By word category We change colour by levels of word category; english %&gt;% ggplot(aes(x = Familiarity, y = RTlexdec, colour = WordCategory)) + ## add colour to the base aesthetics theme_bw() + geom_point() + geom_smooth(method = &quot;lm&quot;) ## `geom_smooth()` using formula = &#39;y ~ x&#39; 2.8.10.1.6 Making final touches Let’s add a title and a subtitle, change x and y labels, change size of overall plot, and colours of the categories. english %&gt;% ggplot(aes(x = Familiarity, y = RTlexdec, colour = WordCategory)) + ## add colour to the base aesthetics theme_bw() + geom_point() + geom_smooth(method = &quot;lm&quot;) + labs(x = &quot;Familiarity rating&quot;, y = &quot;RT Lexical Decision&quot;, title = &quot;Familiarity rating vs RT in a lexical decision task&quot;, subtitle = &quot;with a trend line&quot;) + ## add labels theme(text = element_text(size = 15)) + ## increase size of plot theme(legend.position = &quot;bottom&quot;, legend.title = element_blank()) + ## remove legend title and change position scale_color_manual(labels = c(&quot;Nouns&quot;, &quot;Verbs&quot;), values = c(&quot;blue&quot;, &quot;red&quot;)) ## change colours and names of legend ## `geom_smooth()` using formula = &#39;y ~ x&#39; To choose colours, use the addin colourpicker from above. See this link for full list of colours available. Use colours that are colour-blind friendly here 2.8.10.2 Additional plots We looked above at one example of plots (with points). We could use additional types of plots. 2.8.10.2.1 A bar plot Will show barplots of the dataset english %&gt;% ggplot(aes(x = RTlexdec, colour = AgeSubject)) + theme_bw() + geom_bar() And another view with error bars! This is a nice example that shows how you can combine multiple chains with the pipe: Group by Age of subject Compute mean and SD use ggplot2 syntax to plot a barplot and error bars english %&gt;% group_by(AgeSubject) %&gt;% summarise( sd = sd(RTlexdec), RTlexdecM = mean(RTlexdec) ) %&gt;% ggplot(aes(x = AgeSubject, y = RTlexdecM)) + theme_bw() + geom_col(fill = &quot;lightgray&quot;, color = &quot;black&quot;) + geom_errorbar(aes(ymin = RTlexdecM-sd, ymax = RTlexdecM+sd), width = 0.2) 2.8.10.2.2 A histogram This looks at the distribution of the variable. We look at a histogram english %&gt;% ggplot(aes(x = RTlexdec, colour = AgeSubject)) + theme_bw() + geom_histogram(fill = &quot;white&quot;) + scale_color_manual(values = c(&quot;red&quot;, &quot;blue&quot;)) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 2.8.10.2.3 A density plot This looks at the distribution of the variable. We see that the two variables have different means. We can superpose the density plot on top of the histogram or have the density plot on its own. 2.8.10.2.3.1 Histogram and density plot english %&gt;% ggplot(aes(x = RTlexdec, colour = AgeSubject)) + theme_bw() + geom_histogram(aes(y = ..density..), fill = &quot;white&quot;) + scale_color_manual(values = c(&quot;red&quot;, &quot;blue&quot;)) + geom_density() ## Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0. ## ℹ Please use `after_stat(density)` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 2.8.10.2.3.2 Density plot only english %&gt;% ggplot(aes(x = RTlexdec, colour = AgeSubject)) + theme_bw() + geom_density() 2.8.10.2.4 A boxplot This allows you to see various information, including the Median, SD, Quartiles (25% and 75%) and outliers. Looking at the medians, we see clear difference between the two distributions. english %&gt;% ggplot(aes(x = AgeSubject, y = RTlexdec)) + theme_bw() + geom_boxplot() 2.8.10.2.5 A Violin plot This allows you to see various information, including the Median, SD, Quartiles (25% and 75%) and outliers. Looking at the medians, we see clear difference between the two distributions. english %&gt;% ggplot(aes(x = AgeSubject, y = RTlexdec)) + theme_bw() + geom_violin() 2.8.10.3 Facet_grid The plots we used so far allowed to plot data as a function of one categorical variable, e.g., AgeSubject. What if we wanted to show the different patterns emerging when combining AgeSubject (old vs young), WordCategory (Noun or Verb), CV (Consonant or Vowel) and Voice (Voiced and Voiceless) ? What if we also wanted to modify the labels and order of levels of variables? We will start slowly below to show how we can combine two categorical variables and extend them to additional ones 2.8.10.3.1 Two categorical variables 2.8.10.3.1.1 First steps Here we obtain a boxplot with two categorical variables AgeSubject and WordCategory english %&gt;% ggplot(aes(x = AgeSubject, y = RTlexdec)) + theme_bw() + geom_boxplot() + facet_grid(~ WordCategory) 2.8.10.3.1.2 Changing order of levels within a variable and its labels What would you do to change both order of levels within a variable and its labels? We want to change order for AgeSubject to be Young vs Old (rather than old vs young) and change labels of WordCategory from N vs V to Noun vs Verb? english %&gt;% mutate(AgeSubject = factor(AgeSubject, levels = c(&quot;young&quot;, &quot;old&quot;), labels = c(&quot;Young&quot;, &quot;Old&quot;)), WordCategory = factor(WordCategory, labels = c(&quot;Noun&quot;, &quot;Verb&quot;))) %&gt;% ggplot(aes(x = AgeSubject, y = RTlexdec)) + theme_bw() + geom_boxplot() + facet_grid(~ WordCategory) 2.8.10.3.2 Three or more categorical variables Let us obtain a boxplot with four categorical variables AgeSubject, WordCategory, CV and Voice. We still need to change names. We can also add margins = TRUE to obtain mean values for all categories (under all). We can also use scale = \"free\" to change limits of the y-axis. Of course this figure is so complex that it needs a lot of interpretation. But it allows you to see how we can use facet_grid to get more categorical variables in. This visualisation suggests that there are no clear differences when plotting results by this 4-way interaction as we always have clear differences between “Young” and “Old” participants, with “Young” being faster than “Old” participants. english %&gt;% mutate(AgeSubject = factor(AgeSubject, levels = c(&quot;young&quot;, &quot;old&quot;), labels = c(&quot;Young&quot;, &quot;Old&quot;)), WordCategory = factor(WordCategory, labels = c(&quot;Noun&quot;, &quot;Verb&quot;)), CV = factor(CV, labels = c(&quot;Consonant&quot;, &quot;Vowel&quot;))) %&gt;% ggplot(aes(x = AgeSubject, y = RTlexdec)) + theme_bw() + geom_boxplot() + facet_grid(CV + Voice ~ WordCategory, margins = TRUE, scales = &quot;free&quot;) 2.8.10.3.3 Comparing two numeric outcomes What if we want to compare performance in relation to reaction time for the lexical decision task (RTlexdec) and reaction time for naming (RTnaming). We want to see if there are differences related to the AgeSubject, WordCategory. We use pivot_longer here to do change the format of our table and then change names and use facet_grid. english %&gt;% select(RTlexdec, RTnaming, AgeSubject, WordCategory) %&gt;% pivot_longer(cols = c(RTlexdec, RTnaming), names_to = &quot;variable&quot;, values_to = &quot;values&quot;) %&gt;% mutate(AgeSubject = factor(AgeSubject, levels = c(&quot;young&quot;, &quot;old&quot;), labels = c(&quot;Young&quot;, &quot;Old&quot;)), WordCategory = factor(WordCategory, labels = c(&quot;Noun&quot;, &quot;Verb&quot;))) %&gt;% ggplot(aes(x = variable, y = values)) + theme_bw() + geom_boxplot() + facet_grid(AgeSubject ~ WordCategory, margins = TRUE, scales = &quot;free&quot;) 2.8.10.3.4 Exporting images When you use Rmarkdown, your figures are already embedded within the generated output. If you are using an R script and/or want to add the figure in a different document, you can use the following code: jpeg(filename = paste0(&quot;outputs/test.jpeg&quot;), width = 15, height = 15, units = &quot;cm&quot;, res = 300) english %&gt;% select(RTlexdec, RTnaming, AgeSubject, WordCategory) %&gt;% pivot_longer(cols = c(RTlexdec, RTnaming), names_to = &quot;variable&quot;, values_to = &quot;values&quot;) %&gt;% mutate(AgeSubject = factor(AgeSubject, levels = c(&quot;young&quot;, &quot;old&quot;), labels = c(&quot;Young&quot;, &quot;Old&quot;)), WordCategory = factor(WordCategory, labels = c(&quot;Noun&quot;, &quot;Verb&quot;))) %&gt;% ggplot(aes(x = variable, y = values)) + theme_bw() + geom_boxplot() + facet_grid(AgeSubject ~ WordCategory, margins = TRUE, scales = &quot;free&quot;) dev.off() ## png ## 2 The image is automatically saved into your working directory and you can import it to your word () document. You can use any device to save the output. Jpeg, PNG, PDF, TIFF, etc.. From an R script, you can run the code and then the image will appear within the “Plots” area. Simply click on export and you will be able to save the image. 2.8.10.3.5 Conclusion As you can see, visualisations in R using the Tidyverse provide you with many options and you can explore these further. See here for a full list of geoms. This will help you in thinking about visualisation. See extensions to ggplot2 here for additional plugins to enhance plots. "],["2.9-session-info.html", "2.9 session info", " 2.9 session info sessionInfo() ## R version 4.4.2 (2024-10-31 ucrt) ## Platform: x86_64-w64-mingw32/x64 ## Running under: Windows 11 x64 (build 26100) ## ## Matrix products: default ## ## ## locale: ## [1] LC_COLLATE=English_United Kingdom.utf8 ## [2] LC_CTYPE=English_United Kingdom.utf8 ## [3] LC_MONETARY=English_United Kingdom.utf8 ## [4] LC_NUMERIC=C ## [5] LC_TIME=English_United Kingdom.utf8 ## ## time zone: Europe/Paris ## tzcode source: internal ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] summarytools_1.0.1 phonR_1.0-7 languageR_1.5.0 lubridate_1.9.4 ## [5] forcats_1.0.0 stringr_1.5.1 dplyr_1.1.4 purrr_1.0.2 ## [9] readr_2.1.5 tidyr_1.3.1 tibble_3.2.1 ggplot2_3.5.1 ## [13] tidyverse_2.0.0 ## ## loaded via a namespace (and not attached): ## [1] gtable_0.3.6 xfun_0.49 bslib_0.8.0 lattice_0.22-6 ## [5] tzdb_0.4.0 vctrs_0.6.5 tools_4.4.2 generics_0.1.3 ## [9] fansi_1.0.6 pkgconfig_2.0.3 Matrix_1.7-1 checkmate_2.3.2 ## [13] pryr_0.1.6 lifecycle_1.0.4 farver_2.1.2 compiler_4.4.2 ## [17] rapportools_1.1 munsell_0.5.1 codetools_0.2-20 htmltools_0.5.8.1 ## [21] sass_0.4.9 yaml_2.3.10 crayon_1.5.3 nloptr_2.1.1 ## [25] pillar_1.9.0 jquerylib_0.1.4 MASS_7.3-61 cachem_1.1.0 ## [29] magick_2.8.5 boot_1.3-31 nlme_3.1-166 tidyselect_1.2.1 ## [33] digest_0.6.37 stringi_1.8.4 reshape2_1.4.4 pander_0.6.5 ## [37] bookdown_0.43 labeling_0.4.3 splines_4.4.2 fastmap_1.2.0 ## [41] grid_4.4.2 colorspace_2.1-1 cli_3.6.3 magrittr_2.0.3 ## [45] base64enc_0.1-3 utf8_1.2.4 withr_3.0.2 scales_1.3.0 ## [49] backports_1.5.0 timechange_0.3.0 rmarkdown_2.29 matrixStats_1.4.1 ## [53] lme4_1.1-35.5 hms_1.1.3 evaluate_1.0.1 knitr_1.49 ## [57] tcltk_4.4.2 mgcv_1.9-1 rlang_1.1.4 Rcpp_1.0.14 ## [61] glue_1.8.0 minqa_1.2.8 rstudioapi_0.17.1 jsonlite_1.8.9 ## [65] R6_2.5.1 plyr_1.8.9 "],["3-Correlation_LM_GLM_STD_CLM.html", "Chapter 3 Correlation plots - LM, GLM, CLM ", " Chapter 3 Correlation plots - LM, GLM, CLM "],["3.1-loading-packages-1.html", "3.1 Loading packages", " 3.1 Loading packages ## Use the code below to check if you have all required packages installed. If some are not installed already, the code below will install these. If you have all packages installed, then you could load them with the second code. requiredPackages = c(&#39;tidyverse&#39;, &#39;broom&#39;, &#39;knitr&#39;, &#39;Hmisc&#39;, &#39;corrplot&#39;, &#39;emmeans&#39;, &#39;ggsignif&#39;, &#39;PresenceAbsence&#39;, &#39;languageR&#39;, &#39;psycho&#39;, &#39;ordinal&#39;, &#39;DHARMa&#39;, &#39;sjPlot&#39;, &#39;webshot&#39;) for(p in requiredPackages){ if(!require(p,character.only = TRUE)) install.packages(p) library(p,character.only = TRUE) } "],["3.2-correlation-tests.html", "3.2 Correlation tests", " 3.2 Correlation tests 3.2.1 Basic correlations Let us start with a basic correlation test. We want to evaluate if two numeric variables are correlated with each other. We use the function cor to obtain the pearson correlation and cor.test to run a basic correlation test on our data with significance testing cor(english$RTlexdec, english$RTnaming, method = &quot;pearson&quot;) ## [1] 0.7587033 cor.test(english$RTlexdec, english$RTnaming) ## ## Pearson&#39;s product-moment correlation ## ## data: english$RTlexdec and english$RTnaming ## t = 78.699, df = 4566, p-value &lt; 2.2e-16 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.7461195 0.7707453 ## sample estimates: ## cor ## 0.7587033 What these results are telling us? There is a positive correlation between RTlexdec and RTnaming. The correlation coefficient (R²) is 0.76 (limits between -1 and 1). This correlation is statistically significant with a t value of 78.699, degrees of freedom of 4566 and a p-value &lt; 2.2e-16. What are the degrees of freedom? These relate to number of total observations - number of comparisons. Here we have 4568 observations in the dataset, and two comparisons, hence 4568 - 2 = 4566. For the p value, there is a threshold we usually use. This threshold is p = 0.05. This threshold means we have a minimum to consider any difference as significant or not. 0.05 means that we have a probability to find a significant difference that is at 5% or lower. IN our case, the p value is lower that 2.2e-16. How to interpret this number? this tells us to add 15 0s before the 2!! i.e., 0.0000000000000002. This probability is very (very!!) low. So we conclude that there is a statistically significant correlation between the two variables. The formula to calculate the t value is below. x̄ = sample mean μ0 = population mean s = sample standard deviation n = sample size The p value is influenced by various factors, number of observations, strength of the difference, mean values, etc.. You should always be careful with interpreting p values taking everything else into account. 3.2.2 Using the package corrplot Above, we did a correlation test on two predictors. What if we want to obtain a nice plot of all numeric predictors and add significance levels? 3.2.2.1 Correlation plots corr &lt;- english %&gt;% select(where(is.numeric)) %&gt;% cor() corrplot(corr, method = &#39;ellipse&#39;, type = &#39;upper&#39;) 3.2.2.2 More advanced Let’s first compute the correlations between all numeric variables and plot these with the p values ## correlation using &quot;corrplot&quot; ## based on the function `rcorr&#39; from the `Hmisc` package ## Need to change dataframe into a matrix corr &lt;- english %&gt;% select(where(is.numeric)) %&gt;% data.matrix(english) %&gt;% rcorr(type = &quot;pearson&quot;) # use corrplot to obtain a nice correlation plot! corrplot(corr$r, p.mat = corr$P, addCoef.col = &quot;black&quot;, diag = FALSE, type = &quot;upper&quot;, tl.srt = 55) english %&gt;% group_by(AgeSubject) %&gt;% summarise(mean = mean(RTlexdec), sd = sd(RTlexdec)) ## # A tibble: 2 × 3 ## AgeSubject mean sd ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 old 6.66 0.116 ## 2 young 6.44 0.106 "],["3.3-linear-models.html", "3.3 Linear Models", " 3.3 Linear Models Up to now, we have looked at descriptive statistics, and evaluated summaries, correlations in the data (with p values). We are now interested in looking at group differences. 3.3.1 Introduction The basic assumption of a Linear model is to create a regression analysis on the data. We have an outcome (or dependent variable) and a predictor (or an independent variable). The formula of a linear model is as follows outcome ~ predictor that can be read as “outcome as a function of the predictor”. We can add “1” to specify an intercept, but this is by default added to the model 3.3.1.1 Model estimation english2 &lt;- english %&gt;% mutate(AgeSubject = factor(AgeSubject, levels = c(&quot;young&quot;, &quot;old&quot;))) mdl.lm &lt;- english2 %&gt;% lm(RTlexdec ~ AgeSubject, data = .) #lm(RTlexdec ~ AgeSubject, data = english) mdl.lm #also print(mdl.lm) ## ## Call: ## lm(formula = RTlexdec ~ AgeSubject, data = .) ## ## Coefficients: ## (Intercept) AgeSubjectold ## 6.4392 0.2217 summary(mdl.lm) ## ## Call: ## lm(formula = RTlexdec ~ AgeSubject, data = .) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.25776 -0.08339 -0.01669 0.06921 0.52685 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.439237 0.002324 2771.03 &lt;2e-16 *** ## AgeSubjectold 0.221721 0.003286 67.47 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.1111 on 4566 degrees of freedom ## Multiple R-squared: 0.4992, Adjusted R-squared: 0.4991 ## F-statistic: 4552 on 1 and 4566 DF, p-value: &lt; 2.2e-16 3.3.2 Role of coding schemes 3.3.2.1 Intro There are other coding schemes that can be used. See Schad et al. (2020): “How to capitalize on a priori contrasts in linear (mixed) models: A tutorial”. Journal of Memory and Language,vol. 110, 104038. We have: The treatment coding The contrast or sum coding The polynomial coding The Repeated coding The helmert coding The first two are the most commonly used coding schemes, but see the paper for why one can use the others. 3.3.2.2 Treatment coding By default, R uses a treatment coding scheme. By this we mean that the intercept has the outcome of a specific level in the dataset (usually, the first in alphabetical order, unless you have changed that!). In our example above, we changed the reference level of the variable AgeSubject to be “young” vs “old”. What we see as an result in our LM is the intercept (=Young) vs “AgeSubjectold”. This will mean we are looking at the difference between the reference level and all other levels. The code below allows you to see what the coding scheme is. english2$AgeSubject2 &lt;- english2$AgeSubject contrasts(english2$AgeSubject2) &lt;- contr.treatment(2) contrasts(english2$AgeSubject2) ## 2 ## young 0 ## old 1 mdl.lm.T &lt;- english2 %&gt;% lm(RTlexdec ~ AgeSubject2, data = .) #lm(RTlexdec ~ AgeSubject, data = english) mdl.lm.T #also print(mdl.lm) ## ## Call: ## lm(formula = RTlexdec ~ AgeSubject2, data = .) ## ## Coefficients: ## (Intercept) AgeSubject22 ## 6.4392 0.2217 summary(mdl.lm.T) ## ## Call: ## lm(formula = RTlexdec ~ AgeSubject2, data = .) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.25776 -0.08339 -0.01669 0.06921 0.52685 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.439237 0.002324 2771.03 &lt;2e-16 *** ## AgeSubject22 0.221721 0.003286 67.47 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.1111 on 4566 degrees of freedom ## Multiple R-squared: 0.4992, Adjusted R-squared: 0.4991 ## F-statistic: 4552 on 1 and 4566 DF, p-value: &lt; 2.2e-16 3.3.2.3 Contrast (or sum) coding 3.3.2.3.1 Default Let’s change the coding scheme and see the difference in the output. english2 &lt;- english2 %&gt;% mutate(AgeSubject2 = factor(AgeSubject2, levels = c(&quot;old&quot;, &quot;young&quot;))) contrasts(english2$AgeSubject2) &lt;- contr.sum(2) contrasts(english2$AgeSubject2) ## [,1] ## old 1 ## young -1 mdl.lm.C &lt;- english2 %&gt;% lm(RTlexdec ~ AgeSubject2, data = .) #lm(RTlexdec ~ AgeSubject, data = english) mdl.lm.C #also print(mdl.lm) ## ## Call: ## lm(formula = RTlexdec ~ AgeSubject2, data = .) ## ## Coefficients: ## (Intercept) AgeSubject21 ## 6.5501 0.1109 summary(mdl.lm.C) ## ## Call: ## lm(formula = RTlexdec ~ AgeSubject2, data = .) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.25776 -0.08339 -0.01669 0.06921 0.52685 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.550097 0.001643 3986.29 &lt;2e-16 *** ## AgeSubject21 0.110861 0.001643 67.47 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.1111 on 4566 degrees of freedom ## Multiple R-squared: 0.4992, Adjusted R-squared: 0.4991 ## F-statistic: 4552 on 1 and 4566 DF, p-value: &lt; 2.2e-16 With contrast (or sum) coding, the intercept is almost the same as before (treatment = 6.439237 vs contrast = 6.550097). The intercept is now the average of all of the data points english2 %&gt;% mutate(meanRTlexdec = mean(RTlexdec)) %&gt;% select(meanRTlexdec) %&gt;% head(10) ## meanRTlexdec ## 1 6.550097 ## 2 6.550097 ## 3 6.550097 ## 4 6.550097 ## 5 6.550097 ## 6 6.550097 ## 7 6.550097 ## 8 6.550097 ## 9 6.550097 ## 10 6.550097 The coefficient for “old” is different. It is now nearly half of that in the treatment coding (0.221721 vs 0.110861). Why is this the case? In treatment coding, the distance between old and young was of 1 (1- 0 = 1), in contrast coding, it is of 2 (1 - -1 = 2). The coefficient of the intercept is exactly the same; for the second, it is half of the one above (0.221721 / 1 = 0.221721; 0.221721 / 2 = 0.110861)! How to interpret the coefficient for the level “old”? It is the distance from the average! Let’s change slightly the coding scheme 3.3.2.3.2 Modified english2 &lt;- english2 %&gt;% mutate(AgeSubject2 = factor(AgeSubject, levels = c(&quot;young&quot;, &quot;old&quot;))) contrasts(english2$AgeSubject2) &lt;- c(-0.5, 0.5) contrasts(english2$AgeSubject2) ## [,1] ## young -0.5 ## old 0.5 mdl.lmC.2 &lt;- english2 %&gt;% lm(RTlexdec ~ AgeSubject2, data = .) #lm(RTlexdec ~ AgeSubject, data = english) mdl.lmC.2 #also print(mdl.lmC.2) ## ## Call: ## lm(formula = RTlexdec ~ AgeSubject2, data = .) ## ## Coefficients: ## (Intercept) AgeSubject21 ## 6.5501 0.2217 summary(mdl.lmC.2) ## ## Call: ## lm(formula = RTlexdec ~ AgeSubject2, data = .) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.25776 -0.08339 -0.01669 0.06921 0.52685 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.550097 0.001643 3986.29 &lt;2e-16 *** ## AgeSubject21 0.221721 0.003286 67.47 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.1111 on 4566 degrees of freedom ## Multiple R-squared: 0.4992, Adjusted R-squared: 0.4991 ## F-statistic: 4552 on 1 and 4566 DF, p-value: &lt; 2.2e-16 Our intercept is still the average of all datapoints of the dependent variable; that of “old” is now at 0.221721 as expected. The distance between young and old is of 1 (0.5 - -0.5 = 1). When and why do we use the different coding schemes? We use it to make the intercept more interpretable. This is especially the case when having more than two categorical predictors, or interactions between a numeric and a categorical predictor. Read the paper and the Bodo Winter’s book for more details. 3.3.3 Further steps 3.3.3.1 Tidying the output We use our original model with treatment coding. # from library(broom) tidy(mdl.lm) %&gt;% select(term, estimate) %&gt;% mutate(estimate = round(estimate, 3)) ## # A tibble: 2 × 2 ## term estimate ## &lt;chr&gt; &lt;dbl&gt; ## 1 (Intercept) 6.44 ## 2 AgeSubjectold 0.222 mycoefE &lt;- tidy(mdl.lm) %&gt;% pull(estimate) Obtaining mean values from our model #old mycoefE[1] ## [1] 6.439237 #young mycoefE[1] + mycoefE[2] ## [1] 6.660958 3.3.3.2 Nice table of our model summary We can also obtain a nice table of our model summary. We can use the package knitr or xtable 3.3.3.2.1 Directly from model summary kable(summary(mdl.lm)$coef, digits = 3) Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 6.439 0.002 2771.027 0 AgeSubjectold 0.222 0.003 67.468 0 3.3.3.2.2 From the tidy output mdl.lmT &lt;- tidy(mdl.lm) kable(mdl.lmT, digits = 3) term estimate std.error statistic p.value (Intercept) 6.439 0.002 2771.027 0 AgeSubjectold 0.222 0.003 67.468 0 3.3.3.2.3 Model’s fit print(tab_model(mdl.lm, file = paste0(&quot;outputs/mdl.lm.html&quot;))) webshot(paste0(&quot;outputs/mdl.lm.html&quot;), paste0(&quot;outputs/mdl.lm.png&quot;)) Model fit: Linear model 3.3.3.3 Dissecting the model Let us dissect the model. If you use “str”, you will be able to see what is available under our linear model. To access some info from the model 3.3.3.3.1 “str” and “coef” str(mdl.lm) ## List of 13 ## $ coefficients : Named num [1:2] 6.439 0.222 ## ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;(Intercept)&quot; &quot;AgeSubjectold&quot; ## $ residuals : Named num [1:4568] 0.1045 -0.0416 -0.1343 -0.015 0.0114 ... ## ..- attr(*, &quot;names&quot;)= chr [1:4568] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ effects : Named num [1:4568] -442.7013 7.4927 -0.1352 -0.0159 0.0105 ... ## ..- attr(*, &quot;names&quot;)= chr [1:4568] &quot;(Intercept)&quot; &quot;AgeSubjectold&quot; &quot;&quot; &quot;&quot; ... ## $ rank : int 2 ## $ fitted.values: Named num [1:4568] 6.44 6.44 6.44 6.44 6.44 ... ## ..- attr(*, &quot;names&quot;)= chr [1:4568] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ assign : int [1:2] 0 1 ## $ qr :List of 5 ## ..$ qr : num [1:4568, 1:2] -67.587 0.0148 0.0148 0.0148 0.0148 ... ## .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. ..$ : chr [1:4568] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## .. .. ..$ : chr [1:2] &quot;(Intercept)&quot; &quot;AgeSubjectold&quot; ## .. ..- attr(*, &quot;assign&quot;)= int [1:2] 0 1 ## .. ..- attr(*, &quot;contrasts&quot;)=List of 1 ## .. .. ..$ AgeSubject: chr &quot;contr.treatment&quot; ## ..$ qraux: num [1:2] 1.01 1.01 ## ..$ pivot: int [1:2] 1 2 ## ..$ tol : num 1e-07 ## ..$ rank : int 2 ## ..- attr(*, &quot;class&quot;)= chr &quot;qr&quot; ## $ df.residual : int 4566 ## $ contrasts :List of 1 ## ..$ AgeSubject: chr &quot;contr.treatment&quot; ## $ xlevels :List of 1 ## ..$ AgeSubject: chr [1:2] &quot;young&quot; &quot;old&quot; ## $ call : language lm(formula = RTlexdec ~ AgeSubject, data = .) ## $ terms :Classes &#39;terms&#39;, &#39;formula&#39; language RTlexdec ~ AgeSubject ## .. ..- attr(*, &quot;variables&quot;)= language list(RTlexdec, AgeSubject) ## .. ..- attr(*, &quot;factors&quot;)= int [1:2, 1] 0 1 ## .. .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. .. ..$ : chr [1:2] &quot;RTlexdec&quot; &quot;AgeSubject&quot; ## .. .. .. ..$ : chr &quot;AgeSubject&quot; ## .. ..- attr(*, &quot;term.labels&quot;)= chr &quot;AgeSubject&quot; ## .. ..- attr(*, &quot;order&quot;)= int 1 ## .. ..- attr(*, &quot;intercept&quot;)= int 1 ## .. ..- attr(*, &quot;response&quot;)= int 1 ## .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: 0x0000014f1cba7540&gt; ## .. ..- attr(*, &quot;predvars&quot;)= language list(RTlexdec, AgeSubject) ## .. ..- attr(*, &quot;dataClasses&quot;)= Named chr [1:2] &quot;numeric&quot; &quot;factor&quot; ## .. .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;RTlexdec&quot; &quot;AgeSubject&quot; ## $ model :&#39;data.frame&#39;: 4568 obs. of 2 variables: ## ..$ RTlexdec : num [1:4568] 6.54 6.4 6.3 6.42 6.45 ... ## ..$ AgeSubject: Factor w/ 2 levels &quot;young&quot;,&quot;old&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## ..- attr(*, &quot;terms&quot;)=Classes &#39;terms&#39;, &#39;formula&#39; language RTlexdec ~ AgeSubject ## .. .. ..- attr(*, &quot;variables&quot;)= language list(RTlexdec, AgeSubject) ## .. .. ..- attr(*, &quot;factors&quot;)= int [1:2, 1] 0 1 ## .. .. .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. .. .. ..$ : chr [1:2] &quot;RTlexdec&quot; &quot;AgeSubject&quot; ## .. .. .. .. ..$ : chr &quot;AgeSubject&quot; ## .. .. ..- attr(*, &quot;term.labels&quot;)= chr &quot;AgeSubject&quot; ## .. .. ..- attr(*, &quot;order&quot;)= int 1 ## .. .. ..- attr(*, &quot;intercept&quot;)= int 1 ## .. .. ..- attr(*, &quot;response&quot;)= int 1 ## .. .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: 0x0000014f1cba7540&gt; ## .. .. ..- attr(*, &quot;predvars&quot;)= language list(RTlexdec, AgeSubject) ## .. .. ..- attr(*, &quot;dataClasses&quot;)= Named chr [1:2] &quot;numeric&quot; &quot;factor&quot; ## .. .. .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;RTlexdec&quot; &quot;AgeSubject&quot; ## - attr(*, &quot;class&quot;)= chr &quot;lm&quot; coef(mdl.lm) ## (Intercept) AgeSubjectold ## 6.4392366 0.2217215 ## same as ## mdl.lm$coefficients 3.3.3.3.2 “coef” and “coefficients” What if I want to obtain the “Intercept”? Or the coefficient for distance? What if I want the full row for distance? coef(mdl.lm)[1] # same as mdl.lm$coefficients[1] ## (Intercept) ## 6.439237 coef(mdl.lm)[2] # same as mdl.lm$coefficients[2] ## AgeSubjectold ## 0.2217215 summary(mdl.lm)$coefficients[2, ] # full row ## Estimate Std. Error t value Pr(&gt;|t|) ## 0.22172146 0.00328631 67.46820211 0.00000000 summary(mdl.lm)$coefficients[2, 4] #for p value ## [1] 0 3.3.3.3.3 Residuals What about residuals (difference between the observed value and the estimated value of the quantity) and fitted values? This allows us to evaluate how normal our residuals are and how different they are from a normal distribution. 3.3.3.3.3.1 Histogram hist(residuals(mdl.lm)) 3.3.3.3.3.2 qqplots qqnorm(residuals(mdl.lm)); qqline(residuals(mdl.lm)) 3.3.3.3.3.3 Residuals vs fitted values plot(fitted(mdl.lm), residuals(mdl.lm), cex = 4) 3.3.3.3.3.4 Generating and plotting residual plot with DHARMa sim_residuals &lt;- simulateResiduals(mdl.lm) plot(sim_residuals) 3.3.3.3.4 Goodness of fit? AIC(mdl.lm) # Akaike&#39;s Information Criterion, lower values are better ## [1] -7110.962 BIC(mdl.lm) # Bayesian AIC ## [1] -7091.682 logLik(mdl.lm) # log likelihood ## &#39;log Lik.&#39; 3558.481 (df=3) Or use the following from broom glance(mdl.lm) ## # A tibble: 1 × 12 ## r.squared adj.r.squared sigma statistic p.value df logLik AIC BIC ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.499 0.499 0.111 4552. 0 1 3558. -7111. -7092. ## # ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt; 3.3.3.3.5 Significance testing Are the above informative? of course not directly. If we want to test for overall significance of model. We run a null model (aka intercept only) and compare models. mdl.lm.Null &lt;- english %&gt;% lm(RTlexdec ~ 1, data = .) mdl.comp &lt;- anova(mdl.lm.Null, mdl.lm) mdl.comp ## Analysis of Variance Table ## ## Model 1: RTlexdec ~ 1 ## Model 2: RTlexdec ~ AgeSubject ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 4567 112.456 ## 2 4566 56.314 1 56.141 4552 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The results show that adding the variable “AgeSubject” improves the model fit. We can write this as follows: Model comparison showed that the addition of AgeSubject improved the model fit when compared with an intercept only model (\\(F\\)(1) = 4551.96, p &lt; 0) (F(1) = 4552 , p &lt; 2.2e-16) 3.3.4 Plotting fitted values 3.3.4.1 Trend line Let’s plot our fitted values but only for the trend line english %&gt;% ggplot(aes(x = AgeSubject, y = RTlexdec))+ geom_boxplot()+ theme_bw() + theme(text = element_text(size = 15))+ geom_smooth(aes(x = as.numeric(AgeSubject), y = predict(mdl.lm)), method = &quot;lm&quot;, color = &quot;blue&quot;) + labs(x = &quot;Age&quot;, y = &quot;RTLexDec&quot;, title = &quot;Boxplot and predicted trend line&quot;, subtitle = &quot;with ggplot2&quot;) This allows us to plot the fitted values from our model with the predicted linear trend. This is exactly the same as our original data. 3.3.4.2 Predicted means and the trend line We can also plot the predicted means and linear trend english %&gt;% ggplot(aes(x = AgeSubject, y = predict(mdl.lm)))+ geom_boxplot(color = &quot;blue&quot;) + theme_bw() + theme(text = element_text(size = 15)) + geom_smooth(aes(x = as.numeric(AgeSubject), y = predict(mdl.lm)), method = &quot;lm&quot;, color = &quot;blue&quot;) + labs(x = &quot;Age&quot;, y = &quot;RTLexDec&quot;, title = &quot;Predicted means and trend line&quot;, subtitle = &quot;with ggplot2&quot;) 3.3.4.3 Raw data, predicted means and the trend line We can also plot the actual data, the predicted means and linear trend english %&gt;% ggplot(aes(x = AgeSubject, y = RTlexdec))+ geom_boxplot() + geom_boxplot(aes(x = AgeSubject, y = predict(mdl.lm)), color = &quot;blue&quot;) + theme_bw() + theme(text = element_text(size = 15)) + geom_smooth(aes(x = as.numeric(AgeSubject), y = predict(mdl.lm)), method = &quot;lm&quot;, color = &quot;blue&quot;) + labs(x = &quot;Species&quot;, y = &quot;Length&quot;, title = &quot;Boxplot raw data, predicted means (in blue) and trend line&quot;, subtitle = &quot;with ggplot2&quot;) 3.3.4.4 Add significance levels and trend line on a plot? We can use the p values generated from either our linear model to add significance levels on a plot. We use the code from above and add the significance level. We also add a trend line english %&gt;% ggplot(aes(x = AgeSubject, y = RTlexdec))+ geom_boxplot() + geom_boxplot(aes(x = AgeSubject, y = predict(mdl.lm)), color = &quot;blue&quot;) + theme_bw() + theme(text = element_text(size = 15)) + geom_smooth(aes(x = as.numeric(AgeSubject), y = predict(mdl.lm)), method = &quot;lm&quot;, color = &quot;blue&quot;) + labs(x = &quot;Species&quot;, y = &quot;Length&quot;, title = &quot;Boxplot raw data, predicted means (in blue) and trend line&quot;, subtitle = &quot;with significance testing&quot;) + geom_signif(comparison = list(c(&quot;old&quot;, &quot;young&quot;)), map_signif_level = TRUE, test = function(a, b) { list(p.value = summary(mdl.lm)$coefficients[2, 4])}) 3.3.5 What about pairwise comparison? When having three of more levels in our predictor, we can use pairwise comparisons, with corrections to evaluate differences between each level. summary(mdl.lm) ## ## Call: ## lm(formula = RTlexdec ~ AgeSubject, data = .) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.25776 -0.08339 -0.01669 0.06921 0.52685 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.439237 0.002324 2771.03 &lt;2e-16 *** ## AgeSubjectold 0.221721 0.003286 67.47 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.1111 on 4566 degrees of freedom ## Multiple R-squared: 0.4992, Adjusted R-squared: 0.4991 ## F-statistic: 4552 on 1 and 4566 DF, p-value: &lt; 2.2e-16 mdl.lm %&gt;% emmeans(pairwise ~ AgeSubject, adjust = &quot;fdr&quot;) -&gt; mdl.emmeans mdl.emmeans ## $emmeans ## AgeSubject emmean SE df lower.CL upper.CL ## young 6.439 0.00232 4566 6.435 6.444 ## old 6.661 0.00232 4566 6.656 6.666 ## ## Confidence level used: 0.95 ## ## $contrasts ## contrast estimate SE df t.ratio p.value ## young - old -0.222 0.00329 4566 -67.468 &lt;.0001 How to interpret the output? Discuss with your neighbour and share with the group. Hint… Look at the emmeans values for each level of our factor “Species” and the contrasts. 3.3.6 Multiple predictors? Linear models require a numeric outcome, but the predictor can be either numeric or a factor. We can have more than one predictor. The only issue is that this complicates the interpretation of results english %&gt;% lm(RTlexdec ~ AgeSubject * WordCategory, data = .) %&gt;% summary() ## ## Call: ## lm(formula = RTlexdec ~ AgeSubject * WordCategory, data = .) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.25079 -0.08273 -0.01516 0.06940 0.52285 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.664955 0.002911 2289.950 &lt;2e-16 *** ## AgeSubjectyoung -0.220395 0.004116 -53.545 &lt;2e-16 *** ## WordCategoryV -0.010972 0.004822 -2.275 0.0229 * ## AgeSubjectyoung:WordCategoryV -0.003642 0.006820 -0.534 0.5934 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.1109 on 4564 degrees of freedom ## Multiple R-squared: 0.5008, Adjusted R-squared: 0.5005 ## F-statistic: 1526 on 3 and 4564 DF, p-value: &lt; 2.2e-16 And with an Anova english %&gt;% lm(RTlexdec ~ AgeSubject * WordCategory, data = .) %&gt;% anova() ## Analysis of Variance Table ## ## Response: RTlexdec ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## AgeSubject 1 56.141 56.141 4564.2810 &lt; 2.2e-16 *** ## WordCategory 1 0.173 0.173 14.0756 0.0001778 *** ## AgeSubject:WordCategory 1 0.004 0.004 0.2851 0.5933724 ## Residuals 4564 56.138 0.012 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The results above tell us that all predictors used are significantly different. "],["3.4-generalised-linear-models.html", "3.4 Generalised Linear Models", " 3.4 Generalised Linear Models Here we will look at an example when the outcome is binary. This simulated data is structured as follows. We asked one participant to listen to 165 sentences, and to judge whether these are “grammatical” or “ungrammatical”. There were 105 sentences that were “grammatical” and 60 “ungrammatical”. Responses varied, with 110 “yes” responses and 55 “no” responses, spread across the grammatical. This fictitious example can apply in any other situation. Let’s think Geography: 165 lands: 105 “flat” and 60 “non-flat”, etc. This applies to any case where you need to “categorise” the outcome into two groups. 3.4.1 Load and summaries Let’s create this dataset from scratch (you can load the “grammatical.csv file as well) and do some basic summaries grammatical &lt;- as.data.frame( cbind(&quot;grammaticality&quot; = c(&quot;grammatical&quot; = rep(&quot;grammatical&quot;, 105), &quot;ungrammatical&quot; = rep(&quot;ungrammatical&quot;, 60)), &quot;response&quot; = c(&quot;yes&quot; = rep(&quot;yes&quot;, 100), &quot;no&quot; = rep(&quot;no&quot;, 5), &quot;yes&quot; = rep(&quot;yes&quot;, 10), &quot;no&quot; = rep(&quot;no&quot;, 50))), row.names = FALSE) grammatical %&gt;% head(20) ## grammaticality response ## 1 grammatical yes ## 2 grammatical yes ## 3 grammatical yes ## 4 grammatical yes ## 5 grammatical yes ## 6 grammatical yes ## 7 grammatical yes ## 8 grammatical yes ## 9 grammatical yes ## 10 grammatical yes ## 11 grammatical yes ## 12 grammatical yes ## 13 grammatical yes ## 14 grammatical yes ## 15 grammatical yes ## 16 grammatical yes ## 17 grammatical yes ## 18 grammatical yes ## 19 grammatical yes ## 20 grammatical yes str(grammatical) ## &#39;data.frame&#39;: 165 obs. of 2 variables: ## $ grammaticality: chr &quot;grammatical&quot; &quot;grammatical&quot; &quot;grammatical&quot; &quot;grammatical&quot; ... ## $ response : chr &quot;yes&quot; &quot;yes&quot; &quot;yes&quot; &quot;yes&quot; ... head(grammatical) ## grammaticality response ## 1 grammatical yes ## 2 grammatical yes ## 3 grammatical yes ## 4 grammatical yes ## 5 grammatical yes ## 6 grammatical yes table(grammatical$response, grammatical$grammaticality) ## ## grammatical ungrammatical ## no 5 50 ## yes 100 10 3.4.2 GLM - Categorical predictors Let’s run a first GLM (Generalised Linear Model). A GLM uses a special family “binomial” as it assumes the outcome has a binomial distribution. In general, results from a Logistic Regression are close to what we get from SDT (see above). To run the results, we will change the reference level for both response and grammaticality. The basic assumption about GLM is that we start with our reference level being the “no” responses to the “ungrammatical” category. Any changes to this reference will be seen in the coefficients as “yes” responses to the “grammatical” category. 3.4.2.1 Model estimation and results The results below show the logodds for our model. grammatical &lt;- grammatical %&gt;% mutate(response = factor(response, levels = c(&quot;no&quot;, &quot;yes&quot;)), grammaticality = factor(grammaticality, levels = c(&quot;ungrammatical&quot;, &quot;grammatical&quot;))) grammatical %&gt;% group_by(grammaticality, response) %&gt;% table() ## response ## grammaticality no yes ## ungrammatical 50 10 ## grammatical 5 100 mdl.glm &lt;- grammatical %&gt;% glm(response ~ grammaticality, data = ., family = binomial) summary(mdl.glm) ## ## Call: ## glm(formula = response ~ grammaticality, family = binomial, data = .) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -1.6094 0.3464 -4.646 3.38e-06 *** ## grammaticalitygrammatical 4.6052 0.5744 8.017 1.08e-15 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 210.050 on 164 degrees of freedom ## Residual deviance: 94.271 on 163 degrees of freedom ## AIC: 98.271 ## ## Number of Fisher Scoring iterations: 5 tidy(mdl.glm) %&gt;% select(term, estimate) %&gt;% mutate(estimate = round(estimate, 3)) ## # A tibble: 2 × 2 ## term estimate ## &lt;chr&gt; &lt;dbl&gt; ## 1 (Intercept) -1.61 ## 2 grammaticalitygrammatical 4.61 # to only get the coefficients mycoef2 &lt;- tidy(mdl.glm) %&gt;% pull(estimate) 3.4.2.2 Model’s fit print(tab_model(mdl.glm, file = paste0(&quot;outputs/mdl.glm.html&quot;))) webshot(paste0(&quot;outputs/mdl.glm.html&quot;), paste0(&quot;outputs/mdl.glm.png&quot;)) Model fit: Generalised Linear model - Categorical The results show that for one unit increase in the response (i.e., from no to yes), the logodds of being “grammatical” is increased by 4.6051702 (the intercept shows that when the response is “no”, the logodds are -1.6094379). The actual logodds for the response “yes” to grammatical is 2.9957323 3.4.2.3 Logodds to Odd ratios Logodds can be modified to talk about the odds of an event. For our model above, the odds of “grammatical” receiving a “no” response is a mere 0.2; the odds of “grammatical” to receive a “yes” is a 20; i.e., 20 times more likely exp(mycoef2[1]) ## [1] 0.2 exp(mycoef2[1] + mycoef2[2]) ## [1] 20 3.4.2.4 LogOdds to proportions If you want to talk about the percentage “accuracy” of our model, then we can transform our loggodds into proportions. This shows that the proportion of “grammatical” receiving a “yes” response increases by 99% (or 95% based on our “true” coefficients) plogis(mycoef2[1]) ## [1] 0.1666667 plogis(mycoef2[1] + mycoef2[2]) ## [1] 0.952381 3.4.2.5 Plotting grammatical &lt;- grammatical %&gt;% mutate(prob = predict(mdl.glm, type = &quot;response&quot;)) grammatical %&gt;% ggplot(aes(x = as.numeric(grammaticality), y = prob)) + geom_point() + geom_smooth(method = &quot;glm&quot;, method.args = list(family = &quot;binomial&quot;), se = T) + theme_bw(base_size = 20)+ labs(y = &quot;Probability&quot;, x = &quot;&quot;)+ coord_cartesian(ylim = c(0,1))+ scale_x_discrete(limits = c(&quot;Ungrammatical&quot;, &quot;Grammatical&quot;)) 3.4.3 GLM - Numeric predictors In this example, we will run a GLM model using a similar technique to that used in Al-Tamimi (2017) and Baumann &amp; Winter (2018). We use the package LanguageR and the dataset English. In the model above, we used the equation as lm(RTlexdec ~ AgeSubject). We were interested in examining the impact of age of subject on reaction time in a lexical decision task. In this section, we are interested in understanding how reaction time allows to differentiate the participants based on their age. We use AgeSubject as our outcome and RTlexdec as our predictor using the equation glm(AgeSubject ~ RTlexdec). We usually can use RTlexdec as is, but due to a possible quasi separation and the fact that we may want to compare coefficients using multiple acoustic metrics, we will z-score our predictor. We run below two models, with and without z-scoring For the glm model, we need to specify family = \"binomial\". 3.4.3.1 Without z-scoring of predictor 3.4.3.1.1 Model estimation mdl.glm2 &lt;- english2 %&gt;% glm(AgeSubject ~ RTlexdec, data = ., family = &quot;binomial&quot;) tidy(mdl.glm2) %&gt;% select(term, estimate) %&gt;% mutate(estimate = round(estimate, 3)) ## # A tibble: 2 × 2 ## term estimate ## &lt;chr&gt; &lt;dbl&gt; ## 1 (Intercept) -129. ## 2 RTlexdec 19.6 # to only get the coefficients mycoef2 &lt;- tidy(mdl.glm2) %&gt;% pull(estimate) 3.4.3.1.2 Model’s fit print(tab_model(mdl.glm2, file = paste0(&quot;outputs/mdl.glm2.html&quot;))) webshot(paste0(&quot;outputs/mdl.glm2.html&quot;), paste0(&quot;outputs/mdl.glm2.png&quot;)) Model fit: Generalised Linear model - Numeric 3.4.3.1.3 LogOdds to proportions If you want to talk about the percentage “accuracy” of our model, then we can transform our loggodds into proportions. plogis(mycoef2[1]) ## [1] 1.368844e-56 plogis(mycoef2[1] + mycoef2[2]) ## [1] 4.678715e-48 3.4.3.1.4 Plotting english2 &lt;- english2 %&gt;% mutate(prob = predict(mdl.glm2, type = &quot;response&quot;)) english2 %&gt;% ggplot(aes(x = as.numeric(AgeSubject), y = prob)) + geom_point() + geom_smooth(method = &quot;glm&quot;, method.args = list(family = &quot;binomial&quot;), se = T) + theme_bw(base_size = 20)+ labs(y = &quot;Probability&quot;, x = &quot;&quot;)+ coord_cartesian(ylim = c(0,1))+ scale_x_discrete(limits = c(&quot;Young&quot;, &quot;Old&quot;)) The plot above show how the two groups differ using a glm. The results point to an overall increase in the proportion of reaction time when moving from the “Young” to the “Old” group. Let’s use z-scoring next 3.4.3.2 With z-scoring of predictor 3.4.3.2.1 Model estimation english2 &lt;- english2 %&gt;% mutate(`RTlexdec_z` = scale(RTlexdec, center = TRUE, scale = TRUE)) english2[&#39;RTlexdec_z&#39;] &lt;- as.data.frame(scale(english2$RTlexdec)) mdl.glm3 &lt;- english2 %&gt;% glm(AgeSubject ~ RTlexdec_z, data = ., family = &quot;binomial&quot;) tidy(mdl.glm3) %&gt;% select(term, estimate) %&gt;% mutate(estimate = round(estimate, 3)) ## # A tibble: 2 × 2 ## term estimate ## &lt;chr&gt; &lt;dbl&gt; ## 1 (Intercept) 0.077 ## 2 RTlexdec_z 3.08 # to only get the coefficients mycoef2 &lt;- tidy(mdl.glm3) %&gt;% pull(estimate) 3.4.3.2.2 Model’s fit print(tab_model(mdl.glm3, file = paste0(&quot;outputs/mdl.glm3.html&quot;))) webshot(paste0(&quot;outputs/mdl.glm3.html&quot;), paste0(&quot;outputs/mdl.glm3.png&quot;)) Model fit: Generalised Linear model - Numeric - z-scores 3.4.3.2.3 LogOdds to proportions If you want to talk about the percentage “accuracy” of our model, then we can transform our loggodds into proportions. plogis(mycoef2[1]) ## [1] 0.5192147 plogis(mycoef2[1] + mycoef2[2]) ## [1] 0.959313 3.4.3.2.4 Plotting 3.4.3.2.4.1 Normal english2 &lt;- english2 %&gt;% mutate(prob = predict(mdl.glm3, type = &quot;response&quot;)) english2 %&gt;% ggplot(aes(x = as.numeric(AgeSubject), y = prob)) + geom_point() + geom_smooth(method = &quot;glm&quot;, method.args = list(family = &quot;binomial&quot;), se = T) + theme_bw(base_size = 20)+ labs(y = &quot;Probability&quot;, x = &quot;&quot;)+ coord_cartesian(ylim = c(0,1))+ scale_x_discrete(limits = c(&quot;Young&quot;, &quot;Old&quot;)) We obtain the exact same plots, but the model estimations are different. Let’s use another type of predictions 3.4.3.2.4.2 z-scores z_vals &lt;- seq(-3, 3, 0.01) dfPredNew &lt;- data.frame(RTlexdec_z = z_vals) ## store the predicted probabilities for each value of RTlexdec_z pp &lt;- cbind(dfPredNew, prob = predict(mdl.glm3, newdata = dfPredNew, type = &quot;response&quot;)) pp %&gt;% ggplot(aes(x = RTlexdec_z, y = prob)) + geom_point() + theme_bw(base_size = 20)+ labs(y = &quot;Probability&quot;, x = &quot;&quot;) + coord_cartesian(ylim = c(-0.1, 1.1), expand = FALSE) + scale_y_discrete(limits = c(0,1), labels = c(&quot;Young&quot;, &quot;Old&quot;)) + scale_x_continuous(breaks = c(-3, -2, -1, 0, 1, 2, 3)) We obtain the exact same plots, but the model estimations are different. 3.4.4 Accuracy and Signal Detection Theory 3.4.4.1 Rationale We are generally interested in performance, i.e., whether the we have “accurately” categorised the outcome or not and at the same time want to evaluate our biases in responses. When deciding on categories, we are usually biased in our selection. Let’s ask the question: How many of you have a Mac laptop and how many a Windows laptop? For those with a Mac, what was the main reason for choosing it? Are you biased in anyway by your decision? To correct for these biases, we use some variants from Signal Detection Theory to obtain the true estimates without being influenced by the biases. 3.4.4.2 Running stats Let’s do some stats on this Yes No Total Grammatical (Yes Actual) TP = 100 FN = 5 (Yes Actual) 105 Ungrammatical (No Actual) FP = 10 TN = 50 (No Actual) 60 Total (Yes Response) 110 (No Response) 55 165 grammatical &lt;- grammatical %&gt;% mutate(response = factor(response, levels = c(&quot;yes&quot;, &quot;no&quot;)), grammaticality = factor(grammaticality, levels = c(&quot;grammatical&quot;, &quot;ungrammatical&quot;))) 3.4.4.3 Below we obtain multiple measures 3.4.4.3.1 TP, FP, FN, TN TP = True Positive (Hit); FP = False Positive; FN = False Negative; TN = True Negative TP &lt;- nrow(grammatical %&gt;% filter(grammaticality == &quot;grammatical&quot; &amp; response == &quot;yes&quot;)) FN &lt;- nrow(grammatical %&gt;% filter(grammaticality == &quot;grammatical&quot; &amp; response == &quot;no&quot;)) FP &lt;- nrow(grammatical %&gt;% filter(grammaticality == &quot;ungrammatical&quot; &amp; response == &quot;yes&quot;)) TN &lt;- nrow(grammatical %&gt;% filter(grammaticality == &quot;ungrammatical&quot; &amp; response == &quot;no&quot;)) TP ## [1] 100 FN ## [1] 5 FP ## [1] 10 TN ## [1] 50 3.4.4.3.2 Accuracy, Error, Sensitivity, Specificity, Precision, etc. 3.4.4.3.2.1 Accuracy and Error (TP+TN)/nrow(grammatical) # accuracy ## [1] 0.9090909 (FP+FN)/nrow(grammatical) # error, also 1-accuracy ## [1] 0.09090909 3.4.4.3.2.2 Sensitivity, Specificity, Precision, etc. # When stimulus = yes, how many times response = yes? TP/(TP+FN) # also True Positive Rate or Specificity ## [1] 0.952381 # When stimulus = no, how many times response = yes? FP/(FP+TN) # False Positive Rate, ## [1] 0.1666667 # When stimulus = no, how many times response = no? TN/(FP+TN) # True Negative Rate or Sensitivity ## [1] 0.8333333 # When subject responds &quot;yes&quot; how many times is (s)he correct? TP/(TP+FP) # precision ## [1] 0.9090909 3.4.4.3.2.3 STD measures We can get various measures from Signal Detection Theory. using the package psycho. dprime (or the sensitivity index) beta (bias criterion, 0-1, lower = increase in “yes”) Aprime (estimate of discriminability, 0-1, 1 = good discrimination; 0 at chance) bppd (b prime prime d, -1 to 1; 0 = no bias, negative = tendency to respond “yes”, positive = tendency to respond “no”) c (index of bias, equals to SD) See here for more details psycho::dprime(TP, FP, FN, TN, n_targets = TP+FN, n_distractors = FP+TN, adjust=F) ## $dprime ## [1] 2.635813 ## ## $beta ## [1] 0.3970026 ## ## $aprime ## [1] 0.9419643 ## ## $bppd ## [1] -0.5076923 ## ## $c ## [1] -0.3504848 The most important from above, is d-prime. This is modelling the difference between the rate of “True Positive” responses and “False Positive” responses in standard unit (or z-scores). The formula can be written as: d' (d prime) = Z(True Positive Rate) - Z(False Positive Rate) 3.4.4.4 GLM and d prime The values obtained here match those obtained from SDT. For d prime, the difference stems from the use of the logit variant of the Binomial family. By using a probit variant, one obtains the same values (see here for more details). A probit variant models the z-score differences in the outcome and is evaluated in change in 1-standard unit. This is modelling the change from “ungrammatical” “no” responses into “grammatical” “yes” responses in z-scores. The same conceptual underpinnings of d-prime from Signal Detection Theory. ## d prime psycho::dprime(TP, FP, FN, TN, n_targets = TP+FN, n_distractors = FP+TN, adjust=F)$dprime ## [1] 2.635813 ## GLM with probit coef(glm(response ~ grammaticality, data = grammatical, family = binomial(probit)))[2] ## grammaticalityungrammatical ## 2.635813 3.4.4.5 GLM as a classification tool The code below demonstrates the links between our GLM model and what we had obtained above from SDT. The predictions’ table shows that our GLM was successful at obtaining prediction that are identical to our initial data setup. Look at the table here and the table above. Once we have created our table of outcome, we can compute percent correct, the specificity, the sensitivity, the Kappa score, etc.. this yields the actual value with the SD that is related to variations in responses. ## predict(mdl.glm)&gt;0.5 is identical to ## predict(glm(response~grammaticality,data=grammatical,family = binomial),type=&quot;response&quot;) grammatical &lt;- grammatical %&gt;% mutate(response = factor(response, levels = c(&quot;yes&quot;, &quot;no&quot;)), grammaticality = factor(grammaticality, levels = c(&quot;grammatical&quot;, &quot;ungrammatical&quot;))) mdl.glm.C &lt;- grammatical %&gt;% glm(response ~ grammaticality, data = .,family = binomial) tbl.glm &lt;- table(grammatical$response, predict(mdl.glm.C, type = &quot;response&quot;)&gt;0.5) colnames(tbl.glm) &lt;- c(&quot;grammatical&quot;, &quot;ungrammatical&quot;) tbl.glm ## ## grammatical ungrammatical ## yes 100 10 ## no 5 50 PresenceAbsence::pcc(tbl.glm) ## PCC PCC.sd ## 1 0.9090909 0.0224484 PresenceAbsence::specificity(tbl.glm) ## specificity specificity.sd ## 1 0.8333333 0.04851854 PresenceAbsence::sensitivity(tbl.glm) ## sensitivity sensitivity.sd ## 1 0.952381 0.02088233 ###etc.. If you look at the results from SDT above, these results are the same as the following Accuracy: (TP+TN)/Total (0.9090909) True Positive Rate (or Specificity) TP/(TP+FN) (0.952381) True Negative Rate (or Sensitivity) TN/(FP+TN) (0.8333333) 3.4.4.6 GLM: Other distributions If your data does not fit a binomial distribution, and is a multinomial (i.e., three or more response categories) or poisson (count data), then you need to use the glm function with a specific family function. "],["3.5-cumulative-logit-link-models.html", "3.5 Cumulative Logit Link Models", " 3.5 Cumulative Logit Link Models These models work perfectly with rating data. Ratings are inherently ordered, 1, 2, … n, and expect to observe an increase (or decrease) in overall ratings from 1 to n. To demonstrate this, we will use an example using the package “ordinal”. We use two datasets. We previously ran these two models, however, in this subset of the full dataset, we did not take into account the fact that there were multiple producing speakers and items. 3.5.1 Ratings of percept of nasality The first comes from a likert-scale a rating experiment where six participants rated the percept of nasality in the production of particular consonants in Arabic. The data came from nine producing subjects. The ratings were from 1 to 5, with 1 reflecting an oral percept; 5 a nasal percept. 3.5.1.1 Importing and pre-processing We start by importing the data and process it. We change the reference level in the predictor rating &lt;- read_csv(&quot;data/rating.csv&quot;)[-1] rating ## # A tibble: 405 × 5 ## Response Context Subject Item Rater ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2 n-3 p04 noo3-w R01 ## 2 4 isolation p04 noo3-v R01 ## 3 2 o-3 p04 djuu3-w R01 ## 4 4 isolation p04 djuu3-v R01 ## 5 3 n-7 p04 nuu7-w R01 ## 6 3 isolation p04 nuu7-v R01 ## 7 1 3--3 p04 3oo3-w R01 ## 8 2 isolation p04 3oo3-v R01 ## 9 2 o-7 p04 loo7-w R01 ## 10 1 o-3 p04 bii3-w R01 ## # ℹ 395 more rows rating &lt;- rating %&gt;% mutate(Response = factor(Response), Context = factor(Context)) %&gt;% mutate(Context = relevel(Context, &quot;isolation&quot;)) rating ## # A tibble: 405 × 5 ## Response Context Subject Item Rater ## &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2 n-3 p04 noo3-w R01 ## 2 4 isolation p04 noo3-v R01 ## 3 2 o-3 p04 djuu3-w R01 ## 4 4 isolation p04 djuu3-v R01 ## 5 3 n-7 p04 nuu7-w R01 ## 6 3 isolation p04 nuu7-v R01 ## 7 1 3--3 p04 3oo3-w R01 ## 8 2 isolation p04 3oo3-v R01 ## 9 2 o-7 p04 loo7-w R01 ## 10 1 o-3 p04 bii3-w R01 ## # ℹ 395 more rows 3.5.1.2 Our first model We run our first clm model as a simple, i.e., with no random effects mdl.clm &lt;- rating %&gt;% clm(Response ~ Context, data = .) summary(mdl.clm) ## formula: Response ~ Context ## data: . ## ## link threshold nobs logLik AIC niter max.grad cond.H ## logit flexible 405 -526.16 1086.31 5(0) 3.61e-09 1.3e+02 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## Context3--3 -0.1384 0.5848 -0.237 0.8130 ## Context3-n 3.5876 0.4721 7.600 2.96e-14 *** ## Context3-o -0.4977 0.3859 -1.290 0.1971 ## Context7-n 2.3271 0.5079 4.582 4.60e-06 *** ## Context7-o 0.2904 0.4002 0.726 0.4680 ## Contextn-3 2.8957 0.6685 4.331 1.48e-05 *** ## Contextn-7 2.2678 0.4978 4.556 5.22e-06 *** ## Contextn-n 2.8697 0.4317 6.647 2.99e-11 *** ## Contextn-o 3.5152 0.4397 7.994 1.30e-15 *** ## Contexto-3 -0.2540 0.4017 -0.632 0.5272 ## Contexto-7 -0.6978 0.3769 -1.851 0.0641 . ## Contexto-n 2.9640 0.4159 7.126 1.03e-12 *** ## Contexto-o -0.6147 0.3934 -1.562 0.1182 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Threshold coefficients: ## Estimate Std. Error z value ## 1|2 -1.4615 0.2065 -7.077 ## 2|3 0.4843 0.1824 2.655 ## 3|4 1.5492 0.2044 7.578 ## 4|5 3.1817 0.2632 12.089 3.5.1.3 Testing significance We can evaluate whether “Context” improves the model fit, by comparing a null model with our model. Of course “Context” is improving the model fit. mdl.clm.Null &lt;- rating %&gt;% clm(Response ~ 1, data = .) anova(mdl.clm, mdl.clm.Null) ## Likelihood ratio tests of cumulative link models: ## ## formula: link: threshold: ## mdl.clm.Null Response ~ 1 logit flexible ## mdl.clm Response ~ Context logit flexible ## ## no.par AIC logLik LR.stat df Pr(&gt;Chisq) ## mdl.clm.Null 4 1281.1 -636.56 ## mdl.clm 17 1086.3 -526.16 220.8 13 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 3.5.1.4 Model’s fit print(tab_model(mdl.clm, file = paste0(&quot;outputs/mdl.clm.html&quot;))) webshot(paste0(&quot;outputs/mdl.clm.html&quot;), paste0(&quot;outputs/mdl.clm.png&quot;)) Model fit: Cumulative Logit model 3.5.1.5 Interpreting a cumulative model As a way to interpret the model, we can look at the coefficients and make sense of the results. A CLM model is a Logistic model with a cumulative effect. The “Coefficients” are the estimates for each level of the fixed effect; the “Threshold coefficients” are those of the response. For the former, a negative coefficient indicates a negative association with the response; and a positive is positively associated with the response. The p values are indicating the significance of each level. For the “Threshold coefficients”, we can see the cumulative effects of ratings 1|2, 2|3, 3|4 and 4|5 which indicate an overall increase in the ratings from 1 to 5. 3.5.1.5.1 Plotting 3.5.1.5.2 No confidence intervals We use a modified version of a plotting function that allows us to visualise the effects. For this, we use the base R plotting functions. The version below is without confidence intervals. par(oma=c(1, 0, 0, 3),mgp=c(2, 1, 0)) xlimNas = c(min(mdl.clm$beta), max(mdl.clm$beta)) ylimNas = c(0,1) plot(0,0,xlim=xlimNas, ylim=ylimNas, type=&quot;n&quot;, ylab=expression(Probability), xlab=&quot;&quot;, xaxt = &quot;n&quot;,main=&quot;Predicted curves - Nasalisation&quot;,cex=2,cex.lab=1.5,cex.main=1.5,cex.axis=1.5) axis(side = 1, at = c(0,mdl.clm$beta),labels = levels(rating$Context), las=2,cex=2,cex.lab=1.5,cex.axis=1.5) xsNas = seq(xlimNas[1], xlimNas[2], length.out=100) lines(xsNas, plogis(mdl.clm$Theta[1] - xsNas), col=&#39;black&#39;) lines(xsNas, plogis(mdl.clm$Theta[2] - xsNas)-plogis(mdl.clm$Theta[1] - xsNas), col=&#39;red&#39;) lines(xsNas, plogis(mdl.clm$Theta[3] - xsNas)-plogis(mdl.clm$Theta[2] - xsNas), col=&#39;green&#39;) lines(xsNas, plogis(mdl.clm$Theta[4] - xsNas)-plogis(mdl.clm$Theta[3] - xsNas), col=&#39;orange&#39;) lines(xsNas, 1-(plogis(mdl.clm$Theta[4] - xsNas)), col=&#39;blue&#39;) abline(v=c(0,mdl.clm$beta),lty=3) abline(h=0, lty=&quot;dashed&quot;) abline(h=0.2, lty=&quot;dashed&quot;) abline(h=0.4, lty=&quot;dashed&quot;) abline(h=0.6, lty=&quot;dashed&quot;) abline(h=0.8, lty=&quot;dashed&quot;) abline(h=1, lty=&quot;dashed&quot;) legend(par(&#39;usr&#39;)[2], par(&#39;usr&#39;)[4], bty=&#39;n&#39;, xpd=NA,lty=1, col=c(&quot;black&quot;, &quot;red&quot;, &quot;green&quot;, &quot;orange&quot;, &quot;blue&quot;), legend=c(&quot;Oral&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;Nasal&quot;),cex=0.75) 3.5.1.5.3 With confidence intervals Here is an attempt to add the 97.5% confidence intervals to these plots. This is an experimental attempt and any feedback is welcome! par(oma=c(1, 0, 0, 3),mgp=c(2, 1, 0)) xlimNas = c(min(mdl.clm$beta), max(mdl.clm$beta)) ylimNas = c(0,1) plot(0,0,xlim=xlimNas, ylim=ylimNas, type=&quot;n&quot;, ylab=expression(Probability), xlab=&quot;&quot;, xaxt = &quot;n&quot;,main=&quot;Predicted curves - Nasalisation&quot;,cex=2,cex.lab=1.5,cex.main=1.5,cex.axis=1.5) axis(side = 1, at = c(0,mdl.clm$beta),labels = levels(rating$Context), las=2,cex=2,cex.lab=1.5,cex.axis=1.5) xsNas = seq(xlimNas[1], xlimNas[2], length.out=100) #+CI lines(xsNas, plogis(mdl.clm$Theta[1]+(summary(mdl.clm)$coefficient[,2][[1]]/1.96) - xsNas), col=&#39;black&#39;) lines(xsNas, plogis(mdl.clm$Theta[2]+(summary(mdl.clm)$coefficient[,2][[2]]/1.96) - xsNas)-plogis(mdl.clm$Theta[1]+(summary(mdl.clm)$coefficient[,2][[1]]/1.96) - xsNas), col=&#39;red&#39;) lines(xsNas, plogis(mdl.clm$Theta[3]+(summary(mdl.clm)$coefficient[,2][[3]]/1.96) - xsNas)-plogis(mdl.clm$Theta[2]+(summary(mdl.clm)$coefficient[,2][[2]]/1.96) - xsNas), col=&#39;green&#39;) lines(xsNas, plogis(mdl.clm$Theta[4]+(summary(mdl.clm)$coefficient[,2][[4]]/1.96) - xsNas)-plogis(mdl.clm$Theta[3]+(summary(mdl.clm)$coefficient[,2][[3]]/1.96) - xsNas), col=&#39;orange&#39;) lines(xsNas, 1-(plogis(mdl.clm$Theta[4]+(summary(mdl.clm)$coefficient[,2][[4]]/1.96) - xsNas)), col=&#39;blue&#39;) #-CI lines(xsNas, plogis(mdl.clm$Theta[1]-(summary(mdl.clm)$coefficient[,2][[1]]/1.96) - xsNas), col=&#39;black&#39;) lines(xsNas, plogis(mdl.clm$Theta[2]-(summary(mdl.clm)$coefficient[,2][[2]]/1.96) - xsNas)-plogis(mdl.clm$Theta[1]-(summary(mdl.clm)$coefficient[,2][[1]]/1.96) - xsNas), col=&#39;red&#39;) lines(xsNas, plogis(mdl.clm$Theta[3]-(summary(mdl.clm)$coefficient[,2][[3]]/1.96) - xsNas)-plogis(mdl.clm$Theta[2]-(summary(mdl.clm)$coefficient[,2][[2]]/1.96) - xsNas), col=&#39;green&#39;) lines(xsNas, plogis(mdl.clm$Theta[4]-(summary(mdl.clm)$coefficient[,2][[4]]/1.96) - xsNas)-plogis(mdl.clm$Theta[3]-(summary(mdl.clm)$coefficient[,2][[3]]/1.96) - xsNas), col=&#39;orange&#39;) lines(xsNas, 1-(plogis(mdl.clm$Theta[4]-(summary(mdl.clm)$coefficient[,2][[4]]/1.96) - xsNas)), col=&#39;blue&#39;) # fill area around CI using c(x, rev(x)), c(y2, rev(y1)) polygon(c(xsNas, rev(xsNas)), c(plogis(mdl.clm$Theta[1]+(summary(mdl.clm)$coefficient[,2][[1]]/1.96) - xsNas), rev(plogis(mdl.clm$Theta[1]-(summary(mdl.clm)$coefficient[,2][[1]]/1.96) - xsNas))), col = &quot;gray90&quot;) polygon(c(xsNas, rev(xsNas)), c(plogis(mdl.clm$Theta[2]+(summary(mdl.clm)$coefficient[,2][[2]]/1.96) - xsNas)-plogis(mdl.clm$Theta[1]+(summary(mdl.clm)$coefficient[,2][[1]]/1.96) - xsNas), rev(plogis(mdl.clm$Theta[2]-(summary(mdl.clm)$coefficient[,2][[2]]/1.96) - xsNas)-plogis(mdl.clm$Theta[1]-(summary(mdl.clm)$coefficient[,2][[1]]/1.96) - xsNas))), col = &quot;gray90&quot;) polygon(c(xsNas, rev(xsNas)), c(plogis(mdl.clm$Theta[3]+(summary(mdl.clm)$coefficient[,2][[3]]/1.96) - xsNas)-plogis(mdl.clm$Theta[2]+(summary(mdl.clm)$coefficient[,2][[2]]/1.96) - xsNas), rev(plogis(mdl.clm$Theta[3]-(summary(mdl.clm)$coefficient[,2][[3]]/1.96) - xsNas)-plogis(mdl.clm$Theta[2]-(summary(mdl.clm)$coefficient[,2][[2]]/1.96) - xsNas))), col = &quot;gray90&quot;) polygon(c(xsNas, rev(xsNas)), c(plogis(mdl.clm$Theta[4]+(summary(mdl.clm)$coefficient[,2][[4]]/1.96) - xsNas)-plogis(mdl.clm$Theta[3]+(summary(mdl.clm)$coefficient[,2][[3]]/1.96) - xsNas), rev(plogis(mdl.clm$Theta[4]-(summary(mdl.clm)$coefficient[,2][[4]]/1.96) - xsNas)-plogis(mdl.clm$Theta[3]-(summary(mdl.clm)$coefficient[,2][[3]]/1.96) - xsNas))), col = &quot;gray90&quot;) polygon(c(xsNas, rev(xsNas)), c(1-(plogis(mdl.clm$Theta[4]-(summary(mdl.clm)$coefficient[,2][[4]]/1.96) - xsNas)), rev(1-(plogis(mdl.clm$Theta[4]+(summary(mdl.clm)$coefficient[,2][[4]]/1.96) - xsNas)))), col = &quot;gray90&quot;) lines(xsNas, plogis(mdl.clm$Theta[1] - xsNas), col=&#39;black&#39;) lines(xsNas, plogis(mdl.clm$Theta[2] - xsNas)-plogis(mdl.clm$Theta[1] - xsNas), col=&#39;red&#39;) lines(xsNas, plogis(mdl.clm$Theta[3] - xsNas)-plogis(mdl.clm$Theta[2] - xsNas), col=&#39;green&#39;) lines(xsNas, plogis(mdl.clm$Theta[4] - xsNas)-plogis(mdl.clm$Theta[3] - xsNas), col=&#39;orange&#39;) lines(xsNas, 1-(plogis(mdl.clm$Theta[4] - xsNas)), col=&#39;blue&#39;) abline(v=c(0,mdl.clm$beta),lty=3) abline(h=0, lty=&quot;dashed&quot;) abline(h=0.2, lty=&quot;dashed&quot;) abline(h=0.4, lty=&quot;dashed&quot;) abline(h=0.6, lty=&quot;dashed&quot;) abline(h=0.8, lty=&quot;dashed&quot;) abline(h=1, lty=&quot;dashed&quot;) legend(par(&#39;usr&#39;)[2], par(&#39;usr&#39;)[4], bty=&#39;n&#39;, xpd=NA,lty=1, col=c(&quot;black&quot;, &quot;red&quot;, &quot;green&quot;, &quot;orange&quot;, &quot;blue&quot;), legend=c(&quot;Oral&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;Nasal&quot;),cex=0.75) 3.5.2 Subjective estimates of the weight of the referents of 81 English nouns. This dataset comes from the LanguageR package. It contains the subjective estimates of the weight of the referents of 81 English nouns. This dataset is a little complex. Data comes from multiple subjects who rated 81 nouns. The nouns are from a a class of animals and plants. The subjects are either males or females. We can model it in various ways. Here we decided to explore whether the ratings given to a particular word are different, when the class is either animal or a plant and if males rated the nouns differently from males. 3.5.2.1 Importing and pre-processing weightRatings &lt;- weightRatings %&gt;% mutate(Rating = factor(Rating), Sex = factor(Sex), Class = factor(Class)) weightRatings %&gt;% head(10) ## Subject Rating Trial Sex Word Frequency Class ## 1 A1 5 1 F horse 7.771910 animal ## 2 A1 1 2 F gherkin 2.079442 plant ## 3 A1 3 3 F hedgehog 3.637586 animal ## 4 A1 1 4 F bee 5.700444 animal ## 5 A1 1 5 F peanut 4.595120 plant ## 6 A1 2 6 F pear 4.727388 plant ## 7 A1 3 7 F pineapple 3.988984 plant ## 8 A1 2 8 F frog 5.129899 animal ## 9 A1 1 9 F blackberry 4.060443 plant ## 10 A1 3 10 F pigeon 5.262690 animal 3.5.2.2 Model specifications 3.5.2.2.1 No random effects We run our first clm model as a simple, i.e., with no random effects system.time(mdl.clm &lt;- weightRatings %&gt;% clm(Rating ~ Class * Sex * Frequency, data = .)) ## user system elapsed ## 0.08 0.02 0.08 summary(mdl.clm) ## formula: Rating ~ Class * Sex * Frequency ## data: . ## ## link threshold nobs logLik AIC niter max.grad cond.H ## logit flexible 1620 -2387.08 4800.16 6(0) 1.99e-13 1.7e+04 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## Classplant -1.16225 0.44191 -2.630 0.00854 ** ## SexM -0.68152 0.55688 -1.224 0.22102 ## Frequency 0.23871 0.05694 4.192 2.77e-05 *** ## Classplant:SexM 0.38258 0.82629 0.463 0.64336 ## Classplant:Frequency -0.26492 0.09231 -2.870 0.00410 ** ## SexM:Frequency 0.07563 0.10527 0.718 0.47251 ## Classplant:SexM:Frequency -0.08114 0.17315 -0.469 0.63934 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Threshold coefficients: ## Estimate Std. Error z value ## 1|2 -0.8614 0.3025 -2.848 ## 2|3 0.5553 0.2985 1.861 ## 3|4 1.5121 0.3021 5.005 ## 4|5 2.2185 0.3081 7.200 ## 5|6 3.0602 0.3169 9.657 ## 6|7 3.8655 0.3304 11.698 3.5.2.3 Testing significance We can evaluate whether “Context” improves the model fit, by comparing a null model with our model. Of course “Context” is improving the model fit. mdl.clm.Null &lt;- weightRatings %&gt;% clm(Rating ~ 1, data = .) 3.5.2.3.1 Null vs no random anova(mdl.clm, mdl.clm.Null) ## Likelihood ratio tests of cumulative link models: ## ## formula: link: threshold: ## mdl.clm.Null Rating ~ 1 logit flexible ## mdl.clm Rating ~ Class * Sex * Frequency logit flexible ## ## no.par AIC logLik LR.stat df Pr(&gt;Chisq) ## mdl.clm.Null 6 5430.2 -2709.1 ## mdl.clm 13 4800.2 -2387.1 644.05 7 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The model comparison above shows that our full model is enough. 3.5.2.4 Model’s fit print(tab_model(mdl.clm, file = paste0(&quot;outputs/mdl.clm.html&quot;))) webshot(paste0(&quot;outputs/mdl.clm.html&quot;), paste0(&quot;outputs/mdl.clm.png&quot;)) Model fit: Cumulative Logit model 3.5.2.5 Interpreting a cumulative model As a way to interpret the model, we can look at the coefficients and make sense of the results. A CLM model is a Logistic model with a cumulative effect. The “Coefficients” are the estimates for each level of the fixed effect; the “Threshold coefficients” are those of the response. For the former, a negative coefficient indicates a negative association with the response; and a positive is positively associated with the response. The p values are indicating the significance of each level. For the “Threshold coefficients”, we can see the cumulative effects of ratings 1|2, 2|3, 3|4 and 4|5 which indicate an overall increase in the ratings from 1 to 5. 3.5.2.6 Plotting 3.5.2.6.1 No confidence intervals We use a modified version of a plotting function that allows us to visualise the effects. For this, we use the base R plotting functions. The version below is without confidence intervals. par(oma = c(4, 0, 0, 3), mgp = c(2, 1, 0)) xlim = c(min(mdl.clm$beta), max(mdl.clm$beta)) ylim = c(0, 1) plot(0, 0, xlim = xlim, ylim = ylim, type = &quot;n&quot;, ylab = expression(Probability), xlab = &quot;&quot;, xaxt = &quot;n&quot;, main = &quot;Predicted curves&quot;, cex = 2, cex.lab = 1.5, cex.main = 1.5, cex.axis = 1.5) axis(side = 1, at = mdl.clm$beta, labels = names(mdl.clm$beta), las = 2, cex = 0.75, cex.lab = 0.75, cex.axis = 0.75) xs = seq(xlim[1], xlim[2], length.out = 100) lines(xs, plogis(mdl.clm$Theta[1] - xs), col = &#39;black&#39;) lines(xs, plogis(mdl.clm$Theta[2] - xs) - plogis(mdl.clm$Theta[1] - xs), col = &#39;red&#39;) lines(xs, plogis(mdl.clm$Theta[3] - xs) - plogis(mdl.clm$Theta[2] - xs), col = &#39;green&#39;) lines(xs, plogis(mdl.clm$Theta[4] - xs) - plogis(mdl.clm$Theta[3] - xs), col = &#39;orange&#39;) lines(xs, plogis(mdl.clm$Theta[5] - xs) - plogis(mdl.clm$Theta[4] - xs), col = &#39;yellow&#39;) lines(xs, plogis(mdl.clm$Theta[6] - xs) - plogis(mdl.clm$Theta[5] - xs), col = &#39;grey&#39;) lines(xs, 1 - (plogis(mdl.clm$Theta[6] - xs)), col = &#39;blue&#39;) abline(v = c(0,mdl.clm$beta),lty = 3) abline(h = 0, lty = &quot;dashed&quot;) abline(h = 0.2, lty = &quot;dashed&quot;) abline(h = 0.4, lty = &quot;dashed&quot;) abline(h = 0.6, lty = &quot;dashed&quot;) abline(h = 0.8, lty = &quot;dashed&quot;) abline(h = 1, lty = &quot;dashed&quot;) legend(par(&#39;usr&#39;)[2], par(&#39;usr&#39;)[4], bty = &#39;n&#39;, xpd = NA, lty = 1, col = c(&quot;black&quot;, &quot;red&quot;, &quot;green&quot;, &quot;orange&quot;, &quot;yellow&quot;, &quot;grey&quot;, &quot;blue&quot;), legend = c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;, &quot;6&quot;, &quot;7&quot;), cex = 0.75) 3.5.2.6.2 With confidence intervals Here is an attempt to add the 97.5% confidence intervals to these plots. This is an experimental attempt and any feedback is welcome! par(oma = c(4, 0, 0, 3), mgp = c(2, 1, 0)) xlim = c(min(mdl.clm$beta), max(mdl.clm$beta)) ylim = c(0, 1) plot(0, 0, xlim = xlim, ylim = ylim, type = &quot;n&quot;, ylab = expression(Probability), xlab = &quot;&quot;, xaxt = &quot;n&quot;, main = &quot;Predicted curves&quot;, cex = 2, cex.lab = 1.5, cex.main = 1.5, cex.axis = 1.5) axis(side = 1, at = mdl.clm$beta, labels = names(mdl.clm$beta), las = 2, cex = 0.75, cex.lab = 0.75, cex.axis = 0.75) xs = seq(xlim[1], xlim[2], length.out = 100) #+CI lines(xs, plogis(mdl.clm$Theta[1]+(summary(mdl.clm)$coefficient[,2][[1]]/1.96) - xs), col=&#39;black&#39;) lines(xs, plogis(mdl.clm$Theta[2]+(summary(mdl.clm)$coefficient[,2][[2]]/1.96) - xs)-plogis(mdl.clm$Theta[1]+(summary(mdl.clm)$coefficient[,2][[1]]/1.96) - xs), col=&#39;red&#39;) lines(xs, plogis(mdl.clm$Theta[3]+(summary(mdl.clm)$coefficient[,2][[3]]/1.96) - xs)-plogis(mdl.clm$Theta[2]+(summary(mdl.clm)$coefficient[,2][[2]]/1.96) - xs), col=&#39;green&#39;) lines(xs, plogis(mdl.clm$Theta[4]+(summary(mdl.clm)$coefficient[,2][[4]]/1.96) - xs)-plogis(mdl.clm$Theta[3]+(summary(mdl.clm)$coefficient[,2][[3]]/1.96) - xs), col=&#39;orange&#39;) lines(xs, plogis(mdl.clm$Theta[5]-(summary(mdl.clm)$coefficient[,2][[5]]/1.96) - xs)-plogis(mdl.clm$Theta[4]-(summary(mdl.clm)$coefficient[,2][[4]]/1.96) - xs), col=&#39;yellow&#39;) lines(xs, plogis(mdl.clm$Theta[6]-(summary(mdl.clm)$coefficient[,2][[6]]/1.96) - xs)-plogis(mdl.clm$Theta[5]-(summary(mdl.clm)$coefficient[,2][[5]]/1.96) - xs), col=&#39;grey&#39;) lines(xs, 1-(plogis(mdl.clm$Theta[6]-(summary(mdl.clm)$coefficient[,2][[6]]/1.96) - xs)), col=&#39;blue&#39;) #-CI lines(xs, plogis(mdl.clm$Theta[1]-(summary(mdl.clm)$coefficient[,2][[1]]/1.96) - xs), col=&#39;black&#39;) lines(xs, plogis(mdl.clm$Theta[2]-(summary(mdl.clm)$coefficient[,2][[2]]/1.96) - xs)-plogis(mdl.clm$Theta[1]-(summary(mdl.clm)$coefficient[,2][[1]]/1.96) - xs), col=&#39;red&#39;) lines(xs, plogis(mdl.clm$Theta[3]-(summary(mdl.clm)$coefficient[,2][[3]]/1.96) - xs)-plogis(mdl.clm$Theta[2]-(summary(mdl.clm)$coefficient[,2][[2]]/1.96) - xs), col=&#39;green&#39;) lines(xs, plogis(mdl.clm$Theta[4]-(summary(mdl.clm)$coefficient[,2][[4]]/1.96) - xs)-plogis(mdl.clm$Theta[3]-(summary(mdl.clm)$coefficient[,2][[3]]/1.96) - xs), col=&#39;orange&#39;) lines(xs, plogis(mdl.clm$Theta[5]-(summary(mdl.clm)$coefficient[,2][[5]]/1.96) - xs)-plogis(mdl.clm$Theta[4]-(summary(mdl.clm)$coefficient[,2][[4]]/1.96) - xs), col=&#39;yellow&#39;) lines(xs, plogis(mdl.clm$Theta[6]-(summary(mdl.clm)$coefficient[,2][[6]]/1.96) - xs)-plogis(mdl.clm$Theta[5]-(summary(mdl.clm)$coefficient[,2][[5]]/1.96) - xs), col=&#39;grey&#39;) lines(xs, 1-(plogis(mdl.clm$Theta[6]-(summary(mdl.clm)$coefficient[,2][[6]]/1.96) - xs)), col=&#39;blue&#39;) ## fill area around CI using c(x, rev(x)), c(y2, rev(y1)) polygon(c(xs, rev(xs)), c(plogis(mdl.clm$Theta[1]+(summary(mdl.clm)$coefficient[,2][[1]]/1.96) - xs), rev(plogis(mdl.clm$Theta[1]-(summary(mdl.clm)$coefficient[,2][[1]]/1.96) - xs))), col = &quot;gray90&quot;) polygon(c(xs, rev(xs)), c(plogis(mdl.clm$Theta[2]+(summary(mdl.clm)$coefficient[,2][[2]]/1.96) - xs)-plogis(mdl.clm$Theta[1]+(summary(mdl.clm)$coefficient[,2][[1]]/1.96) - xs), rev(plogis(mdl.clm$Theta[2]-(summary(mdl.clm)$coefficient[,2][[2]]/1.96) - xs)-plogis(mdl.clm$Theta[1]-(summary(mdl.clm)$coefficient[,2][[1]]/1.96) - xs))), col = &quot;gray90&quot;) polygon(c(xs, rev(xs)), c(plogis(mdl.clm$Theta[3]+(summary(mdl.clm)$coefficient[,2][[3]]/1.96) - xs)-plogis(mdl.clm$Theta[2]+(summary(mdl.clm)$coefficient[,2][[2]]/1.96) - xs), rev(plogis(mdl.clm$Theta[3]-(summary(mdl.clm)$coefficient[,2][[3]]/1.96) - xs)-plogis(mdl.clm$Theta[2]-(summary(mdl.clm)$coefficient[,2][[2]]/1.96) - xs))), col = &quot;gray90&quot;) polygon(c(xs, rev(xs)), c(plogis(mdl.clm$Theta[4]+(summary(mdl.clm)$coefficient[,2][[4]]/1.96) - xs)-plogis(mdl.clm$Theta[3]+(summary(mdl.clm)$coefficient[,2][[3]]/1.96) - xs), rev(plogis(mdl.clm$Theta[4]-(summary(mdl.clm)$coefficient[,2][[4]]/1.96) - xs)-plogis(mdl.clm$Theta[3]-(summary(mdl.clm)$coefficient[,2][[3]]/1.96) - xs))), col = &quot;gray90&quot;) polygon(c(xs, rev(xs)), c(plogis(mdl.clm$Theta[5]+(summary(mdl.clm)$coefficient[,2][[5]]/1.96) - xs)-plogis(mdl.clm$Theta[4]+(summary(mdl.clm)$coefficient[,2][[4]]/1.96) - xs), rev(plogis(mdl.clm$Theta[5]-(summary(mdl.clm)$coefficient[,2][[5]]/1.96) - xs)-plogis(mdl.clm$Theta[4]-(summary(mdl.clm)$coefficient[,2][[4]]/1.96) - xs))), col = &quot;gray90&quot;) polygon(c(xs, rev(xs)), c(plogis(mdl.clm$Theta[6]+(summary(mdl.clm)$coefficient[,2][[6]]/1.96) - xs)-plogis(mdl.clm$Theta[5]+(summary(mdl.clm)$coefficient[,2][[5]]/1.96) - xs), rev(plogis(mdl.clm$Theta[6]-(summary(mdl.clm)$coefficient[,2][[6]]/1.96) - xs)-plogis(mdl.clm$Theta[5]-(summary(mdl.clm)$coefficient[,2][[5]]/1.96) - xs))), col = &quot;gray90&quot;) polygon(c(xs, rev(xs)), c(1-(plogis(mdl.clm$Theta[6]-(summary(mdl.clm)$coefficient[,2][[6]]/1.96) - xs)), rev(1-(plogis(mdl.clm$Theta[6]+(summary(mdl.clm)$coefficient[,2][[6]]/1.96) - xs)))), col = &quot;gray90&quot;) lines(xs, plogis(mdl.clm$Theta[1] - xs), col = &#39;black&#39;) lines(xs, plogis(mdl.clm$Theta[2] - xs) - plogis(mdl.clm$Theta[1] - xs), col = &#39;red&#39;) lines(xs, plogis(mdl.clm$Theta[3] - xs) - plogis(mdl.clm$Theta[2] - xs), col = &#39;green&#39;) lines(xs, plogis(mdl.clm$Theta[4] - xs) - plogis(mdl.clm$Theta[3] - xs), col = &#39;orange&#39;) lines(xs, plogis(mdl.clm$Theta[5] - xs) - plogis(mdl.clm$Theta[4] - xs), col = &#39;yellow&#39;) lines(xs, plogis(mdl.clm$Theta[6] - xs) - plogis(mdl.clm$Theta[5] - xs), col = &#39;grey&#39;) lines(xs, 1 - (plogis(mdl.clm$Theta[6] - xs)), col = &#39;blue&#39;) abline(v = c(0,mdl.clm$beta),lty = 3) abline(h = 0, lty = &quot;dashed&quot;) abline(h = 0.2, lty = &quot;dashed&quot;) abline(h = 0.4, lty = &quot;dashed&quot;) abline(h = 0.6, lty = &quot;dashed&quot;) abline(h = 0.8, lty = &quot;dashed&quot;) abline(h = 1, lty = &quot;dashed&quot;) legend(par(&#39;usr&#39;)[2], par(&#39;usr&#39;)[4], bty = &#39;n&#39;, xpd = NA, lty = 1, col = c(&quot;black&quot;, &quot;red&quot;, &quot;green&quot;, &quot;orange&quot;, &quot;yellow&quot;, &quot;grey&quot;, &quot;blue&quot;), legend = c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;, &quot;6&quot;, &quot;7&quot;), cex = 0.75) "],["3.6-session-info-1.html", "3.6 session info", " 3.6 session info sessionInfo() ## R version 4.4.2 (2024-10-31 ucrt) ## Platform: x86_64-w64-mingw32/x64 ## Running under: Windows 11 x64 (build 26100) ## ## Matrix products: default ## ## ## locale: ## [1] LC_COLLATE=English_United Kingdom.utf8 ## [2] LC_CTYPE=English_United Kingdom.utf8 ## [3] LC_MONETARY=English_United Kingdom.utf8 ## [4] LC_NUMERIC=C ## [5] LC_TIME=English_United Kingdom.utf8 ## ## time zone: Europe/Paris ## tzcode source: internal ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] webshot_0.5.5 sjPlot_2.8.17 DHARMa_0.4.7 ## [4] ordinal_2023.12-4.1 psycho_0.6.1 PresenceAbsence_1.1.11 ## [7] ggsignif_0.6.4 emmeans_1.10.5 corrplot_0.95 ## [10] Hmisc_5.2-1 knitr_1.49 broom_1.0.7 ## [13] summarytools_1.0.1 phonR_1.0-7 languageR_1.5.0 ## [16] lubridate_1.9.4 forcats_1.0.0 stringr_1.5.1 ## [19] dplyr_1.1.4 purrr_1.0.2 readr_2.1.5 ## [22] tidyr_1.3.1 tibble_3.2.1 ggplot2_3.5.1 ## [25] tidyverse_2.0.0 ## ## loaded via a namespace (and not attached): ## [1] Rdpack_2.6.2 gridExtra_2.3 tcltk_4.4.2 ## [4] sandwich_3.1-1 rlang_1.1.4 magrittr_2.0.3 ## [7] multcomp_1.4-26 matrixStats_1.4.1 compiler_4.4.2 ## [10] mgcv_1.9-1 callr_3.7.6 vctrs_0.6.5 ## [13] reshape2_1.4.4 pkgconfig_2.0.3 crayon_1.5.3 ## [16] fastmap_1.2.0 backports_1.5.0 magick_2.8.5 ## [19] labeling_0.4.3 effectsize_1.0.0 pander_0.6.5 ## [22] utf8_1.2.4 rmarkdown_2.29 tzdb_0.4.0 ## [25] ps_1.8.1 nloptr_2.1.1 bit_4.5.0.1 ## [28] xfun_0.49 cachem_1.1.0 jsonlite_1.8.9 ## [31] sjmisc_2.8.10 ggeffects_2.0.0 pryr_0.1.6 ## [34] parallel_4.4.2 cluster_2.1.6 gap.datasets_0.0.6 ## [37] R6_2.5.1 bslib_0.8.0 stringi_1.8.4 ## [40] boot_1.3-31 rpart_4.1.23 jquerylib_0.1.4 ## [43] numDeriv_2016.8-1.1 estimability_1.5.1 Rcpp_1.0.14 ## [46] bookdown_0.43 zoo_1.8-12 parameters_0.24.2 ## [49] base64enc_0.1-3 Matrix_1.7-1 splines_4.4.2 ## [52] nnet_7.3-19 timechange_0.3.0 tidyselect_1.2.1 ## [55] rstudioapi_0.17.1 yaml_2.3.10 sjlabelled_1.2.0 ## [58] codetools_0.2-20 processx_3.8.4 lattice_0.22-6 ## [61] plyr_1.8.9 bayestestR_0.15.2 withr_3.0.2 ## [64] coda_0.19-4.1 evaluate_1.0.1 foreign_0.8-87 ## [67] survival_3.7-0 pillar_1.9.0 gap_1.6 ## [70] checkmate_2.3.2 insight_1.1.0 generics_0.1.3 ## [73] vroom_1.6.5 hms_1.1.3 munsell_0.5.1 ## [76] scales_1.3.0 minqa_1.2.8 xtable_1.8-4 ## [79] glue_1.8.0 tools_4.4.2 data.table_1.16.4 ## [82] lme4_1.1-35.5 mvtnorm_1.3-2 rapportools_1.1 ## [85] grid_4.4.2 rbibutils_2.3 datawizard_1.0.0 ## [88] colorspace_2.1-1 nlme_3.1-166 performance_0.13.0 ## [91] htmlTable_2.4.3 Formula_1.2-5 cli_3.6.3 ## [94] fansi_1.0.6 sjstats_0.19.0 gtable_0.3.6 ## [97] sass_0.4.9 digest_0.6.37 ucminf_1.2.2 ## [100] TH.data_1.1-2 htmlwidgets_1.6.4 farver_2.1.2 ## [103] htmltools_0.5.8.1 lifecycle_1.0.4 bit64_4.5.2 ## [106] MASS_7.3-61 "],["4-Random_LMM_GLMM_CLMM_GAMM.html", "Chapter 4 Random effects - LMM, GLMM, CLMM, GAMMs ", " Chapter 4 Random effects - LMM, GLMM, CLMM, GAMMs "],["4.1-loading-packages-2.html", "4.1 Loading packages", " 4.1 Loading packages ### Use the code below to check if you have all required packages installed. If some are not installed already, the code below will install these. If you have all packages installed, then you could load them with the second code. requiredPackages = c(&#39;tidyverse&#39;, &#39;broom&#39;, &#39;knitr&#39;, &#39;Hmisc&#39;, &#39;corrplot&#39;, &#39;lme4&#39;, &#39;lmerTest&#39;, &#39;emmeans&#39;, &#39;ggsignif&#39;, &#39;PresenceAbsence&#39;, &#39;languageR&#39;, &#39;ordinal&#39;, &#39;mgcv&#39;, &#39;itsadug&#39;, &#39;ggstats&#39;, &#39;ggstatsplot&#39;, &#39;sjPlot&#39;, &#39;paletteer&#39;, &#39;lattice&#39;, &#39;car&#39;, &#39;webshot&#39;) for(p in requiredPackages){ if(!require(p,character.only = TRUE)) install.packages(p, dependencies = TRUE) library(p,character.only = TRUE) } detach(&quot;package:lmerTest&quot;, unload = TRUE) "],["4.2-introduction-3.html", "4.2 Introduction", " 4.2 Introduction When looking at any study in Linguistics (and beyond), we rarely use productions of one vowel, from one speaker and from one item. If this were the case, we are unable to quantify changes in specific languages. To be able to generalise our results, we go for data collected from: Multiple speakers Multiple vowels and consonants Multiple Items (words) Multiple utterances where words are embedded Multiple listeners in perception experiments. In the last case, when designing our perception experiment, we can sometimes use multiple items, coming from multiple utterances and from multiple speakers! If we do not account for these inter-dependencies in our dataset, we are increasing Type I Error. Type I error, is when you easily find statistical differences when they are not there. Type II error is when you fail to find statistical difference when it is there. There are other types of errors see this reference for more details. 4.2.1 Fixed and random effects 4.2.1.1 How to choose fixed and random effects Fixed effects are those that are part of the experimental conditions. If you have exhausted all levels of an experimental condition, then this goes into fixed effects. Random effects are random selections of the population you have and you want to generalise over them. E.g., Speakers, listeners, items, utterances are all random effects because you are not using all the population of speakers, listeners, items, or utterances in your data! BUT.. Can Speakers, listeners, items, or utterances be included as fixed effects? Yes!! When you do this, it means you are interested in this specific population and want to evaluate differences specific to the population!! 4.2.1.2 What about Random Intercepts and Random Slopes Random Intercepts are used to obtain averages of your population and these are used in your statistical model to estimate variations. Random Slopes are adjustments to your participants’ observations as a function of your variables of interest. Usually, any within-subject (or within-item) variable is to be included as a random slope, but you need to use model comparison to evaluate the need to use it. "],["4.3-linear-mixed-effects-models.-why-random-effects-matter.html", "4.3 Linear Mixed-effects Models. Why random effects matter", " 4.3 Linear Mixed-effects Models. Why random effects matter Let’s generate a new dataframe that we will use later on for our mixed models We will use the faux package. It is not available on CRAN, but you can install it via github. First install the package devtools, and then install the package faux using the function devtools::install_github. # install.packages(&quot;devtools&quot;) # devtools::install_github(&quot;debruine/faux&quot;) library(faux) 4.3.1 Dataframe (simulated) Our experiment has the following structure: we asked 40 subjects to respond to 40 items in a fully crossed design. There were two IVs: Condition with congruent and incongruent and Age with young and old. The Condition is a within subject variable; age is a between subject. However, Condition and Age were both within item variables. The dependant variable was LookingTime. This meant that we used items within each of the young and the old subjects in addition to items within each of the congurent and incongruent conditions. Our research question is as follows: Age of subject will impact the Looking Time in the two conditions. Our hypothesis is: The older a subject is, the more the looking time it is to the incongruent condition. We will use the package faux to simulate a dataframe. This step is crucial in assessing contributions of particular predictors and for testing ideas as we already know the distribution of the data and what to expect as an outcome when it comes to the fixed effect in question. The simulated data has the following parameters set.seed(42) # define parameters Subj_n = 40 # number of subjects Item_n = 40 # number of items b0 = 100 # intercept b1 = 2.5 * b0 # fixed effect of condition u0s_sd = 300 # random intercept SD for subjects u0i_sd = 200 # random intercept SD for items u1s_sd = 100 # random b1 slope SD for subjects u1i_sd = 50 # random b1 slope SD for items r01s = -0.3 # correlation between random effects 0 and 1 for subjects r01i = 0.2 # correlation between random effects 0 and 1 for items sigma_sd = 150 # error SD # set up data structure dataCong &lt;- add_random(Subj = Subj_n, Item = Item_n) %&gt;% # add within categorical variable for subject add_within(&quot;Subj&quot;, Cond = c(&quot;Congruent&quot;, &quot;Incongruent&quot;)) %&gt;% add_recode(&quot;Cond&quot;, &quot;Cond.Incongruent&quot;, Congruent = 0, Incongruent = 1) %&gt;% # add between categorical variable for subject add_between(&quot;Subj&quot;, Age = c(&quot;Young&quot;, &quot;Old&quot;)) %&gt;% add_recode(&quot;Age&quot;, &quot;Age.Old&quot;, Young = 0, Old = 1) %&gt;% # add random effects add_ranef(&quot;Subj&quot;, u0s = u0s_sd, u1s = u1s_sd, .cors = r01s) %&gt;% add_ranef(&quot;Item&quot;, u0i = u0i_sd, u1i = u1i_sd, .cors = r01i) %&gt;% ##add_ranef(c(&quot;Subj&quot;, &quot;Item&quot;), u0si = u0s_sd + u0i_sd) %&gt;% ##add_ranef(c(&quot;Subj&quot;, &quot;Item&quot;), u1si = u1s_sd + u1i_sd) %&gt;% add_ranef(sigma = sigma_sd) %&gt;% # calculate DV mutate(LookingTime = b0 + b1 + u0s + u0i + #u0si + u1si + (((b1 + u1s) + 0.5) * Cond.Incongruent) + (((b1 + u1s) + 0.9) * Age.Old) + # subject specific variation (((b1 + u1i) - 0.3) * Cond.Incongruent) + (((b1 + u1i) - 0.25) * Age.Old) + # item specific variation sigma) write.csv(dataCong, &quot;data/dataCong.csv&quot;) If you were not able to install the faux package, simply uncomment the following line of code below to import the dataset #dataCong &lt;- read.csv(&quot;dataCong.csv&quot;)[-1] 4.3.1.1 Counts dataCong &lt;- dataCong %&gt;% mutate(Subj = factor(Subj), Item = factor(Item)) dataCong ## # A tibble: 3,200 × 12 ## Subj Item Cond Cond.Incongruent Age Age.Old u0s u1s u0i u1i ## &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Subj01 Item01 Congru… 0 Young 0 -413. 26.2 -306. 56.9 ## 2 Subj01 Item01 Incong… 1 Young 0 -413. 26.2 -306. 56.9 ## 3 Subj01 Item02 Congru… 0 Young 0 -413. 26.2 -55.4 69.1 ## 4 Subj01 Item02 Incong… 1 Young 0 -413. 26.2 -55.4 69.1 ## 5 Subj01 Item03 Congru… 0 Young 0 -413. 26.2 -17.4 -7.03 ## 6 Subj01 Item03 Incong… 1 Young 0 -413. 26.2 -17.4 -7.03 ## 7 Subj01 Item04 Congru… 0 Young 0 -413. 26.2 21.6 50.0 ## 8 Subj01 Item04 Incong… 1 Young 0 -413. 26.2 21.6 50.0 ## 9 Subj01 Item05 Congru… 0 Young 0 -413. 26.2 239. 12.8 ## 10 Subj01 Item05 Incong… 1 Young 0 -413. 26.2 239. 12.8 ## # ℹ 3,190 more rows ## # ℹ 2 more variables: sigma &lt;dbl&gt;, LookingTime &lt;dbl&gt; 4.3.1.1.1 Subjects dataCong %&gt;% group_by(Cond, Age, Subj) %&gt;% summarise(count = n()) ## # A tibble: 80 × 4 ## # Groups: Cond, Age [4] ## Cond Age Subj count ## &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; ## 1 Congruent Young Subj01 40 ## 2 Congruent Young Subj03 40 ## 3 Congruent Young Subj05 40 ## 4 Congruent Young Subj07 40 ## 5 Congruent Young Subj09 40 ## 6 Congruent Young Subj11 40 ## 7 Congruent Young Subj13 40 ## 8 Congruent Young Subj15 40 ## 9 Congruent Young Subj17 40 ## 10 Congruent Young Subj19 40 ## # ℹ 70 more rows 4.3.1.1.2 Items 4.3.1.1.3 Age dataCong %&gt;% group_by(Age, Item) %&gt;% summarise(count = n()) ## # A tibble: 80 × 3 ## # Groups: Age [2] ## Age Item count ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; ## 1 Young Item01 40 ## 2 Young Item02 40 ## 3 Young Item03 40 ## 4 Young Item04 40 ## 5 Young Item05 40 ## 6 Young Item06 40 ## 7 Young Item07 40 ## 8 Young Item08 40 ## 9 Young Item09 40 ## 10 Young Item10 40 ## # ℹ 70 more rows 4.3.1.1.4 Cond dataCong %&gt;% group_by(Cond, Item) %&gt;% summarise(count = n()) ## # A tibble: 80 × 3 ## # Groups: Cond [2] ## Cond Item count ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; ## 1 Congruent Item01 40 ## 2 Congruent Item02 40 ## 3 Congruent Item03 40 ## 4 Congruent Item04 40 ## 5 Congruent Item05 40 ## 6 Congruent Item06 40 ## 7 Congruent Item07 40 ## 8 Congruent Item08 40 ## 9 Congruent Item09 40 ## 10 Congruent Item10 40 ## # ℹ 70 more rows 4.3.1.2 Visualisations 4.3.1.2.1 Condition by Age The figure below confirms this, where we see an increase in LookingTime in the incongruent condition and oevrall, older participants show an increase in LookingTime dataCong %&gt;% ggplot(aes(x = Cond, y = LookingTime, colour = Age)) + theme_bw() + geom_boxplot() + geom_smooth(aes(as.numeric(Cond)), method = &quot;lm&quot;) 4.3.1.2.2 Subject by Condition This figure shows that subjects are variable in how they responded to this task dataCong %&gt;% ggplot(aes(x = Cond, y = LookingTime, colour = Subj)) + theme_bw() + geom_point() + geom_smooth(aes(as.numeric(Cond)), method = &quot;lm&quot;, se = FALSE) + scale_colour_manual(values = paletteer_c(&quot;grDevices::rainbow&quot;, length(unique(dataCong$Subj)))) 4.3.1.2.3 Subject by Age This figure shows that subjects had an impact on the LookingTime in both age groups, simply due to their variable responses to the different items dataCong %&gt;% ggplot(aes(x = Age, y = LookingTime, colour = Subj)) + theme_bw() + geom_point() + geom_smooth(aes(as.numeric(Cond)), method = &quot;lm&quot;, se = FALSE) + scale_colour_manual(values = paletteer_c(&quot;grDevices::rainbow&quot;, length(unique(dataCong$Subj)))) 4.3.1.2.4 Item by Condition This figure shows that items had an impact on the LookingTime in both conditions dataCong %&gt;% ggplot(aes(x = Cond, y = LookingTime, colour = Item)) + theme_bw() + geom_point() + geom_smooth(aes(as.numeric(Cond)), method = &quot;lm&quot;, se = FALSE) + scale_colour_manual(values = paletteer_c(&quot;grDevices::rainbow&quot;, length(unique(dataCong$Item)))) 4.3.1.2.5 Subject by Age This figure shows that items had an impact on the LookingTime in both age groups dataCong %&gt;% ggplot(aes(x = Age, y = LookingTime, colour = Item)) + theme_bw() + geom_point() + geom_smooth(aes(as.numeric(Cond)), method = &quot;lm&quot;, se = FALSE) + scale_colour_manual(values = paletteer_c(&quot;grDevices::rainbow&quot;, length(unique(dataCong$Item)))) 4.3.2 Modelling strategy We use an LMER model with a crossed random effect. To choose our optimal model, we start first by a simple model with only random intercepts, increasing complexity by accounting for random slopes for both subjects and items. It is clear from our visualisation above, that there is no interaction between the two predictors. However, for demonstration purposes, we do test for this 4.3.2.1 Simple Linear Model mdl.lm &lt;- dataCong %&gt;% lm(LookingTime ~ Cond + Age, data = .) summary(mdl.lm) ## ## Call: ## lm(formula = LookingTime ~ Cond + Age, data = .) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1215.59 -290.17 -21.78 264.89 1661.41 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 304.95 12.91 23.61 &lt;2e-16 *** ## CondIncongruent 504.35 14.91 33.82 &lt;2e-16 *** ## AgeOld 566.44 14.91 37.98 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 421.8 on 3197 degrees of freedom ## Multiple R-squared: 0.4472, Adjusted R-squared: 0.4469 ## F-statistic: 1293 on 2 and 3197 DF, p-value: &lt; 2.2e-16 hist(residuals(mdl.lm)) qqnorm(residuals(mdl.lm)); qqline(residuals(mdl.lm)) plot(fitted(mdl.lm), residuals(mdl.lm), cex = 4) 4.3.2.2 No interaction 4.3.2.2.1 Crossed random intercepts xmdl.rand.Interc &lt;- dataCong %&gt;% lmer(LookingTime ~ Cond + Age + (1 | Subj) + (1 | Item), data = ., REML = FALSE, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 1e5))) 4.3.2.2.2 Crossed random intercepts + By-speaker random slopes xmdl.rand.Slope1 &lt;- dataCong %&gt;% lmer(LookingTime ~ Cond + Age + (1 + Cond | Subj) + (1 | Item), data = ., REML = FALSE, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 1e5))) 4.3.2.2.3 Crossed random intercepts + By-speaker and by-item random slopes xmdl.rand.Slope2 &lt;- dataCong %&gt;% lmer(LookingTime ~ Cond + Age + (1 + Cond | Subj) + (1 + Cond | Item), data = ., REML = FALSE, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 1e5))) 4.3.2.2.4 Crossed random intercepts + By-speaker and by-item random slopes xmdl.rand.Slope3 &lt;- dataCong %&gt;% lmer(LookingTime ~ Cond + Age + (1 + Cond | Subj) + (1 + Cond + Age| Item), data = ., REML = FALSE, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 1e5))) 4.3.2.3 With interaction 4.3.2.3.1 Crossed random intercepts + Interaction xmdl.rand.Interc.Int &lt;- dataCong %&gt;% lmer(LookingTime ~ Cond * Age + (1 | Subj) + (1 | Item), data = ., REML = FALSE, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 1e5))) 4.3.2.3.2 Crossed random intercepts + By-speaker random slopes + Interaction xmdl.rand.Slope1.Int &lt;- dataCong %&gt;% lmer(LookingTime ~ Cond * Age + (1 + Cond | Subj) + (1 | Item), data = ., REML = FALSE, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 1e5))) 4.3.2.3.3 Crossed random intercepts + By-speaker and by-item random slopes + Interaction xmdl.rand.Slope2.Int &lt;- dataCong %&gt;% lmer(LookingTime ~ Cond * Age + (1 + Cond | Subj) + (1 + Cond | Item), data = ., REML = FALSE, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 1e5))) 4.3.2.3.4 Crossed random intercepts + By-speaker and by-item random slopes xmdl.rand.Slope3.Int &lt;- dataCong %&gt;% lmer(LookingTime ~ Cond * Age + (1 + Cond | Subj) + (1 + Cond * Age| Item), data = ., REML = FALSE, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 1e5))) 4.3.2.4 Model comparison anova(xmdl.rand.Interc, xmdl.rand.Slope1, xmdl.rand.Slope2, xmdl.rand.Slope3, xmdl.rand.Interc.Int, xmdl.rand.Slope1.Int, xmdl.rand.Slope2.Int, xmdl.rand.Slope3.Int) ## Data: . ## Models: ## xmdl.rand.Interc: LookingTime ~ Cond + Age + (1 | Subj) + (1 | Item) ## xmdl.rand.Interc.Int: LookingTime ~ Cond * Age + (1 | Subj) + (1 | Item) ## xmdl.rand.Slope1: LookingTime ~ Cond + Age + (1 + Cond | Subj) + (1 | Item) ## xmdl.rand.Slope1.Int: LookingTime ~ Cond * Age + (1 + Cond | Subj) + (1 | Item) ## xmdl.rand.Slope2: LookingTime ~ Cond + Age + (1 + Cond | Subj) + (1 + Cond | Item) ## xmdl.rand.Slope2.Int: LookingTime ~ Cond * Age + (1 + Cond | Subj) + (1 + Cond | Item) ## xmdl.rand.Slope3: LookingTime ~ Cond + Age + (1 + Cond | Subj) + (1 + Cond + Age | Item) ## xmdl.rand.Slope3.Int: LookingTime ~ Cond * Age + (1 + Cond | Subj) + (1 + Cond * Age | Item) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## xmdl.rand.Interc 6 42074 42110 -21031 42062 ## xmdl.rand.Interc.Int 7 42050 42093 -21018 42036 25.8359 1 3.717e-07 ## xmdl.rand.Slope1 8 41834 41883 -20909 41818 217.8699 1 &lt; 2.2e-16 ## xmdl.rand.Slope1.Int 9 41833 41888 -20908 41815 3.0247 1 0.0820 ## xmdl.rand.Slope2 10 41808 41869 -20894 41788 27.3253 1 1.719e-07 ## xmdl.rand.Slope2.Int 11 41807 41874 -20892 41785 3.0149 1 0.0825 ## xmdl.rand.Slope3 13 41780 41858 -20877 41754 31.2599 2 1.629e-07 ## xmdl.rand.Slope3.Int 18 41786 41895 -20875 41750 3.3401 5 0.6477 ## ## xmdl.rand.Interc ## xmdl.rand.Interc.Int *** ## xmdl.rand.Slope1 *** ## xmdl.rand.Slope1.Int . ## xmdl.rand.Slope2 *** ## xmdl.rand.Slope2.Int . ## xmdl.rand.Slope3 *** ## xmdl.rand.Slope3.Int ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The results above highlight that the model accounting for both by-subject and by-item random intercepts and random slopes for Condition are improving the model fit in comparison to a more complex model. We rerun the model with REML = False 4.3.2.5 Optimal model xmdl.Optimal &lt;- dataCong %&gt;% lmer(LookingTime ~ Cond + Age + (1 + Cond | Subj) + (1 + Cond + Age | Item), data = ., REML = TRUE, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 1e5))) 4.3.2.5.1 Model criticism 4.3.2.5.1.1 Histogram hist(residuals(xmdl.Optimal)) 4.3.2.5.1.2 QQ-plot qqnorm(residuals(xmdl.Optimal)); qqline(residuals(xmdl.Optimal)) 4.3.2.5.1.3 Residuals vs Fitted plot(fitted(xmdl.Optimal), residuals(xmdl.Optimal), cex = 4) 4.3.2.5.2 Summary xmdl.Optimal %&gt;% summary() ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: LookingTime ~ Cond + Age + (1 + Cond | Subj) + (1 + Cond + Age | ## Item) ## Data: . ## Control: lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 1e+05)) ## ## REML criterion at convergence: 41724.6 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.5337 -0.6485 -0.0054 0.6647 3.5358 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## Subj (Intercept) 123480 351.40 ## CondIncongruent 10746 103.66 -0.26 ## Item (Intercept) 38781 196.93 ## CondIncongruent 1872 43.27 0.31 ## AgeOld 1851 43.03 -0.13 0.69 ## Residual 22613 150.38 ## Number of obs: 3200, groups: Subj, 40; Item, 40 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 315.04 83.42 3.777 ## CondIncongruent 504.35 18.54 27.204 ## AgeOld 546.28 107.70 5.072 ## ## Correlation of Fixed Effects: ## (Intr) CndInc ## CndIncngrnt -0.120 ## AgeOld -0.646 0.016 4.3.2.5.3 ANOVA Anova(xmdl.Optimal) ## Analysis of Deviance Table (Type II Wald chisquare tests) ## ## Response: LookingTime ## Chisq Df Pr(&gt;Chisq) ## Cond 740.067 1 &lt; 2.2e-16 *** ## Age 25.729 1 3.928e-07 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 4.3.2.5.4 Model’s fit print(tab_model(xmdl.Optimal, file = paste0(&quot;outputs/xmdl.Optimal.html&quot;))) webshot(paste0(&quot;outputs/xmdl.Optimal.html&quot;), paste0(&quot;outputs/xmdl.Optimal.png&quot;)) Model fit: Linear Mixed effects model 4.3.3 Plotting model’s output 4.3.3.1 With ggstats We use two functions from the package ggstats. 4.3.3.1.1 A plot ggcoef_model(xmdl.Optimal) 4.3.3.2 A plot + a table + 95% CI ggcoef_table(xmdl.Optimal) 4.3.3.3 With ggstatsplot ggcoefstats(xmdl.Optimal, point.args = list(color = paletteer_c(&quot;grDevices::rainbow&quot;, 13), stats.label.color = paletteer_c(&quot;grDevices::rainbow&quot;, 13))) ## Warning in (function (mapping = NULL, data = NULL, stat = &quot;identity&quot;, position ## = &quot;identity&quot;, : Ignoring unknown parameters: `stats.label.colour` ## Number of labels is greater than default palette color count. ## • Select another color `palette` (and/or `package`). 4.3.4 Exploring random effects 4.3.4.1 Subject random effects random_effects &lt;- ranef(xmdl.Optimal) %&gt;% pluck(1) %&gt;% rownames_to_column() %&gt;% rename(Subject = rowname, Intercept = &quot;(Intercept)&quot;) random_effects %&gt;% knitr::kable() Subject Intercept CondIncongruent Subj01 -404.45054 58.1953368 Subj02 164.05584 56.9126271 Subj03 -56.37438 -104.0600477 Subj04 -87.06837 43.7884729 Subj05 -55.65214 104.5323900 Subj06 -42.39999 -7.1394328 Subj07 -448.81496 124.6524549 Subj08 -171.75810 -105.4504187 Subj09 -587.74594 123.6911001 Subj10 -44.50407 -50.9618431 Subj11 -346.46288 1.6396966 Subj12 -550.49633 158.6524706 Subj13 417.66027 -169.1409700 Subj14 -11.45716 -30.0008252 Subj15 62.46659 -14.3520076 Subj16 -210.03389 -23.9077430 Subj17 124.19946 -122.7635167 Subj18 666.67147 -42.1836697 Subj19 815.78333 217.1615447 Subj20 -393.58521 26.1633665 Subj21 120.64645 37.9297097 Subj22 455.31816 -46.4925696 Subj23 42.42431 -54.4053551 Subj24 -496.29436 -31.7202386 Subj25 -552.91357 144.2714898 Subj26 -21.91509 -159.7897817 Subj27 65.14521 54.5212747 Subj28 373.40089 -166.0862255 Subj29 -132.82108 -21.8820276 Subj30 104.73419 -112.8914459 Subj31 -79.72260 125.0118699 Subj32 -182.30982 15.3898936 Subj33 -303.68384 -0.1957386 Subj34 215.98609 136.5078869 Subj35 -152.60397 76.5559812 Subj36 401.50547 -145.0045141 Subj37 274.61818 -114.4122298 Subj38 139.48473 -82.7958618 Subj39 733.87830 58.5575032 Subj40 155.08935 41.5013939 4.3.4.2 Items random effects random_effects &lt;- ranef(xmdl.Optimal) %&gt;% pluck(2) %&gt;% rownames_to_column() %&gt;% rename(Items = rowname, Intercept = &quot;(Intercept)&quot;) random_effects %&gt;% knitr::kable() Items Intercept CondIncongruent AgeOld Item01 -247.414507 16.2991489 28.312990 Item02 -28.240445 20.6149279 37.267856 Item03 -27.548429 11.7099339 -3.218254 Item04 30.999046 32.2392558 32.548236 Item05 246.216859 38.0585978 2.963549 Item06 -135.583736 28.3151555 28.127356 Item07 75.461498 28.6715548 -2.095288 Item08 72.679400 69.1730999 73.479523 Item09 -180.071444 32.9237845 60.953057 Item10 -170.029328 8.4112590 23.865843 Item11 -278.857705 -39.6392919 -22.526611 Item12 114.001985 4.7652485 -15.353357 Item13 -137.533542 -49.5701246 -36.764423 Item14 -272.928912 -85.2576750 -45.340742 Item15 219.855541 -70.2475223 -83.121735 Item16 243.071753 13.0287924 -4.812872 Item17 210.792625 10.6898312 17.840004 Item18 328.737750 -36.9498461 -82.922663 Item19 -46.910049 28.2829527 22.930110 Item20 -107.870056 -25.5384308 -13.846115 Item21 -209.598744 -56.8339801 -29.482588 Item22 -190.253581 -3.0439700 20.502593 Item23 207.958662 34.4328035 33.373202 Item24 -371.211245 -46.1955836 1.751542 Item25 163.603914 15.0837752 -7.780876 Item26 -56.954235 -39.1972201 -59.652416 Item27 126.648406 7.5867262 -1.102683 Item28 48.176096 -0.4969082 1.358911 Item29 -76.699978 -27.4397677 -1.462473 Item30 -20.393146 33.1813806 36.286219 Item31 33.763413 -15.9993987 -14.400133 Item32 -15.979008 47.9237115 67.643383 Item33 64.451213 -8.2252951 -47.157817 Item34 102.286457 22.6554454 17.134672 Item35 319.882212 54.1470278 10.485257 Item36 115.886689 22.7596669 9.094458 Item37 93.471368 9.1514824 -17.490313 Item38 -523.293815 -46.1545897 -5.185309 Item39 287.858945 20.0462752 2.292928 Item40 -8.431927 -59.3622338 -34.495018 4.3.4.3 Plots These plots below are produced with the sjPlot package. 4.3.4.3.1 Fixed effects 4.3.4.3.1.1 Condition plot_model(xmdl.Optimal, type=&quot;pred&quot;, terms=c(&quot;Cond&quot;), ci.lvl = NA, dodge = 0) + theme_bw() + geom_line() 4.3.4.3.1.2 Age plot_model(xmdl.Optimal, type=&quot;pred&quot;, terms=c(&quot;Age&quot;), ci.lvl = NA, dodge = 0) + theme_bw() + geom_line() 4.3.4.3.1.3 Condition by Age plot_model(xmdl.Optimal, type=&quot;emm&quot;, terms=c(&quot;Cond&quot;, &quot;Age&quot;), ci.lvl = NA, dodge = 0) + theme_bw() + geom_line() 4.3.4.3.2 Random effects 4.3.4.3.2.1 Subject plot_model(xmdl.Optimal, type=&quot;pred&quot;, terms=c(&quot;Subj&quot;), pred.type=&quot;re&quot;, ci.lvl = NA, dodge = 0) + theme_bw() + geom_line() 4.3.4.3.2.2 Subject by Condition plot_model(xmdl.Optimal, type=&quot;pred&quot;, terms=c(&quot;Cond&quot;, &quot;Subj&quot;), pred.type=&quot;re&quot;, ci.lvl = NA, dodge = 0, colors = paletteer_c(&quot;grDevices::rainbow&quot;, length(unique(dataCong$Subj)))) + theme_bw() + geom_line() 4.3.4.3.2.3 Subject by Age plot_model(xmdl.Optimal, type=&quot;pred&quot;, terms=c(&quot;Age&quot;, &quot;Subj&quot;), pred.type=&quot;re&quot;, ci.lvl = NA, dodge = 0, colors = paletteer_c(&quot;grDevices::rainbow&quot;, length(unique(dataCong$Subj)))) + theme_bw() + geom_line() 4.3.4.3.2.4 Item plot_model(xmdl.Optimal, type=&quot;pred&quot;, terms=c(&quot;Item&quot;), pred.type=&quot;re&quot;, ci.lvl = NA, dodge = 0) + theme_bw() + geom_line() 4.3.4.3.2.5 Item by Cond plot_model(xmdl.Optimal, type=&quot;pred&quot;, terms=c(&quot;Cond&quot;, &quot;Item&quot;), pred.type=&quot;re&quot;, ci.lvl = NA, dodge = 0, colors = paletteer_c(&quot;grDevices::rainbow&quot;, length(unique(dataCong$Item)))) + theme_bw() + geom_line() 4.3.4.3.2.6 Item by Age plot_model(xmdl.Optimal, type=&quot;pred&quot;, terms=c(&quot;Age&quot;, &quot;Item&quot;), pred.type=&quot;re&quot;, ci.lvl = NA, dodge = 0, colors = paletteer_c(&quot;grDevices::rainbow&quot;, length(unique(dataCong$Item)))) + theme_bw() + geom_line() 4.3.4.3.2.7 Item by Cond facetted by Age plot_model(xmdl.Optimal, type=&quot;pred&quot;, terms=c(&quot;Cond&quot;, &quot;Item&quot;, &quot;Age&quot;), pred.type=&quot;re&quot;, ci.lvl = NA, dodge = 0, colors = paletteer_c(&quot;grDevices::rainbow&quot;, length(unique(dataCong$Item)))) + theme_bw() + geom_line() 4.3.4.3.2.8 Subject by Item plot_model(xmdl.Optimal, type=&quot;pred&quot;, terms=c(&quot;Subj&quot;, &quot;Item&quot;), pred.type=&quot;re&quot;, ci.lvl = NA, dodge = 0, colors = paletteer_c(&quot;grDevices::rainbow&quot;, length(unique(dataCong$Subj)))) + theme_bw() + geom_line() 4.3.4.3.2.9 Subject by Item facetted by Cond plot_model(xmdl.Optimal, type=&quot;pred&quot;, terms=c(&quot;Subj&quot;, &quot;Item&quot;, &quot;Cond&quot;), pred.type=&quot;re&quot;, ci.lvl = NA, dodge = 0, colors = paletteer_c(&quot;grDevices::rainbow&quot;, length(unique(dataCong$Subj)))) + theme_bw() + geom_line() 4.3.4.3.2.10 Subject by Item facetted by Age plot_model(xmdl.Optimal, type=&quot;pred&quot;, terms=c(&quot;Subj&quot;, &quot;Item&quot;, &quot;Age&quot;), pred.type=&quot;re&quot;, ci.lvl = NA, dodge = 0, colors = paletteer_c(&quot;grDevices::rainbow&quot;, length(unique(dataCong$Subj)))) + theme_bw() + geom_line() 4.3.4.3.3 With Lattice 4.3.4.3.3.1 Subject Intercepts dotplot(ranef(xmdl.Optimal))$Subj[1] 4.3.4.3.3.2 Subject Slopes dotplot(ranef(xmdl.Optimal), xlim = c(-350, 350))$Subj[2] 4.3.4.3.3.3 Item Intercepts dotplot(ranef(xmdl.Optimal))$Item[1] 4.3.4.3.3.4 Item Slopes for Cond dotplot(ranef(xmdl.Optimal), xlim = c(-150, 150))$Item[2] 4.3.4.3.3.5 Item Slopes for Age dotplot(ranef(xmdl.Optimal), xlim = c(-150, 150))$Item[3] I hope this tutorial helped you to uncover the role of participants and items and what they can tell us beyond the fixed effect! 4.3.5 Conclusion In this simulated dataset, we showed how to use Linear Mixed-effects Models, and used a specific approach, named “maximal specification model”. This maximal specification model uses both random intercepts and random slopes. Usually, on any dataset, you are required to formally assess the need for Random slopes. As a rule of thumb: Any within-subject (or within-item) should be tested for a potential inclusion as a random slope. Fixed effects provide averages over all observations, even when using mixed effects regressions; we need to explore what random effects (intercepts and slopes) tell us. In this example, we see that many subjects vary beyond the fixed effect; Standard Errors are not enough to quantify this type of variation. The same is true for items that are not explored routinely! The approach above used a maximal specification model. This of course depends on the dataset you are working on and requires formal testing. See the package RePsychLing that is on github. The function RePCA is part of the package lme4. You can use it to verify if the model structure is appropriate. However, lme4 will give you directly a warning “is singular” that you can interpret as “over specified model”. "],["4.4-generalised-linear-mixed-effects-models.html", "4.4 Generalised Linear Mixed-effects Models", " 4.4 Generalised Linear Mixed-effects Models Here we will look at an example when the outcome is binary. This simulated data is structured as follows. We asked one participant to listen to 165 sentences, and to judge whether these are “grammatical” or “ungrammatical”. There were 105 sentences that were “grammatical” and 60 “ungrammatical”. This fictitious example can apply in any other situation. Let’s think Geography: 165 lands: 105 “flat” and 60 “non-flat”, etc. This applies to any case where you need to “categorise” the outcome into two groups. 4.4.1 GLMM - Categorical predictors Let’s run a first GLMM (Generalised Linear Model). 4.4.1.1 Simulating a new dataset grammatical2 &lt;- as.data.frame( cbind(&quot;participant&quot; = c(&quot;participant&quot; = rep(&quot;p1&quot;, 165), rep(&quot;p2&quot;, 165)), &quot;grammaticality&quot; = c(&quot;grammatical&quot; = rep(&quot;grammatical&quot;, 105), &quot;ungrammatical&quot; = rep(&quot;ungrammatical&quot;, 60), &quot;grammatical&quot; = rep(&quot;grammatical&quot;, 105), &quot;ungrammatical&quot; = rep(&quot;ungrammatical&quot;, 60)), &quot;response&quot; = c(&quot;yes&quot; = rep(&quot;yes&quot;, 100), &quot;no&quot; = rep(&quot;no&quot;, 5), &quot;yes&quot; = rep(&quot;yes&quot;, 10), &quot;no&quot; = rep(&quot;no&quot;, 50), &quot;yes&quot; = rep(&quot;yes&quot;, 90), &quot;no&quot; = rep(&quot;no&quot;, 15), &quot;yes&quot; = rep(&quot;yes&quot;, 30), &quot;no&quot; = rep(&quot;no&quot;, 30))), row.names = FALSE) grammatical2 %&gt;% head(10) ## participant grammaticality response ## 1 p1 grammatical yes ## 2 p1 grammatical yes ## 3 p1 grammatical yes ## 4 p1 grammatical yes ## 5 p1 grammatical yes ## 6 p1 grammatical yes ## 7 p1 grammatical yes ## 8 p1 grammatical yes ## 9 p1 grammatical yes ## 10 p1 grammatical yes 4.4.1.2 Manipulations and a table grammatical2 &lt;- grammatical2 %&gt;% mutate(response = factor(response, levels = c(&quot;no&quot;, &quot;yes&quot;)), grammaticality = factor(grammaticality, levels = c(&quot;ungrammatical&quot;, &quot;grammatical&quot;))) grammatical2 %&gt;% select(response, grammaticality) %&gt;% group_by(response, grammaticality) %&gt;% table() ## grammaticality ## response ungrammatical grammatical ## no 80 20 ## yes 40 190 4.4.1.3 Model estimation and results 4.4.1.3.1 Random Intercepts The results below show the logodds for our model. mdl.glmm &lt;- grammatical2 %&gt;% glmer(response ~ grammaticality + (1|participant), data = ., family = binomial) summary(mdl.glmm) ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: binomial ( logit ) ## Formula: response ~ grammaticality + (1 | participant) ## Data: . ## ## AIC BIC logLik deviance df.resid ## 290.8 302.2 -142.4 284.8 327 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.1221 -0.6985 0.3203 0.3280 1.4317 ## ## Random effects: ## Groups Name Variance Std.Dev. ## participant (Intercept) 0.005276 0.07264 ## Number of obs: 330, groups: participant, 2 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.6940 0.2006 -3.459 0.000542 *** ## grammaticalitygrammatical 2.9475 0.3060 9.632 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ## grmmtcltygr -0.615 4.4.1.3.2 Random Slopes The results below show the logodds for our model. mdl.glmmSlope &lt;- grammatical2 %&gt;% glmer(response ~ grammaticality + (grammaticality|participant), data = ., family = binomial) summary(mdl.glmmSlope) ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: binomial ( logit ) ## Formula: response ~ grammaticality + (grammaticality | participant) ## Data: . ## ## AIC BIC logLik deviance df.resid ## 280.3 299.2 -135.1 270.3 325 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -4.2750 -0.4702 0.2339 0.3998 2.1269 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## participant (Intercept) 0.5992 0.774 ## grammaticalitygrammatical 1.8089 1.345 -1.00 ## Number of obs: 330, groups: participant, 2 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.7951 0.5875 -1.353 0.17593 ## grammaticalitygrammatical 3.1739 1.0099 3.143 0.00167 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ## grmmtcltygr -0.955 ## optimizer (Nelder_Mead) convergence code: 0 (OK) ## boundary (singular) fit: see help(&#39;isSingular&#39;) 4.4.1.3.3 Random Slopes decorrelated The results below show the logodds for our model. mdl.glmmSlopeDec &lt;- grammatical2 %&gt;% glmer(response ~ grammaticality + (grammaticality||participant), data = ., family = binomial) summary(mdl.glmmSlopeDec) ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: binomial ( logit ) ## Formula: response ~ grammaticality + (grammaticality || participant) ## Data: . ## ## AIC BIC logLik deviance df.resid ## 282.3 305.0 -135.1 270.3 324 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -4.2749 -0.4702 0.2339 0.3998 2.1269 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## participant (Intercept) 1.189e-10 1.091e-05 ## participant.1 grammaticalityungrammatical 5.992e-01 7.741e-01 ## grammaticalitygrammatical 3.259e-01 5.709e-01 -1.00 ## Number of obs: 330, groups: participant, 2 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.7951 0.5874 -1.353 0.17591 ## grammaticalitygrammatical 3.1738 1.0098 3.143 0.00167 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ## grmmtcltygr -0.955 ## optimizer (Nelder_Mead) convergence code: 0 (OK) ## boundary (singular) fit: see help(&#39;isSingular&#39;) 4.4.1.4 Model comparison anova(mdl.glmm, mdl.glmmSlope) ## Data: . ## Models: ## mdl.glmm: response ~ grammaticality + (1 | participant) ## mdl.glmmSlope: response ~ grammaticality + (grammaticality | participant) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## mdl.glmm 3 290.84 302.24 -142.42 284.84 ## mdl.glmmSlope 5 280.25 299.25 -135.13 270.25 14.584 2 0.0006811 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 anova(mdl.glmmSlope, mdl.glmmSlopeDec) ## Data: . ## Models: ## mdl.glmmSlope: response ~ grammaticality + (grammaticality | participant) ## mdl.glmmSlopeDec: response ~ grammaticality + (grammaticality || participant) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## mdl.glmmSlope 5 280.25 299.25 -135.13 270.25 ## mdl.glmmSlopeDec 6 282.25 305.05 -135.13 270.25 0 1 1 The model comparisons show that the model with both random intercepts and random slopes is improving the model fit. The Is.Singular message tells us that there is a chance there is a complete separation in the model. 4.4.1.5 Getting results 4.4.1.5.1 Model’s fit print(tab_model(mdl.glmmSlope, file = paste0(&quot;outputs/mdl.glmmSlope.html&quot;))) webshot(paste0(&quot;outputs/mdl.glmmSlope.html&quot;), paste0(&quot;outputs/mdl.glmmSlope.png&quot;)) Model fit: Generalised Linear Mixed effects model - Categorical 4.4.1.5.2 Fixed effects fixef(mdl.glmmSlope) ## (Intercept) grammaticalitygrammatical ## -0.7950773 3.1738527 fixef(mdl.glmmSlope)[1] ## (Intercept) ## -0.7950773 fixef(mdl.glmmSlope)[2] ## grammaticalitygrammatical ## 3.173853 4.4.1.5.3 Random effects coef(mdl.glmmSlope)$`participant`[1] ## (Intercept) ## p1 -1.50933642 ## p2 -0.05609396 coef(mdl.glmmSlope)$`participant`[2] ## grammaticalitygrammatical ## p1 4.414908 ## p2 1.889839 4.4.1.5.4 Logodds to Odd ratios Logodds can be modified to talk about the odds of an event. exp(fixef(mdl.glmmSlope)[1]) ## (Intercept) ## 0.4515463 exp(fixef(mdl.glmmSlope)[1] + fixef(mdl.glmmSlope)[2]) ## (Intercept) ## 10.79168 4.4.1.5.5 LogOdds to proportions If you want to talk about the percentage “accuracy” of our model, then we can transform our loggodds into proportions. This shows that the proportion of “grammatical” receiving a “yes” response increases by 99% (or 95% based on our “true” coefficients). plogis(fixef(mdl.glmmSlope)[1]) ## (Intercept) ## 0.3110795 plogis(fixef(mdl.glmmSlope)[1] + fixef(mdl.glmmSlope)[2]) ## (Intercept) ## 0.9151944 4.4.1.5.6 Plotting grammatical2 &lt;- grammatical2 %&gt;% mutate(prob = predict(mdl.glmmSlope, type = &quot;response&quot;)) grammatical2 %&gt;% ggplot(aes(x = as.numeric(grammaticality), y = prob)) + geom_point() + geom_smooth(method = &quot;glm&quot;, method.args = list(family = &quot;binomial&quot;), se = T) + theme_bw(base_size = 20)+ labs(y = &quot;Probability&quot;, x = &quot;&quot;)+ coord_cartesian(ylim = c(0,1))+ scale_x_discrete(limits = c(&quot;Ungrammatical&quot;, &quot;Grammatical&quot;)) + facet_grid(~ participant, margins = TRUE, scales = &quot;free&quot;) 4.4.2 GLMM - Numeric predictors In this example, we will run a GLM model using a similar technique to that used in Al-Tamimi (2017) and Baumann &amp; Winter (2018). We use the package LanguageR and the dataset English. In the model above, we used the equation as lm(RTlexdec ~ AgeSubject). We were interested in examining the impact of age of subject on reaction time in a lexical decision task. In this section, we are interested in understanding how reaction time allows to differentiate the participants based on their age. We use AgeSubject as our outcome and RTlexdec as our predictor using the equation glm(AgeSubject ~ RTlexdec). We usually can use RTlexdec as is, but due to a possible quasi separation and the fact that we may want to compare coefficients using multiple acoustic metrics, we will z-score our predictor. We run below two models, with and without z-scoring For the glm model, we need to specify family = \"binomial\". 4.4.2.1 Without z-scoring of predictor 4.4.2.1.1 Model estimation In the english dataset, we have a random factor: “Word”. We include it here. 4.4.2.1.1.1 Random Intercepts english2 &lt;- english %&gt;% mutate(AgeSubject = factor(AgeSubject, levels = c(&quot;young&quot;, &quot;old&quot;))) mdl.glmm2 &lt;- english2 %&gt;% glmer(AgeSubject ~ RTlexdec + (1|Word), data = ., family = &quot;binomial&quot;) summary(mdl.glmm2) ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: binomial ( logit ) ## Formula: AgeSubject ~ RTlexdec + (1 | Word) ## Data: . ## ## AIC BIC logLik deviance df.resid ## 3151.8 3171.1 -1572.9 3145.8 4565 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -26.3468 -0.3058 -0.0166 0.3893 4.0750 ## ## Random effects: ## Groups Name Variance Std.Dev. ## Word (Intercept) 1.666e-15 4.082e-08 ## Number of obs: 4568, groups: Word, 2197 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -128.6308 3.7966 -33.88 &lt;2e-16 *** ## RTlexdec 19.6497 0.5798 33.89 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ## RTlexdec -1.000 ## optimizer (Nelder_Mead) convergence code: 0 (OK) ## boundary (singular) fit: see help(&#39;isSingular&#39;) 4.4.2.1.1.2 Random Slopes mdl.glmmSlope2 &lt;- english2 %&gt;% glmer(AgeSubject ~ RTlexdec + (RTlexdec|Word), data = ., family = &quot;binomial&quot;) summary(mdl.glmmSlope2) ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: binomial ( logit ) ## Formula: AgeSubject ~ RTlexdec + (RTlexdec | Word) ## Data: . ## ## AIC BIC logLik deviance df.resid ## 3075.6 3107.7 -1532.8 3065.6 4563 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.3923 -0.2133 -0.0024 0.2512 5.8061 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## Word (Intercept) 3325.68 57.669 ## RTlexdec 80.01 8.945 -1.00 ## Number of obs: 4568, groups: Word, 2197 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -179.980 10.482 -17.17 &lt;2e-16 *** ## RTlexdec 27.535 1.607 17.13 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ## RTlexdec -1.000 ## optimizer (Nelder_Mead) convergence code: 0 (OK) ## boundary (singular) fit: see help(&#39;isSingular&#39;) 4.4.2.2 Model comparison anova(mdl.glmm2, mdl.glmmSlope2) ## Data: . ## Models: ## mdl.glmm2: AgeSubject ~ RTlexdec + (1 | Word) ## mdl.glmmSlope2: AgeSubject ~ RTlexdec + (RTlexdec | Word) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## mdl.glmm2 3 3151.8 3171.1 -1572.9 3145.8 ## mdl.glmmSlope2 5 3075.6 3107.7 -1532.8 3065.6 80.262 2 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The model comparisons show that the model with both random intercepts and random slopes is improving the model fit. The Is.Singular message tells us that there is a chance there is a complete separation in the model. 4.4.2.3 Gettings results 4.4.2.3.1 Model’s fit print(tab_model(mdl.glmmSlope2, file = paste0(&quot;outputs/mdl.glmmSlope2.html&quot;))) webshot(paste0(&quot;outputs/mdl.glmmSlope2.html&quot;), paste0(&quot;outputs/mdl.glmmSlope2.png&quot;)) Model fit: Generalised Linear Mixed effects model - Numeric 4.4.2.3.2 Fixed effects fixef(mdl.glmmSlope2) ## (Intercept) RTlexdec ## -179.97997 27.53549 fixef(mdl.glmmSlope2)[1] ## (Intercept) ## -179.98 fixef(mdl.glmmSlope2)[2] ## RTlexdec ## 27.53549 4.4.2.3.3 Random effects coef(mdl.glmmSlope2)$`Word`[1] ## (Intercept) ## ace -183.90593 ## act -194.45238 ## add -188.40333 ## age -187.46409 ## aid -181.03495 ## aide -158.07461 ## ail -123.55216 ## aim -190.10409 ## air -200.14396 ## aisle -174.27287 ## ale -180.30489 ## angst -165.78719 ## ant -191.28906 ## ape -187.24205 ## arc -126.77945 ## arch -184.42680 ## are -182.46607 ## arm -217.59076 ## art -189.04802 ## ash -182.98220 ## ask -196.70366 ## ass -183.23599 ## axe -181.94943 ## babe -188.70258 ## back -195.42039 ## badge -183.01595 ## bag -199.54314 ## bail -168.15030 ## bait -190.95479 ## bale -121.78656 ## ball -187.58021 ## ban -150.32497 ## band -182.62443 ## bang -196.73783 ## bank -193.70561 ## bar -200.25188 ## bard -117.84681 ## barge -141.73048 ## bark -196.61578 ## barn -200.39050 ## base -192.56565 ## bash -180.80001 ## bat -199.64365 ## batch -189.94741 ## bath -193.82412 ## bay -189.46411 ## beach -185.19024 ## bead -168.42383 ## beak -133.17528 ## beam -180.59024 ## bean -182.07824 ## bear -213.07935 ## beard -196.58612 ## beast -181.77336 ## beat -189.71515 ## beau -154.41186 ## beck -91.17832 ## bed -188.54683 ## bee -198.73653 ## beech -126.52901 ## beef -211.38709 ## beep -190.21971 ## beer -198.75869 ## beet -173.58986 ## beg -200.94583 ## belch -155.10294 ## bell -195.09608 ## belt -187.26488 ## bench -200.14864 ## bend -198.78979 ## berth -157.88188 ## bet -201.03313 ## bib -167.68854 ## bid -201.07976 ## bide -89.33357 ## bile -166.74646 ## bilge -99.16027 ## bill -189.36736 ## bin -159.06192 ## bind -150.49849 ## binge -173.11795 ## birch -158.44403 ## bird -192.34647 ## bit -197.94419 ## bitch -186.76026 ## bite -200.32906 ## blade -194.37973 ## blame -188.93559 ## blanch -125.38813 ## blast -186.24327 ## blaze -194.63239 ## bleat -157.35749 ## bleed -185.28387 ## bleep -132.46422 ## blend -191.20349 ## bless -186.61600 ## blight -165.14486 ## blink -180.49654 ## bliss -198.34652 ## blitz -171.79726 ## bloat -177.86001 ## blob -171.53996 ## block -192.29142 ## bloke -115.79912 ## blood -189.62162 ## bloom -196.43342 ## blot -184.07464 ## blouse -172.69882 ## blow -194.93018 ## bluff -194.80366 ## blur -180.40574 ## blush -200.80527 ## boar -143.98103 ## board -193.40371 ## boast -190.16576 ## boat -200.62991 ## bob -143.95566 ## bog -163.01171 ## boil -187.41753 ## bolt -201.12835 ## bomb -187.14944 ## bond -193.50088 ## bone -199.94605 ## boo -183.41252 ## book -182.65017 ## boom -182.31854 ## boon -136.22257 ## boost -180.50187 ## boot -191.30090 ## booth -197.22089 ## booze -185.34293 ## bore -184.45599 ## boss -193.25143 ## bough -96.02206 ## bounce -200.88341 ## bound -185.03387 ## bout -140.82693 ## bowl -185.48560 ## box -181.85502 ## boy -197.94150 ## brace -188.09038 ## brad -93.89473 ## brag -188.95756 ## braid -179.85516 ## brain -195.29232 ## brake -200.99390 ## bran -84.22164 ## branch -183.72877 ## brand -185.22584 ## brass -198.41293 ## brat -182.01103 ## brawl -174.25434 ## brawn -82.04808 ## breach -140.02970 ## bread -200.46399 ## break -190.42288 ## breast -183.88243 ## breath -188.84558 ## breed -189.48451 ## breeze -199.04383 ## brew -192.13872 ## bribe -192.44277 ## brick -183.68374 ## bride -193.32446 ## bridge -182.66701 ## brig -87.00210 ## brim -156.28506 ## bring -199.97936 ## brink -165.33005 ## broach -101.67591 ## broad -184.14711 ## broil -188.83623 ## bronze -194.90983 ## brooch -144.85307 ## brood -111.85702 ## brook -138.60347 ## broom -200.65621 ## broth -105.41151 ## brow -168.12982 ## bruise -184.30588 ## brunt -135.10110 ## brush -183.22355 ## brute -178.24258 ## buck -171.40396 ## bud -198.25589 ## budge -180.94456 ## buff -178.05972 ## bug -200.45603 ## build -195.49856 ## bulb -190.58618 ## bulge -181.62072 ## bulk -201.21282 ## bull -192.23010 ## bum -185.53349 ## bump -180.65765 ## bun -181.01941 ## bunch -194.60407 ## bunk -148.84434 ## burn -187.44693 ## burr -149.28860 ## burst -184.95025 ## bus -195.88880 ## bush -187.16601 ## bust -192.71986 ## butt -185.85764 ## buy -197.22608 ## buzz -191.01296 ## cab -189.31414 ## cad -94.64563 ## cage -196.05196 ## cake -197.79401 ## calf -189.19360 ## call -199.38304 ## cam -179.76373 ## camp -186.84921 ## can -194.03450 ## cane -182.10092 ## cant -165.08879 ## cap -189.91369 ## cape -185.06189 ## car -199.84930 ## card -187.43885 ## care -187.49421 ## cart -183.78949 ## carve -187.96568 ## case -183.55075 ## cash -199.32521 ## cask -150.36261 ## cast -191.30003 ## caste -146.56770 ## cat -191.56693 ## catch -200.53959 ## cause -191.64140 ## cave -194.45719 ## cease -181.37334 ## cell -186.90544 ## cent -184.33529 ## chafe -75.51498 ## chain -181.65685 ## chair -200.40358 ## chaise -100.81512 ## chalk -196.17666 ## champ -191.66872 ## chance -200.93094 ## change -192.45362 ## chant -185.03447 ## chap -177.44020 ## char -68.46758 ## charge -194.79495 ## charm -200.86638 ## chart -197.81125 ## chase -200.24425 ## chat -189.45649 ## cheat -190.39801 ## check -198.39310 ## cheek -184.48965 ## cheer -200.34693 ## cheese -193.36714 ## chef -196.11278 ## chess -188.22427 ## chest -189.05611 ## chew -198.32585 ## chide -91.71206 ## chief -192.85386 ## child -195.18982 ## chime -184.57576 ## chin -181.01093 ## chip -199.00443 ## chive -123.44145 ## choice -197.97144 ## choir -192.00608 ## choke -186.05490 ## chomp -121.12000 ## choose -193.94850 ## chop -218.63852 ## chord -171.56332 ## chore -176.05107 ## chow -129.50781 ## chrome -172.35499 ## chuck -108.07041 ## chum -94.27296 ## chump -146.09800 ## chunk -181.15673 ## church -198.07686 ## churn -168.15092 ## chute -135.57633 ## cinch -132.48822 ## cite -169.39440 ## claim -183.59400 ## clam -183.37827 ## clamp -180.45165 ## clan -150.00296 ## clang -173.81098 ## clap -207.24220 ## clash -181.86249 ## class -193.98180 ## clause -133.02072 ## claw -187.57444 ## clay -196.65089 ## cleat -83.63746 ## clench -142.35169 ## clerk -183.34216 ## click -190.02281 ## cliff -195.01134 ## climb -199.07735 ## clinch -122.08349 ## cling -187.60078 ## clip -218.89310 ## cloak -184.24439 ## clock -194.97953 ## clod -130.05891 ## clog -147.25097 ## clot -180.13859 ## cloth -184.46511 ## cloud -187.55839 ## clout -174.13905 ## clove -131.16563 ## clown -196.03988 ## club -180.83260 ## cluck -124.64114 ## clump -139.14257 ## clutch -185.24986 ## coach -198.34055 ## coal -200.14164 ## coast -199.03566 ## coat -184.64238 ## coax -170.23921 ## cock -178.45820 ## cod -174.57753 ## code -180.97523 ## coil -181.77305 ## coin -193.51354 ## coke -187.51022 ## colt -164.12220 ## comb -194.19489 ## come -191.11122 ## cone -180.49716 ## cook -194.54499 ## coop -132.64990 ## cop -187.59229 ## cope -190.58579 ## cord -196.17560 ## core -188.10518 ## cork -199.57276 ## corn -192.90891 ## corps -164.00444 ## corpse -189.23185 ## cost -195.36964 ## cot -156.64105 ## couch -197.45139 ## cough -187.03208 ## count -217.84091 ## coup -130.69606 ## coupe -131.78313 ## course -192.21289 ## court -199.68152 ## cove -174.66380 ## cow -207.93440 ## cowl -79.16103 ## cox -185.92867 ## crab -187.65680 ## crack -190.65621 ## craft -190.62081 ## crag -133.96321 ## cram -171.49642 ## cramp -183.33555 ## crane -179.95949 ## crank -181.54295 ## crap -186.18659 ## crash -199.75401 ## crate -160.10062 ## crave -180.76333 ## crawl -190.86481 ## craze -184.42817 ## creak -180.55221 ## cream -190.42547 ## crease -141.98035 ## creed -187.18248 ## creek -182.42283 ## creep -193.43466 ## crepe -126.11991 ## crest -182.43332 ## crew -191.06474 ## crime -181.11049 ## croak -161.38980 ## crone -165.66314 ## crook -191.27333 ## croon -78.44560 ## crop -192.24369 ## cross -188.28667 ## crouch -180.25490 ## crow -194.60014 ## crowd -184.34005 ## crown -196.03991 ## crumb -196.51806 ## crunch -180.84114 ## crush -195.22073 ## crust -200.53826 ## crutch -179.71648 ## crux -100.86016 ## cry -189.14185 ## crypt -178.51140 ## cub -175.90026 ## cube -197.38293 ## cud -96.53218 ## cue -187.12064 ## cuff -155.37406 ## cull -140.84171 ## cult -178.16884 ## cup -198.20140 ## cur -180.14039 ## curb -180.74474 ## curd -146.87155 ## cure -183.56937 ## curl -196.35512 ## curse -192.69476 ## curve -194.28198 ## cusp -149.77829 ## cut -199.67885 ## cyst -89.16689 ## czar -91.18242 ## dad -196.62455 ## dale -105.53136 ## dam -173.80358 ## dame -162.49351 ## damn -181.66803 ## damp -209.91264 ## dance -200.63086 ## dare -200.39417 ## darn -168.02181 ## dash -190.99587 ## date -183.79488 ## daunt -133.97389 ## dawn -190.14072 ## deal -201.01035 ## dean -168.18573 ## dearth -148.41103 ## debt -193.93207 ## deck -201.15082 ## deed -191.01543 ## deem -91.13100 ## deer -196.33211 ## dell -80.69776 ## den -180.44026 ## dent -180.65280 ## desk -201.03569 ## dial -183.48571 ## dice -188.75710 ## die -189.10200 ## dig -197.56064 ## dike -94.58259 ## dill -137.67789 ## dime -182.62316 ## din -177.53529 ## dine -165.61647 ## dint -57.00731 ## dip -191.20058 ## dirge -163.84647 ## dirt -196.81738 ## disc -180.40030 ## dish -209.01026 ## ditch -181.87106 ## dive -185.07340 ## do -195.02990 ## dock -215.99127 ## dodge -184.76229 ## doe -161.63446 ## dog -194.18373 ## dole -171.96681 ## doll -181.98804 ## dome -179.91678 ## doom -181.66542 ## door -198.07026 ## dope -183.56799 ## dose -182.10807 ## doubt -191.71819 ## dough -190.01009 ## douse -87.93434 ## draft -185.61917 ## drag -199.16559 ## drain -186.91320 ## drake -128.99536 ## dram -61.66574 ## drape -170.05545 ## draught -176.00763 ## draw -186.86532 ## drawl -181.59201 ## dread -176.26934 ## dream -200.44281 ## dress -189.73487 ## drift -180.27390 ## drill -195.81357 ## drink -198.81291 ## drip -198.69315 ## drive -197.67095 ## drone -178.40936 ## droop -122.89942 ## drop -191.56759 ## dross -176.57875 ## drought -167.63177 ## drove -176.16415 ## drown -181.05452 ## drum -194.35796 ## duck -216.69012 ## duct -126.54745 ## dud -129.74875 ## duel -188.71094 ## dug -186.27951 ## duke -180.96454 ## dump -191.35165 ## dun -180.28043 ## dune -177.33480 ## dung -98.89113 ## dunk -151.71047 ## dusk -190.12137 ## dust -199.54212 ## dwarf -180.77459 ## dwell -172.50535 ## ear -196.88224 ## earl -157.48977 ## earn -187.52218 ## earth -195.82627 ## ease -180.98396 ## east -171.11772 ## eat -189.95817 ## ebb -139.52032 ## edge -194.51263 ## eel -161.25098 ## egg -199.67159 ## elk -181.43786 ## elm -182.60086 ## end -181.59002 ## err -117.43488 ## eve -181.61675 ## ewe -114.59184 ## face -197.99366 ## fact -199.51572 ## fad -169.12056 ## fade -188.69965 ## fail -180.56733 ## fair -192.27541 ## faith -200.82745 ## fake -183.14828 ## fame -180.32311 ## fan -181.44536 ## fang -153.91650 ## farce -128.83801 ## fare -176.54643 ## farm -200.43607 ## fast -195.47234 ## fate -199.77081 ## fault -195.75784 ## fawn -169.78123 ## faze -161.37956 ## fear -199.41411 ## feast -198.80146 ## feat -171.81362 ## fee -176.63271 ## feed -187.77635 ## feel -200.76150 ## feint -146.21897 ## fell -217.53817 ## fen -160.55269 ## fence -193.26012 ## fern -133.64212 ## fetch -196.10547 ## feud -177.24139 ## fiend -100.06022 ## fife -95.12509 ## fig -178.07028 ## fight -182.32497 ## file -191.68091 ## fill -175.68862 ## film -192.12628 ## filth -164.73944 ## fin -177.10972 ## find -189.25564 ## fine -181.82587 ## fink -128.19955 ## fir -160.69287 ## fire -199.86895 ## firm -197.81085 ## fish -198.30845 ## fist -160.05563 ## fix -199.19887 ## flag -198.46404 ## flail -84.08973 ## flair -167.02357 ## flake -177.85993 ## flame -194.72421 ## flange -77.78611 ## flank -165.52170 ## flare -193.75979 ## flask -186.04244 ## flaw -185.49454 ## flax -150.47932 ## flea -186.79512 ## fleck -114.79213 ## flee -179.89965 ## fleet -177.65238 ## flesh -190.19661 ## flex -186.41256 ## flick -178.21487 ## flight -181.29330 ## fling -183.60529 ## flint -179.31598 ## flip -182.12116 ## flirt -195.48457 ## float -184.83669 ## flock -187.60664 ## floe -124.83803 ## flog -172.28889 ## flood -201.00571 ## floor -194.93437 ## flop -166.74578 ## flour -196.72488 ## flow -180.73385 ## fluff -182.38838 ## fluke -183.47084 ## flush -189.89104 ## flute -182.08558 ## flux -167.27107 ## fly -217.99313 ## foal -146.96307 ## foam -186.60844 ## foe -186.51443 ## fog -185.98901 ## foil -186.45515 ## fold -199.14960 ## folk -191.49742 ## font -128.39289 ## food -192.46378 ## fool -200.77036 ## foot -198.20382 ## force -181.76007 ## ford -154.80240 ## forge -158.95721 ## fork -196.29043 ## form -182.59819 ## fort -148.53676 ## found -198.75044 ## fowl -199.62518 ## fox -200.83612 ## frame -176.34010 ## fraud -167.72184 ## fray -150.17128 ## freak -190.49511 ## freeze -184.41054 ## freight -175.58916 ## fret -118.61732 ## friend -192.71619 ## frieze -151.34849 ## fright -180.89830 ## frill -167.57179 ## fringe -176.32200 ## frock -139.43297 ## frog -193.45638 ## front -198.21653 ## frost -182.99339 ## froth -108.04893 ## frown -180.45973 ## fruit -197.51965 ## fry -207.23628 ## fuel -198.32659 ## full -194.13626 ## fun -192.26156 ## fund -182.25280 ## funk -175.44217 ## fur -193.97540 ## fuse -177.01873 ## fuss -182.68614 ## fuzz -149.71941 ## gab -142.05673 ## gag -153.90200 ## gain -181.93614 ## gait -128.41767 ## gal -123.49029 ## gale -156.99413 ## gall -157.17548 ## game -198.27914 ## gang -185.16851 ## gap -189.97582 ## garb -113.91571 ## gas -180.65589 ## gash -105.17302 ## gasp -180.73184 ## gate -177.42815 ## gauge -141.47216 ## gauze -135.20602 ## gay -181.83600 ## gaze -176.88690 ## gear -195.62551 ## gel -176.01706 ## gem -184.61844 ## gene -162.34573 ## get -192.14872 ## ghost -192.78995 ## ghoul -116.12786 ## gibe -152.77635 ## gift -200.60508 ## gig -121.14889 ## gill -77.93246 ## gilt -138.13176 ## gin -181.24206 ## gird -179.93736 ## girl -185.41349 ## gist -129.11464 ## give -200.41921 ## glance -187.06491 ## gland -181.50379 ## glare -199.90763 ## glass -199.48135 ## glaze -186.50647 ## gleam -149.70623 ## glean -78.15143 ## glee -160.76827 ## glen -138.05496 ## glide -179.37727 ## glimpse -181.60587 ## glint -159.28343 ## gloat -147.86417 ## globe -175.12505 ## gloom -192.23249 ## gloss -197.04694 ## glove -181.16216 ## glow -180.92182 ## glue -190.64795 ## gnaw -148.13583 ## gnome -105.86890 ## go -187.69626 ## goad -175.42550 ## goal -196.93545 ## goat -187.41293 ## gob -92.92868 ## god -180.44330 ## gold -181.47352 ## golf -179.63170 ## gong -136.75768 ## goon -82.58610 ## goose -181.13527 ## gore -113.73461 ## gouge -113.02282 ## gourd -112.04557 ## gout -141.88418 ## gown -176.09007 ## grab -182.00879 ## grace -192.65180 ## grade -186.62191 ## graft -154.77915 ## grail -114.55579 ## grain -184.09745 ## gram -146.18919 ## grant -191.43474 ## grape -189.60298 ## graph -185.83960 ## grasp -185.26877 ## grass -182.52369 ## grate -166.38184 ## grave -191.07284 ## graze -176.97760 ## grease -182.23696 ## greed -186.00495 ## greet -131.94855 ## grid -179.17089 ## grill -181.08284 ## grille -98.32969 ## grime -163.38482 ## grin -174.34635 ## grind -186.01090 ## grip -180.26049 ## gripe -149.76243 ## grist -104.85385 ## grit -133.28047 ## groan -183.79673 ## groin -159.07079 ## groom -193.53931 ## groove -183.85655 ## grope -147.93012 ## grouch -162.22721 ## ground -197.96126 ## group -190.42197 ## grouse -157.99376 ## grove -162.20875 ## grow -201.06608 ## growl -182.43694 ## grub -121.92463 ## grudge -175.96427 ## grunt -177.67133 ## guard -200.05251 ## guess -187.26570 ## guest -189.15319 ## guide -200.88828 ## guild -144.09297 ## guile -126.39128 ## guilt -182.63131 ## guise -143.77007 ## gulf -167.56129 ## gull -120.08771 ## gulp -185.41947 ## gum -181.88001 ## gun -192.22397 ## gush -162.54448 ## gust -151.78338 ## gut -175.50119 ## guy -184.26441 ## gyp -146.46216 ## hack -178.47039 ## hag -179.76685 ## hail -199.05497 ## hair -182.40259 ## hall -187.63544 ## halt -199.93177 ## ham -200.91003 ## hand -199.44050 ## hang -194.70301 ## hank -174.77663 ## hark -176.38744 ## harm -183.11507 ## harp -193.61555 ## hart -168.52174 ## hash -176.20912 ## haste -197.95679 ## hat -187.99761 ## hatch -193.38815 ## hate -200.45732 ## haul -200.91033 ## haunt -157.99475 ## have -196.13107 ## haw -174.20030 ## hawk -185.90661 ## hay -200.81383 ## haze -187.56525 ## head -200.94795 ## heal -187.82438 ## heap -186.46627 ## hear -194.58605 ## heart -199.26918 ## hearth -180.74902 ## heat -195.54487 ## heave -165.81451 ## heck -172.10979 ## hedge -173.64492 ## heed -169.91193 ## heel -185.83464 ## height -188.06076 ## heir -187.25315 ## hell -188.73324 ## helm -123.79796 ## help -201.01950 ## hem -162.33898 ## hen -181.48984 ## herb -178.17453 ## herd -185.34950 ## hick -177.52740 ## hide -218.47041 ## hike -193.76251 ## hill -199.53181 ## hilt -176.98041 ## hind -176.80490 ## hinge -180.36160 ## hint -194.41117 ## hip -198.84191 ## hire -191.31187 ## hiss -162.03448 ## hit -187.51734 ## hitch -148.42063 ## hive -171.91169 ## hob -181.48475 ## hoe -188.72219 ## hog -215.54434 ## hoist -182.30562 ## hold -196.56028 ## hole -197.40126 ## home -185.23380 ## hone -99.91129 ## hooch -178.09861 ## hood -194.60524 ## hoof -184.50822 ## hook -187.10417 ## hoop -182.79192 ## hoot -185.03854 ## hop -187.04028 ## hope -196.63149 ## horn -200.19922 ## horse -177.64210 ## hose -186.40822 ## host -195.40717 ## hound -183.13897 ## hour -185.18426 ## house -186.09944 ## howl -195.10912 ## hub -159.86107 ## hue -182.83221 ## huff -178.46191 ## hug -196.04598 ## hulk -193.74639 ## hull -179.02064 ## hum -180.51704 ## hump -155.67932 ## hunch -171.43643 ## hunk -182.50043 ## hunt -193.42263 ## hurl -192.87159 ## hurt -192.77434 ## hush -181.81350 ## hut -199.93621 ## hymn -179.70837 ## ice -200.58146 ## inch -195.52191 ## ink -201.02913 ## inn -182.07870 ## ire -174.74473 ## isle -166.65097 ## itch -152.99889 ## jab -163.82217 ## jack -194.88449 ## jade -177.90244 ## jag -169.33332 ## jail -199.84984 ## jam -199.41694 ## jape -180.12428 ## jar -190.68926 ## jaw -191.43533 ## jazz -188.97833 ## jeep -197.29170 ## jeer -182.32390 ## jerk -191.06361 ## jest -179.71290 ## jet -194.42482 ## jig -181.90520 ## job -180.71905 ## jog -200.74753 ## join -182.70937 ## joke -200.78251 ## jolt -181.87755 ## jot -175.23045 ## joust -169.66294 ## jowl -146.81413 ## joy -187.00519 ## judge -192.82922 ## jug -194.23844 ## juice -200.69223 ## jump -187.23337 ## junk -197.84974 ## jute -112.79893 ## kale -100.18255 ## keel -177.50475 ## keen -177.06191 ## keep -189.54046 ## keg -190.13366 ## kelp -97.03229 ## ken -173.00711 ## key -181.65476 ## kick -184.68939 ## kid -203.26627 ## kill -200.79462 ## kilt -133.20374 ## kin -179.01422 ## kind -188.54239 ## king -195.66770 ## kiss -199.94798 ## kit -183.92038 ## kite -196.93088 ## knack -123.44901 ## knead -183.49961 ## knee -199.65242 ## kneel -178.31363 ## knife -199.20108 ## knight -186.49948 ## knit -192.80352 ## knob -197.84757 ## knock -194.47701 ## knoll -151.90373 ## knot -199.87274 ## know -197.81408 ## lace -200.42146 ## lack -187.83600 ## lad -190.75025 ## lag -180.62334 ## lake -200.78604 ## lamb -183.68771 ## lame -200.63837 ## lamp -196.93251 ## lance -145.86903 ## land -195.33679 ## lane -197.30552 ## lap -216.39033 ## lapse -186.91969 ## lard -177.86885 ## lark -184.39725 ## lash -183.76214 ## lass -106.43691 ## last -176.23897 ## latch -186.71549 ## lath -71.31035 ## lathe -178.61193 ## laugh -187.55382 ## launch -184.23064 ## law -195.24692 ## lawn -180.29152 ## lay -191.58704 ## laze -180.34278 ## leaf -193.94081 ## leak -200.79029 ## lean -192.27152 ## leap -181.08828 ## learn -158.31850 ## lease -200.55078 ## leash -199.65926 ## leave -196.83801 ## ledge -181.67514 ## lee -142.13595 ## leg -179.99013 ## lend -199.24896 ## lens -183.66178 ## let -180.71139 ## lick -189.40868 ## lid -192.57303 ## lie -196.61014 ## life -199.71842 ## lift -192.01078 ## light -200.24591 ## like -199.73231 ## lilt -181.08670 ## limb -196.88088 ## lime -184.93160 ## limp -190.25819 ## line -171.59602 ## link -186.96680 ## lint -175.89030 ## lip -200.54641 ## lisle -72.67327 ## list -193.41954 ## load -196.30199 ## loaf -195.46059 ## loan -193.83004 ## lob -163.11344 ## lobe -162.57905 ## lock -198.67102 ## lodge -195.13566 ## loft -178.97956 ## log -185.22078 ## loin -180.45703 ## look -200.89286 ## loom -151.07758 ## loon -152.26744 ## loop -198.47144 ## loot -184.21423 ## lop -178.76689 ## lope -179.87693 ## lord -201.15254 ## lore -173.11925 ## lose -186.88681 ## loss -194.38298 ## lot -198.80471 ## lounge -182.29248 ## louse -138.15435 ## love -200.33196 ## low -198.61875 ## luck -190.81330 ## lug -185.59208 ## lull -153.65927 ## lump -196.41526 ## lung -180.98134 ## lurch -122.99627 ## lure -181.35837 ## lurk -179.32358 ## lust -182.89164 ## lute -180.48183 ## lye -113.39506 ## lymph -143.73762 ## lynch -171.52063 ## maid -198.09962 ## mail -184.84235 ## make -200.80781 ## mall -180.99489 ## malt -190.31519 ## man -200.79574 ## mane -178.15249 ## manse -179.99685 ## map -200.88926 ## mar -152.80806 ## march -208.94308 ## mare -153.04916 ## mark -183.89005 ## marsh -151.77141 ## mart -156.16528 ## mash -182.90075 ## mask -200.03227 ## mass -183.25182 ## mast -184.29974 ## mat -182.98022 ## match -193.21544 ## mate -189.31414 ## maw -180.44250 ## may -185.46891 ## maze -188.60828 ## mead -165.20365 ## meal -200.22039 ## mean -182.43837 ## meat -185.86031 ## meet -195.91554 ## meld -181.95453 ## melt -197.25873 ## mend -185.49384 ## merge -185.13662 ## mesh -185.50697 ## mess -176.37793 ## mew -93.25702 ## might -182.50529 ## mile -190.52918 ## milk -188.72240 ## mill -175.77660 ## mime -117.24062 ## mince -124.07608 ## mind -199.74716 ## mine -181.29971 ## mink -143.47992 ## mint -188.97949 ## mirth -160.28014 ## miss -189.59721 ## mist -193.40429 ## mite -140.20659 ## mitt -162.01465 ## mix -195.93078 ## moan -180.78331 ## mob -198.98451 ## mock -182.82260 ## mode -176.03664 ## mole -191.68787 ## moll -134.16861 ## mom -193.87945 ## monk -195.70333 ## month -198.53557 ## moo -169.34995 ## mood -187.67002 ## moon -181.15562 ## moose -185.85566 ## moot -154.24901 ## mop -193.99076 ## moss -186.95396 ## moth -144.23981 ## mould -154.46921 ## mount -194.34907 ## mourn -192.96060 ## mouse -186.28277 ## mouth -196.54941 ## move -195.40323 ## mow -170.08923 ## muck -127.07729 ## mud -199.67957 ## muff -157.43872 ## mug -197.36210 ## mulch -158.18027 ## mule -182.71257 ## mum -145.17176 ## munch -161.30880 ## muse -146.61355 ## mush -160.07077 ## must -191.94731 ## myth -180.64856 ## nab -129.49141 ## nail -181.13083 ## name -181.10521 ## nap -182.97976 ## nape -152.35898 ## naught -116.73088 ## neck -193.97846 ## need -198.85321 ## nerve -180.74974 ## nest -188.23496 ## news -195.08342 ## newt -154.34379 ## nick -110.02855 ## niece -182.17530 ## night -183.06171 ## nil -90.11699 ## nip -152.17400 ## nod -178.18764 ## node -168.31176 ## noise -194.50435 ## nonce -178.07127 ## nook -127.53759 ## noon -180.34609 ## noose -175.11994 ## norm -180.74248 ## north -186.63133 ## nose -183.30458 ## notch -175.82574 ## note -181.15978 ## noun -158.11040 ## nudge -161.41559 ## nun -180.75218 ## nurse -182.95022 ## nut -198.20571 ## nymph -176.22918 ## oak -200.34944 ## oath -181.48696 ## oil -200.78910 ## ooze -169.22253 ## orb -106.54526 ## ore -162.97071 ## ought -180.08220 ## ounce -180.72218 ## oust -120.36905 ## owl -200.70880 ## pace -186.45204 ## pack -200.03755 ## pact -194.62752 ## pad -196.85380 ## page -199.01848 ## pail -181.89363 ## pain -187.32906 ## paint -200.79098 ## pair -200.91533 ## pal -198.66856 ## pale -200.27561 ## pall -180.42405 ## palm -197.91769 ## pan -193.49579 ## pane -173.63898 ## pang -113.91692 ## pant -194.06427 ## pap -155.08604 ## par -150.55460 ## pare -141.23823 ## park -195.30045 ## part -197.76299 ## pass -185.08781 ## paste -193.96262 ## pat -201.02096 ## patch -195.48718 ## pate -180.54191 ## path -199.13137 ## paunch -128.71632 ## pause -195.08610 ## pave -176.88551 ## paw -185.47866 ## pawn -181.30552 ## pay -200.19722 ## pea -200.71782 ## peace -193.35666 ## peach -183.59653 ## peak -192.52925 ## peal -180.74111 ## pear -193.74897 ## pearl -200.70403 ## peat -149.20065 ## peck -191.99359 ## pee -178.43011 ## peel -193.00972 ## peep -182.76614 ## peer -194.61593 ## peg -190.32993 ## pelt -132.93315 ## pen -194.91945 ## perch -163.05019 ## perk -180.57165 ## pest -179.61735 ## pet -198.61936 ## pew -144.58374 ## phase -181.11181 ## phrase -181.60563 ## pick -196.88221 ## pie -198.30051 ## piece -187.93957 ## pier -181.77809 ## pierce -181.03272 ## pig -200.72493 ## pike -192.16181 ## pile -201.09305 ## pill -182.88186 ## pimp -182.37559 ## pin -181.37618 ## pinch -181.51707 ## pine -196.79650 ## pint -179.79235 ## pip -141.24310 ## pipe -200.79354 ## piss -180.38935 ## pit -189.26940 ## pitch -192.42438 ## pith -156.22479 ## place -200.16531 ## plaid -195.06602 ## plain -180.30771 ## plan -199.75163 ## plane -180.41347 ## plank -165.79725 ## plant -186.87654 ## plate -193.70710 ## play -199.25126 ## plea -187.86079 ## plead -197.54024 ## please -200.60511 ## pleat -139.96200 ## pledge -183.61700 ## plod -128.38135 ## plot -199.69360 ## plough -168.01326 ## pluck -187.01972 ## plug -184.80959 ## plum -201.15028 ## plume -147.75665 ## plunge -186.43705 ## plush -190.67227 ## poach -130.40642 ## pod -175.41735 ## point -199.14027 ## poise -182.14726 ## poke -186.77324 ## pole -189.42852 ## poll -186.57126 ## pomp -174.66773 ## pond -189.41429 ## pool -200.77211 ## pop -195.60487 ## pope -198.78767 ## porch -185.46070 ## pore -161.30291 ## pork -198.89400 ## port -172.58742 ## pose -189.27807 ## post -189.02343 ## pot -199.61732 ## pouch -181.26954 ## pound -217.75718 ## pour -187.31017 ## pout -145.10510 ## praise -189.95765 ## prank -186.43456 ## pray -191.62946 ## preach -153.30282 ## prep -171.84330 ## press -192.28828 ## prey -189.16135 ## price -201.04373 ## prick -180.63602 ## pride -200.82337 ## priest -173.18802 ## prime -191.51082 ## prince -180.70657 ## print -200.01290 ## prize -194.75454 ## probe -185.76816 ## prod -125.66617 ## prop -162.65597 ## prose -167.59682 ## prove -176.96261 ## prow -146.63555 ## prowl -184.17429 ## pry -168.89280 ## psalm -148.82510 ## pub -193.56240 ## puck -178.14789 ## puff -185.96955 ## puke -160.15354 ## pull -191.09319 ## pulp -184.67662 ## pulse -197.74325 ## pump -186.66700 ## pun -152.61996 ## punch -193.28535 ## punk -190.08833 ## punt -179.36237 ## pup -191.98187 ## purge -182.04486 ## purse -184.90220 ## pus -169.22419 ## push -180.66250 ## put -186.90231 ## putt -177.24050 ## pyre -132.51119 ## quack -182.74197 ## quake -170.45057 ## quart -179.25866 ## quartz -182.25666 ## quay -180.64819 ## queen -185.98573 ## quell -90.45914 ## quench -165.11305 ## quest -180.60952 ## queue -123.85789 ## quill -175.44450 ## quince -102.66350 ## quirk -177.83388 ## quiz -183.30790 ## quote -191.33133 ## race -198.11680 ## rack -183.32338 ## raft -178.53014 ## rag -182.64471 ## rage -199.89479 ## raid -197.15718 ## rail -183.15826 ## rain -194.15535 ## raise -187.57436 ## rake -194.48466 ## ram -155.21072 ## ranch -199.36573 ## range -193.20859 ## rank -181.84561 ## rant -150.87228 ## rap -184.78255 ## rape -187.57505 ## rash -198.11612 ## rasp -153.50488 ## rat -198.03964 ## rate -189.99350 ## rave -186.42459 ## ray -180.91672 ## reach -200.87196 ## realm -182.55186 ## ream -109.76483 ## reap -167.10909 ## rear -193.66365 ## reed -155.95166 ## reef -143.87663 ## reek -166.25755 ## reel -146.38460 ## reign -179.86878 ## rein -144.30895 ## rend -179.96963 ## rent -190.18766 ## rest -200.14005 ## retch -75.93226 ## rhyme -179.63498 ## rib -196.17855 ## rice -200.77392 ## ride -185.69574 ## ridge -178.83661 ## rift -156.90625 ## rig -170.59591 ## right -197.72986 ## rile -126.35545 ## rim -183.34697 ## rime -97.32187 ## rind -157.11220 ## ring -205.12959 ## rink -153.40127 ## rinse -194.99619 ## rip -182.49526 ## rise -200.97542 ## risk -191.45216 ## rite -161.96339 ## roach -185.43835 ## road -200.40120 ## roam -188.26786 ## roar -192.19867 ## roast -182.36657 ## rob -187.81765 ## robe -182.55108 ## rock -214.41192 ## rod -187.99830 ## roe -152.55200 ## role -190.78015 ## roll -181.86569 ## romp -167.51676 ## roof -200.64774 ## rook -138.88816 ## room -201.12960 ## roost -188.87526 ## root -195.84367 ## rope -193.25524 ## rose -199.24926 ## rot -182.31482 ## rouse -109.79916 ## rout -142.80674 ## rove -102.46965 ## rub -200.95492 ## rue -158.31063 ## rug -192.37161 ## rule -195.91589 ## rum -186.37569 ## rump -177.00272 ## run -182.39464 ## rung -155.71650 ## runt -118.33002 ## ruse -125.97785 ## rush -195.98513 ## rust -186.47713 ## rut -161.82767 ## rye -178.07559 ## sack -181.38431 ## sag -181.07131 ## sail -197.21202 ## saint -193.19800 ## sake -175.30860 ## sale -183.96642 ## salt -200.93684 ## salve -169.89094 ## sand -194.04721 ## sap -161.70408 ## sash -166.15555 ## sauce -194.25654 ## save -193.62868 ## saw -180.62980 ## sax -142.90758 ## say -184.19972 ## scald -132.74152 ## scale -189.65499 ## scalp -199.18851 ## scan -179.27390 ## scar -182.48437 ## scare -180.89106 ## scarf -183.69445 ## scene -186.47739 ## scent -198.97303 ## scheme -183.74242 ## school -187.36513 ## scoop -184.99389 ## scope -182.48244 ## score -193.73114 ## scorn -181.21660 ## scotch -175.97100 ## scour -164.89223 ## scourge -178.14822 ## scout -178.13461 ## scrap -180.07528 ## scrape -180.81134 ## scratch -182.85589 ## scream -181.03116 ## screech -156.68407 ## screen -183.02911 ## screw -198.49070 ## scribe -179.24772 ## script -200.85556 ## scrub -180.37167 ## scuff -125.06188 ## sea -195.16190 ## seal -182.82942 ## seam -134.86899 ## sear -138.84448 ## search -181.41687 ## seat -190.31345 ## sect -99.94390 ## see -191.78834 ## seed -188.68877 ## seek -200.85510 ## seem -181.75373 ## seep -141.27184 ## seize -195.57464 ## self -200.86794 ## sell -181.30148 ## send -187.14534 ## sense -189.31080 ## serf -152.05742 ## serge -147.29812 ## serve -182.59617 ## set -216.67293 ## sew -186.87950 ## sex -194.72305 ## shack -186.29230 ## shade -191.77651 ## shaft -181.66234 ## shag -160.94406 ## shah -147.18544 ## shake -193.82763 ## shall -177.64945 ## sham -159.27054 ## shame -185.77155 ## shank -137.77019 ## shape -197.14660 ## shard -129.99753 ## share -200.24253 ## shark -198.84384 ## shave -186.78454 ## shawl -160.77695 ## shay -168.85475 ## sheaf -134.71013 ## shear -174.93947 ## sheath -153.11711 ## shed -184.09195 ## sheen -138.83067 ## sheep -187.45273 ## sheer -173.79078 ## sheet -200.41153 ## shelf -194.14407 ## shell -199.56132 ## shield -199.55416 ## shift -187.21278 ## shin -147.15171 ## shine -180.82416 ## ship -195.32094 ## shirt -184.85724 ## shoal -132.34242 ## shock -184.36120 ## shoe -182.78819 ## shoot -190.72601 ## shop -193.30458 ## shore -182.16144 ## shot -182.83511 ## should -198.11266 ## shout -192.52303 ## shove -182.26475 ## show -188.95606 ## shred -180.62172 ## shrimp -188.37147 ## shrine -140.27048 ## shrink -184.59246 ## shrub -181.05770 ## shrug -165.70948 ## shuck -66.41085 ## shun -148.85423 ## shunt -88.92763 ## shut -181.15680 ## side -184.96325 ## siege -176.44916 ## sigh -168.48956 ## sight -185.19623 ## sign -182.02804 ## silk -182.17829 ## sill -97.09991 ## sin -182.22347 ## sine -118.70866 ## sing -198.64374 ## sink -192.16917 ## sip -196.58851 ## sir -177.99672 ## sit -198.01134 ## site -182.20435 ## size -197.90666 ## skate -194.54895 ## skeet -109.43309 ## sketch -182.82084 ## ski -183.35813 ## skid -167.38537 ## skiff -180.61240 ## skill -190.75874 ## skin -180.88862 ## skip -185.55312 ## skirt -183.05175 ## skit -192.00281 ## skulk -179.31218 ## skull -196.78044 ## skunk -177.59173 ## sky -200.66092 ## slab -162.59690 ## slam -183.43196 ## slang -184.48607 ## slant -179.90844 ## slap -187.07268 ## slash -180.14653 ## slat -151.77343 ## slate -171.99171 ## slave -195.93577 ## sleep -185.52574 ## sleeve -196.70453 ## slice -198.69686 ## slide -188.20557 ## slip -200.91955 ## slit -176.38264 ## slob -181.57825 ## sloe -123.63302 ## sloop -167.91262 ## slop -138.09665 ## slope -180.03767 ## slot -185.55774 ## slouch -169.68507 ## slough -145.58308 ## sludge -122.18314 ## slug -180.66804 ## sluice -92.79625 ## slum -156.86831 ## slump -183.36249 ## smack -183.89882 ## smart -190.89899 ## smash -191.95488 ## smear -198.17038 ## smell -201.10669 ## smelt -119.75341 ## smile -198.52241 ## smirk -178.61037 ## smoke -199.91456 ## snack -180.85241 ## snag -187.81698 ## snail -180.88456 ## snake -189.01833 ## snap -191.98350 ## snare -183.00731 ## snatch -181.81922 ## sneak -185.82816 ## sneer -183.88804 ## sniff -180.79746 ## snip -175.96218 ## snob -182.07073 ## snoop -181.84613 ## snort -176.38866 ## snout -168.95207 ## snow -186.54855 ## snug -180.52870 ## soak -197.47777 ## soap -200.16648 ## sob -180.05082 ## sock -183.37524 ## sod -171.87157 ## sole -186.57964 ## solve -181.25563 ## son -181.25279 ## song -190.83791 ## soot -119.54193 ## soothe -170.16984 ## sop -83.73826 ## sort -186.53189 ## soul -197.95492 ## sound -198.28540 ## soup -190.62453 ## source -198.28720 ## south -160.28872 ## soy -175.16694 ## spa -174.78612 ## space -197.98746 ## spade -185.49269 ## span -180.64745 ## spare -178.05934 ## spark -197.20337 ## spat -176.79567 ## spate -111.00927 ## speak -183.95416 ## spear -189.72435 ## speck -139.14799 ## speech -189.36852 ## speed -192.29385 ## spell -216.32293 ## spend -200.73796 ## sphere -181.48721 ## sphinx -179.94986 ## spice -181.51850 ## spike -200.21480 ## spill -200.79293 ## spin -200.44847 ## spine -186.52253 ## spire -158.62391 ## spit -187.10866 ## spite -166.83537 ## splash -191.04130 ## spleen -119.16819 ## splice -141.89796 ## split -191.21046 ## splurge -149.94453 ## spoil -190.85156 ## spoke -199.23057 ## spoof -140.69350 ## spool -200.30228 ## spoon -183.00642 ## sport -189.72236 ## spot -187.75947 ## spouse -184.65006 ## spout -180.21159 ## sprawl -180.95358 ## spray -180.97595 ## spread -182.45691 ## spree -128.06103 ## sprig -115.04485 ## spring -190.76488 ## sprite -139.41579 ## sprout -185.85706 ## spur -181.05877 ## spurt -150.35849 ## spy -188.31844 ## squad -180.87106 ## squall -150.39662 ## square -183.61698 ## squash -181.76710 ## squat -168.49604 ## squaw -131.41016 ## squawk -148.36055 ## squeak -182.72143 ## squeal -181.00388 ## squeeze -185.02157 ## squint -182.96653 ## squire -159.63536 ## squirm -183.28023 ## squirt -181.15936 ## stab -182.63028 ## stack -184.97646 ## staff -196.70820 ## stag -192.24276 ## stage -189.04541 ## stain -180.92342 ## stair -185.67162 ## stake -176.17801 ## stalk -183.83687 ## stall -195.48424 ## stamp -186.02846 ## stance -177.40536 ## stanch -180.56654 ## stand -192.21776 ## star -190.12507 ## starch -188.25042 ## stare -185.37834 ## start -186.51462 ## starve -183.12461 ## state -187.50172 ## staunch -123.61598 ## stave -142.97567 ## stay -198.67878 ## stead -155.95756 ## steak -181.94464 ## steal -197.20840 ## steam -180.82404 ## steed -145.20281 ## steel -184.23585 ## steer -181.12372 ## stem -181.08883 ## stench -147.23064 ## step -200.63404 ## stew -201.07644 ## stick -191.94924 ## still -197.13322 ## stilt -133.62956 ## sting -181.41850 ## stink -183.02114 ## stint -179.08701 ## stir -200.52346 ## stitch -159.49679 ## stock -200.79501 ## stole -197.24021 ## stone -182.69565 ## stool -200.61709 ## stoop -147.13250 ## stop -191.18680 ## store -190.57167 ## stork -183.89560 ## storm -190.51947 ## stout -179.12409 ## stove -187.92919 ## stow -149.30680 ## strafe -147.84157 ## strain -189.56632 ## strand -177.70036 ## strap -181.55636 ## straw -198.46284 ## stray -195.30999 ## streak -185.23098 ## stream -180.72229 ## street -184.65560 ## stress -199.67422 ## stretch -184.51075 ## stride -189.82378 ## strife -168.19173 ## strike -199.54882 ## string -185.42961 ## strip -197.04012 ## stripe -188.38282 ## strive -180.66683 ## stroke -184.98133 ## stroll -181.33207 ## strut -150.71254 ## stub -176.97839 ## stud -188.61372 ## stuff -191.09976 ## stump -186.63559 ## stunt -180.22994 ## style -201.26577 ## sub -101.36317 ## suck -181.09018 ## sue -174.48489 ## suit -188.74239 ## suite -185.04973 ## sulk -151.02667 ## sum -183.32057 ## sun -184.45041 ## sup -180.40743 ## surf -182.64958 ## surge -173.12654 ## swamp -181.09198 ## swan -180.87991 ## swap -163.73536 ## swarm -182.43298 ## swath -132.62905 ## sway -182.26333 ## swear -192.45090 ## sweat -191.82664 ## sweep -182.57891 ## swell -200.14393 ## swerve -180.52031 ## swig -150.03192 ## swim -190.68509 ## swine -183.51823 ## swing -200.76315 ## swipe -181.79668 ## swirl -180.64481 ## switch -185.40017 ## swoop -156.86835 ## sword -198.07333 ## tab -185.34020 ## tack -176.33899 ## tact -192.71237 ## tag -184.71081 ## tail -184.72629 ## taint -181.81677 ## take -197.70277 ## tale -190.42637 ## talk -184.25487 ## tamp -167.22869 ## tan -184.36062 ## tang -149.54766 ## tank -180.64483 ## tape -195.05470 ## tar -192.36391 ## tart -180.99382 ## task -199.74630 ## taste -197.67704 ## taunt -180.87142 ## tax -197.43834 ## tea -199.77953 ## teach -191.02274 ## teak -180.01711 ## team -198.86440 ## tease -192.64858 ## tech -87.81492 ## tee -184.37757 ## teens -180.63114 ## tell -194.65882 ## tempt -195.21268 ## tend -180.67394 ## tense -190.90087 ## tent -199.59222 ## test -193.52204 ## text -198.24629 ## thank -196.56181 ## thaw -182.35136 ## theft -184.26332 ## theme -184.80672 ## thief -183.78822 ## thigh -198.10655 ## thin -189.50346 ## thing -187.31531 ## think -201.13984 ## thirst -200.45240 ## thong -156.36849 ## thorn -201.22369 ## thought -189.60407 ## thrash -178.27401 ## thread -193.55186 ## threat -182.45323 ## thrift -185.10653 ## thrill -184.75849 ## thrive -183.50624 ## throat -200.86763 ## throne -164.71494 ## throng -123.56174 ## throw -183.93492 ## thrush -141.05116 ## thrust -178.71562 ## thud -165.84814 ## thug -180.18185 ## thumb -200.85400 ## thump -180.29645 ## thwack -69.88762 ## thwart -117.62108 ## tick -186.55411 ## tide -196.56662 ## tie -200.84920 ## tile -193.51764 ## till -161.59440 ## tilt -197.53378 ## time -198.48699 ## tin -180.94599 ## tint -185.77403 ## tip -197.06528 ## tire -200.97724 ## toad -196.87130 ## toast -194.68748 ## toe -181.83161 ## toil -182.27627 ## toll -177.94353 ## tomb -200.83592 ## tome -178.69155 ## ton -180.57647 ## tone -192.34434 ## tongue -197.27624 ## tool -200.33082 ## toot -134.82231 ## tooth -190.75597 ## top -191.95670 ## torch -182.64929 ## torque -167.21142 ## toss -195.88277 ## tote -134.76051 ## touch -200.38664 ## tour -195.14260 ## tout -150.25231 ## town -197.88634 ## toy -200.69677 ## trace -194.76929 ## track -194.24006 ## tract -182.29734 ## trade -199.17084 ## trail -181.11518 ## train -198.67362 ## trait -178.40999 ## tramp -177.71433 ## trance -170.77198 ## trap -190.86259 ## trash -184.49991 ## tray -165.96588 ## tread -169.87213 ## treat -192.72227 ## tree -200.78742 ## trench -181.53909 ## trend -183.81382 ## tribe -178.30892 ## trick -183.65499 ## trill -94.16184 ## trip -191.79554 ## tripe -171.75260 ## troll -136.96517 ## troop -166.04179 ## trot -135.28715 ## trough -93.68329 ## trout -194.04246 ## truce -164.77917 ## truck -185.05280 ## trump -148.60379 ## trunk -198.23570 ## trust -190.07671 ## try -195.85140 ## tryst -112.84060 ## tub -194.13517 ## tube -216.92658 ## tuck -178.55009 ## tug -198.70085 ## tune -191.38693 ## turf -171.55760 ## turn -182.79655 ## tusk -160.32521 ## twain -162.32871 ## tweed -184.84044 ## twin -197.72924 ## twinge -128.61933 ## twist -192.82111 ## twitch -162.54189 ## type -183.02509 ## urge -182.82868 ## urn -134.31288 ## use -200.83878 ## vale -91.99216 ## valve -180.06869 ## vamp -128.25497 ## van -180.81907 ## vase -182.60373 ## vault -188.14840 ## veal -178.27875 ## veer -114.97513 ## veil -181.14740 ## vein -183.58267 ## vent -178.16568 ## verb -184.68579 ## verge -159.83675 ## verse -183.17901 ## verve -134.43507 ## vest -167.99667 ## vet -151.03261 ## vex -176.05519 ## vice -173.31410 ## vie -115.53271 ## view -186.44665 ## vine -181.75089 ## voice -198.95636 ## volt -171.24165 ## vote -182.26518 ## vow -177.10664 ## wad -178.98315 ## wade -181.51478 ## wag -181.88371 ## wage -182.73040 ## wail -178.78117 ## waist -182.07413 ## wait -192.62546 ## waive -180.78230 ## wake -182.53351 ## walk -200.46506 ## wall -189.20327 ## waltz -196.91726 ## wand -165.61313 ## wane -148.80156 ## want -189.11501 ## war -199.26029 ## ward -143.55353 ## ware -169.85549 ## warn -185.87920 ## warp -180.54667 ## wart -177.63466 ## wash -185.94340 ## wasp -184.10710 ## waste -200.15585 ## watch -192.66819 ## watt -177.08191 ## wave -182.90924 ## wax -183.55177 ## way -198.28465 ## wealth -182.18369 ## wear -185.04250 ## weave -190.74687 ## web -200.42577 ## wed -197.52586 ## wedge -181.52225 ## weed -189.29598 ## week -184.75627 ## weep -181.79707 ## weigh -187.13250 ## weight -188.70790 ## weld -141.79127 ## well -200.32146 ## welt -121.10373 ## west -114.32336 ## whack -178.16918 ## wharf -185.54523 ## wheat -188.46005 ## wheel -180.62620 ## whelp -90.58334 ## whiff -156.87734 ## while -192.41232 ## whim -181.59554 ## whine -177.74229 ## whip -200.70911 ## whirl -181.79475 ## whit -134.39317 ## whiz -189.42117 ## whoop -138.18242 ## whoosh -169.41932 ## whore -182.70003 ## whorl -108.52093 ## wick -180.51515 ## wield -164.96929 ## wife -200.72735 ## wig -183.04900 ## will -200.32650 ## wilt -176.39694 ## win -182.73616 ## wine -200.01713 ## wing -201.17579 ## wink -191.84224 ## wipe -199.77175 ## wire -200.67932 ## wish -197.65218 ## wisp -133.95199 ## wit -182.50254 ## witch -183.96756 ## woe -184.55419 ## wolf -199.94775 ## womb -181.50123 ## woo -106.62975 ## wood -182.96855 ## wool -178.06060 ## word -192.47039 ## work -196.50373 ## world -198.47109 ## worm -183.73082 ## would -195.31635 ## wow -180.40012 ## wrack -180.52852 ## wrap -188.24929 ## wrath -178.23652 ## wreak -170.33323 ## wreath -175.45288 ## wreck -188.39149 ## wren -134.32343 ## wrest -178.39658 ## wretch -180.97683 ## wring -93.40979 ## wrist -196.10913 ## writ -87.58470 ## write -188.71380 ## writhe -164.88818 ## yacht -155.32948 ## yak -69.96091 ## yam -179.76093 ## yang -69.95412 ## yank -139.63448 ## yard -186.10502 ## yarn -185.51756 ## yaw -117.54558 ## yawl -114.62595 ## yawn -185.24871 ## yea -165.71544 ## year -187.99049 ## yearn -163.12214 ## yeast -187.47524 ## yell -183.94921 ## yelp -142.53705 ## yen -123.83434 ## yes -201.01980 ## yield -200.55053 ## yoke -186.55669 ## yolk -177.72978 ## yore -125.92411 ## youth -192.62610 ## zeal -172.60320 ## zest -171.22511 ## zinc -160.04071 ## zing -108.93644 ## zip -188.51307 ## zone -192.72947 ## zoo -180.22778 coef(mdl.glmmSlope2)$`Word`[2] ## RTlexdec ## ace 28.144457 ## act 29.780336 ## add 28.842057 ## age 28.696371 ## aid 27.699135 ## aide 24.137713 ## ail 18.782872 ## aim 29.105866 ## air 30.663168 ## aisle 26.650256 ## ale 27.585894 ## angst 25.334026 ## ant 29.289667 ## ape 28.661928 ## arc 19.283464 ## arch 28.225250 ## are 27.921118 ## arm 33.369373 ## art 28.942057 ## ash 28.001176 ## ask 30.129537 ## ass 28.040541 ## axe 27.840981 ## babe 28.888475 ## back 29.930486 ## badge 28.006411 ## bag 30.569973 ## bail 25.700572 ## bait 29.237819 ## bale 18.509007 ## ball 28.714381 ## ban 22.935653 ## band 27.945681 ## bang 30.134836 ## bank 29.664503 ## bar 30.679907 ## bard 17.897905 ## barge 21.602545 ## bark 30.115906 ## barn 30.701409 ## base 29.487682 ## bash 27.662692 ## bat 30.585565 ## batch 29.081562 ## bath 29.682886 ## bay 29.006597 ## beach 28.343669 ## bead 25.743000 ## beak 20.275533 ## beam 27.630154 ## bean 27.860961 ## bear 32.669600 ## beard 30.111305 ## beast 27.813670 ## beat 29.045536 ## beau 23.569578 ## beck 13.761306 ## bed 28.864315 ## bee 30.444859 ## beech 19.244617 ## beef 32.407110 ## beep 29.123800 ## beer 30.448296 ## beet 26.544312 ## beg 30.787547 ## belch 23.676772 ## bell 29.880181 ## belt 28.665469 ## bench 30.663894 ## bend 30.453120 ## berth 24.107819 ## bet 30.801089 ## bib 25.628948 ## bid 30.808322 ## bide 13.475164 ## bile 25.482820 ## bilge 14.999401 ## bill 28.991589 ## bin 24.290857 ## bind 22.962567 ## binge 26.471113 ## birch 24.195015 ## bird 29.453684 ## bit 30.321957 ## bitch 28.587198 ## bite 30.691879 ## blade 29.769067 ## blame 28.924616 ## blanch 19.067653 ## blast 28.507006 ## blaze 29.808258 ## bleat 24.026480 ## bleed 28.358191 ## bleep 20.165238 ## blend 29.276395 ## bless 28.564821 ## blight 25.234393 ## blink 27.615620 ## bliss 30.384363 ## blitz 26.266259 ## bloat 27.206663 ## blob 26.226349 ## block 29.445146 ## bloke 17.580284 ## blood 29.031029 ## bloom 30.087619 ## blot 28.170626 ## blouse 26.406102 ## blow 29.854449 ## bluff 29.834824 ## blur 27.601536 ## blush 30.765744 ## boar 21.951632 ## board 29.617675 ## boast 29.115431 ## boat 30.738545 ## bob 21.947698 ## bog 24.903516 ## boil 28.689148 ## bolt 30.815858 ## bomb 28.647563 ## bond 29.632747 ## bone 30.632469 ## boo 28.067924 ## book 27.949674 ## boom 27.898234 ## boon 20.748203 ## boost 27.616446 ## boot 29.291505 ## booth 30.209764 ## booze 28.367353 ## bore 28.229778 ## boss 29.594055 ## bough 14.512627 ## bounce 30.777866 ## bound 28.319413 ## bout 21.462393 ## bowl 28.389483 ## box 27.826336 ## boy 30.321540 ## brace 28.793515 ## brad 14.182654 ## brag 28.928025 ## braid 27.516134 ## brain 29.910621 ## brake 30.795004 ## bran 12.682243 ## branch 28.116978 ## brand 28.349190 ## brass 30.394664 ## brat 27.850536 ## brawl 26.647382 ## brawn 12.345098 ## breach 21.338735 ## bread 30.712809 ## break 29.155313 ## breast 28.140811 ## breath 28.910655 ## breed 29.009762 ## breeze 30.492524 ## brew 29.421460 ## bribe 29.468623 ## brick 28.109992 ## bride 29.605382 ## bridge 27.952286 ## brig 13.113525 ## brim 23.860133 ## bring 30.637636 ## brink 25.263119 ## broach 15.389606 ## broad 28.181866 ## broil 28.909205 ## bronze 29.851293 ## brooch 22.086896 ## brood 16.968817 ## brook 21.117509 ## broom 30.742625 ## broth 15.969042 ## brow 25.697396 ## bruise 28.206495 ## brunt 20.574249 ## brush 28.038612 ## brute 27.266004 ## buck 26.205253 ## bud 30.370305 ## budge 27.685114 ## buff 27.237640 ## bug 30.711573 ## build 29.942611 ## bulb 29.180643 ## bulge 27.789994 ## bulk 30.828960 ## bull 29.435635 ## bum 28.396911 ## bump 27.640610 ## bun 27.696723 ## bunch 29.803865 ## bunk 22.705989 ## burn 28.693708 ## burr 22.774899 ## burst 28.306444 ## bus 30.003142 ## bush 28.650134 ## bust 29.511601 ## butt 28.447190 ## buy 30.210570 ## buzz 29.246842 ## cab 28.983335 ## cad 14.299127 ## cage 30.028450 ## cake 30.298662 ## calf 28.964637 ## call 30.545140 ## cam 27.501952 ## camp 28.600995 ## can 29.715518 ## cane 27.864479 ## cant 25.225696 ## cap 29.076331 ## cape 28.323761 ## car 30.617462 ## card 28.692455 ## care 28.701042 ## cart 28.126396 ## carve 28.774172 ## case 28.089364 ## cash 30.536170 ## cask 22.941491 ## cast 29.291370 ## caste 22.352854 ## cat 29.332769 ## catch 30.724535 ## cause 29.344320 ## cave 29.781083 ## cease 27.751623 ## cell 28.609716 ## cent 28.211055 ## chafe 11.331736 ## chain 27.795599 ## chair 30.703437 ## chaise 15.256088 ## chalk 30.047793 ## champ 29.348558 ## chance 30.785237 ## change 29.470306 ## chant 28.319507 ## chap 27.141545 ## char 10.238602 ## charge 29.833473 ## charm 30.775224 ## chart 30.301336 ## chase 30.678725 ## chat 29.005414 ## cheat 29.151455 ## check 30.391589 ## cheek 28.234999 ## cheer 30.694650 ## cheese 29.612003 ## chef 30.037884 ## chess 28.814283 ## chest 28.943310 ## chew 30.381157 ## chide 13.844095 ## chief 29.532386 ## child 29.894723 ## chime 28.248356 ## chin 27.695408 ## chip 30.486413 ## chive 18.765700 ## choice 30.326185 ## choir 29.400887 ## choke 28.477788 ## chomp 18.405616 ## choose 29.702178 ## chop 33.531893 ## chord 26.229972 ## chore 26.926074 ## chow 19.706665 ## chrome 26.352770 ## chuck 16.381469 ## chum 14.241322 ## chump 22.279999 ## chunk 27.718023 ## church 30.342536 ## churn 25.700668 ## chute 20.647964 ## cinch 20.168961 ## cite 25.893547 ## claim 28.096073 ## clam 28.062611 ## clamp 27.608658 ## clan 22.885705 ## clang 26.578610 ## clap 31.764189 ## clash 27.827496 ## class 29.707344 ## clause 20.251558 ## claw 28.713486 ## clay 30.121351 ## cleat 12.591630 ## clench 21.698902 ## clerk 28.057009 ## click 29.093258 ## cliff 29.867037 ## climb 30.497724 ## clinch 18.555065 ## cling 28.717572 ## clip 33.571382 ## cloak 28.196956 ## clock 29.862104 ## clod 19.792147 ## clog 22.458839 ## clot 27.560098 ## cloth 28.231193 ## cloud 28.710996 ## clout 26.629499 ## clove 19.963812 ## clown 30.026576 ## club 27.667747 ## cluck 18.951785 ## clump 21.201130 ## clutch 28.352917 ## coach 30.383438 ## coal 30.662808 ## coast 30.491257 ## coat 28.258688 ## coax 26.024587 ## cock 27.299449 ## cod 26.697511 ## code 27.689870 ## coil 27.813622 ## coin 29.634711 ## coke 28.703525 ## colt 25.075766 ## comb 29.740396 ## come 29.262083 ## cone 27.615716 ## cook 29.794702 ## coop 20.194039 ## cop 28.716255 ## cope 29.180583 ## cord 30.047627 ## core 28.795811 ## cork 30.574567 ## corn 29.540926 ## corps 25.057500 ## corpse 28.970570 ## cost 29.922614 ## cot 23.915352 ## couch 30.245518 ## cough 28.629359 ## count 33.408175 ## coup 19.890976 ## coupe 20.059594 ## course 29.432965 ## court 30.591438 ## cove 26.710892 ## cow 31.871558 ## cowl 11.897282 ## cox 28.458207 ## crab 28.726261 ## crack 29.191505 ## craft 29.186014 ## crag 20.397750 ## cram 26.219595 ## cramp 28.055985 ## crane 27.532317 ## crank 27.777931 ## crap 28.498214 ## crash 30.602682 ## crate 24.451971 ## crave 27.657002 ## crawl 29.223862 ## craze 28.225462 ## creak 27.624255 ## cream 29.155715 ## crease 21.641304 ## creed 28.652688 ## creek 27.914411 ## creep 29.622476 ## crepe 19.181161 ## crest 27.916038 ## crew 29.254873 ## crime 27.710851 ## croak 24.651939 ## crone 25.314784 ## crook 29.287228 ## croon 11.786311 ## crop 29.437743 ## cross 28.823962 ## crouch 27.578139 ## crow 29.803256 ## crowd 28.211794 ## crown 30.026581 ## crumb 30.100748 ## crunch 27.669072 ## crush 29.899517 ## crust 30.724329 ## crutch 27.494624 ## crux 15.263074 ## cry 28.956610 ## crypt 27.307702 ## cub 26.902683 ## cube 30.234900 ## cud 14.591753 ## cue 28.643097 ## cuff 23.718826 ## cull 21.464686 ## cult 27.254566 ## cup 30.361853 ## cur 27.560378 ## curb 27.654120 ## curd 22.399986 ## cure 28.092252 ## curl 30.075473 ## curse 29.507709 ## curve 29.753905 ## cusp 22.850855 ## cut 30.591024 ## cyst 13.449309 ## czar 13.761942 ## dad 30.117266 ## dale 15.987633 ## dam 26.577462 ## dame 24.823137 ## damn 27.797332 ## damp 32.178406 ## dance 30.738691 ## dare 30.701979 ## darn 25.680642 ## dash 29.244191 ## date 28.127232 ## daunt 20.399406 ## dawn 29.111547 ## deal 30.797555 ## dean 25.706068 ## dearth 22.638778 ## debt 29.699630 ## deck 30.819344 ## deed 29.247225 ## deem 13.753966 ## deer 30.071904 ## dell 12.135647 ## den 27.606891 ## dent 27.639858 ## desk 30.801486 ## dial 28.079276 ## dice 28.896931 ## die 28.950429 ## dig 30.262464 ## dike 14.289349 ## dill 20.973940 ## dime 27.945484 ## din 27.156296 ## dine 25.307544 ## dint 8.460978 ## dip 29.275943 ## dirge 25.032997 ## dirt 30.147176 ## disc 27.600692 ## dish 32.038436 ## ditch 27.828825 ## dive 28.325545 ## do 29.869917 ## dock 33.121274 ## dodge 28.277289 ## doe 24.689888 ## dog 29.738665 ## dole 26.292559 ## doll 27.846970 ## dome 27.525693 ## doom 27.796928 ## door 30.341512 ## dope 28.092039 ## dose 27.865588 ## doubt 29.356231 ## dough 29.091284 ## douse 13.258127 ## draft 28.410201 ## drag 30.511412 ## drain 28.610921 ## drake 19.627177 ## dram 9.183556 ## drape 25.996084 ## draught 26.919338 ## draw 28.603494 ## drawl 27.785540 ## dread 26.959932 ## dream 30.709523 ## dress 29.048595 ## drift 27.581087 ## drill 29.991474 ## drink 30.456706 ## drip 30.438129 ## drive 30.279575 ## drone 27.291874 ## droop 18.681625 ## drop 29.332871 ## dross 27.007924 ## drought 25.620142 ## drove 26.943616 ## drown 27.702170 ## drum 29.765690 ## duck 33.229673 ## duct 19.247477 ## dud 19.744037 ## duel 28.889771 ## dug 28.512627 ## duke 27.688212 ## dump 29.299376 ## dun 27.582098 ## dune 27.125197 ## dung 14.957654 ## dunk 23.150560 ## dusk 29.108545 ## dust 30.569815 ## dwarf 27.658749 ## dwell 26.376092 ## ear 30.157236 ## earl 24.046998 ## earn 28.705380 ## earth 29.993442 ## ease 27.691224 ## east 26.160854 ## eat 29.083232 ## ebb 21.259723 ## edge 29.789682 ## eel 24.630406 ## egg 30.589898 ## elk 27.761631 ## elm 27.942026 ## end 27.785232 ## err 17.834010 ## eve 27.789379 ## ewe 17.393020 ## face 30.329631 ## fact 30.565721 ## fad 25.851070 ## fade 28.888020 ## fail 27.626601 ## fair 29.442662 ## faith 30.769185 ## fake 28.026937 ## fame 27.588719 ## fan 27.762793 ## fang 23.492741 ## farce 19.602771 ## fare 27.002911 ## farm 30.708478 ## fast 29.938545 ## fate 30.605288 ## fault 29.982829 ## fawn 25.953549 ## faze 24.650350 ## fear 30.549960 ## feast 30.454931 ## feat 26.268797 ## fee 27.016294 ## feed 28.744805 ## feel 30.758955 ## feint 22.298763 ## fell 33.361216 ## fen 24.522093 ## fence 29.595403 ## fern 20.347944 ## fetch 30.036750 ## feud 27.110709 ## fiend 15.138995 ## fife 14.373497 ## fig 27.239278 ## fight 27.899231 ## file 29.350448 ## fill 26.869855 ## film 29.419531 ## filth 25.171508 ## fin 27.090285 ## find 28.974260 ## fine 27.821815 ## fink 19.503738 ## fir 24.543837 ## fire 30.620511 ## firm 30.301275 ## fish 30.378459 ## fist 24.444993 ## fix 30.516573 ## flag 30.402592 ## flail 12.661782 ## flair 25.525803 ## flake 27.206650 ## flame 29.822500 ## flange 11.684016 ## flank 25.292846 ## flare 29.672907 ## flask 28.475855 ## flaw 28.390870 ## flax 22.959594 ## flea 28.592604 ## fleck 17.424087 ## flee 27.523036 ## fleet 27.174457 ## flesh 29.120215 ## flex 28.533265 ## flick 27.261706 ## flight 27.739207 ## fling 28.097823 ## flint 27.432502 ## flip 27.867619 ## flirt 29.940441 ## float 28.288830 ## flock 28.718481 ## floe 18.982325 ## flog 26.342517 ## flood 30.796836 ## floor 29.855098 ## flop 25.482714 ## flour 30.132828 ## flow 27.652430 ## fluff 27.909066 ## fluke 28.076970 ## flush 29.072818 ## flute 27.862098 ## flux 25.564193 ## fly 33.431785 ## foal 22.414182 ## foam 28.563648 ## foe 28.549067 ## fog 28.467568 ## foil 28.539871 ## fold 30.508931 ## folk 29.321987 ## font 19.533727 ## food 29.471881 ## fool 30.760331 ## foot 30.362230 ## force 27.811609 ## ford 23.630155 ## forge 24.274615 ## fork 30.065440 ## form 27.941611 ## fort 22.658280 ## found 30.447016 ## fowl 30.582699 ## fox 30.770529 ## frame 26.970907 ## fraud 25.634113 ## fray 22.911813 ## freak 29.166517 ## freeze 28.222728 ## freight 26.854428 ## fret 18.017420 ## friend 29.511033 ## frieze 23.094412 ## fright 27.677937 ## frill 25.610838 ## fringe 26.968099 ## frock 21.246175 ## frog 29.625845 ## front 30.364201 ## frost 28.002912 ## froth 16.378138 ## frown 27.609910 ## fruit 30.256107 ## fry 31.763270 ## fuel 30.381272 ## full 29.731302 ## fun 29.440515 ## fund 27.888037 ## funk 26.831628 ## fur 29.706351 ## fuse 27.076170 ## fuss 27.955253 ## fuzz 22.841723 ## gab 21.653150 ## gag 23.490492 ## gain 27.838919 ## gait 19.537570 ## gal 18.773275 ## gale 23.970118 ## gall 23.998247 ## game 30.373913 ## gang 28.340298 ## gap 29.085970 ## garb 17.288144 ## gas 27.640338 ## gash 15.932051 ## gasp 27.652118 ## gate 27.139676 ## gauge 21.562476 ## gauze 20.590525 ## gay 27.823387 ## gaze 27.055723 ## gear 29.962302 ## gel 26.920800 ## gem 28.254975 ## gene 24.800214 ## get 29.423011 ## ghost 29.522473 ## ghoul 17.631276 ## gibe 23.315890 ## gift 30.734694 ## gig 18.410097 ## gill 11.706717 ## gilt 21.044341 ## gin 27.731259 ## gird 27.528884 ## girl 28.378297 ## gist 19.645679 ## give 30.705862 ## glance 28.634453 ## gland 27.771856 ## glare 30.626510 ## glass 30.560389 ## glaze 28.547831 ## gleam 22.839678 ## glean 11.740681 ## glee 24.555531 ## glen 21.032429 ## glide 27.442009 ## glimpse 27.787690 ## glint 24.325215 ## gloat 22.553953 ## globe 26.782439 ## gloom 29.436005 ## gloss 30.182783 ## glove 27.718865 ## glow 27.681587 ## glue 29.190225 ## gnaw 22.596090 ## gnome 16.039989 ## go 28.732382 ## goad 26.829041 ## goal 30.165490 ## goat 28.688434 ## gob 14.032808 ## god 27.607361 ## gold 27.767161 ## golf 27.481473 ## gong 20.831204 ## goon 12.428551 ## goose 27.714695 ## gore 17.260054 ## gouge 17.149647 ## gourd 16.998064 ## gout 21.626385 ## gown 26.932125 ## grab 27.850188 ## grace 29.501045 ## grade 28.565738 ## graft 23.626549 ## grail 17.387428 ## grain 28.174164 ## gram 22.294144 ## grant 29.312264 ## grape 29.028137 ## graph 28.444392 ## grasp 28.355849 ## grass 27.930055 ## grate 25.426262 ## grave 29.256130 ## graze 27.069792 ## grease 27.885580 ## greed 28.470040 ## greet 20.085251 ## grid 27.409996 ## grill 27.706562 ## grille 14.870569 ## grime 24.961390 ## grin 26.661654 ## grind 28.470963 ## grip 27.579007 ## gripe 22.848396 ## grist 15.882543 ## grit 20.291848 ## groan 28.127519 ## groin 24.292233 ## groom 29.638709 ## groove 28.136798 ## grope 22.564183 ## grouch 24.781831 ## ground 30.324606 ## group 29.155172 ## grouse 24.125173 ## grove 24.778967 ## grow 30.806199 ## growl 27.916599 ## grub 18.530423 ## grudge 26.912611 ## grunt 27.177396 ## guard 30.648983 ## guess 28.665596 ## guest 28.958370 ## guide 30.778621 ## guild 21.968995 ## guile 19.223254 ## guilt 27.946749 ## guise 21.918909 ## gulf 25.609210 ## gull 18.245496 ## gulp 28.379225 ## gum 27.830213 ## gun 29.434683 ## gush 24.831044 ## gust 23.161869 ## gut 26.840782 ## guy 28.200061 ## gyp 22.336485 ## hack 27.301341 ## hag 27.502437 ## hail 30.494252 ## hair 27.911272 ## hall 28.722948 ## halt 30.630255 ## ham 30.781994 ## hand 30.554052 ## hang 29.819212 ## hank 26.728395 ## hark 26.978250 ## harm 28.021785 ## harp 29.650534 ## hart 25.758188 ## hash 26.950590 ## haste 30.323913 ## hat 28.779125 ## hatch 29.615262 ## hate 30.711773 ## haul 30.782041 ## haunt 24.125326 ## have 30.040720 ## haw 26.638999 ## hawk 28.454786 ## hay 30.767073 ## haze 28.712061 ## head 30.787877 ## heal 28.752255 ## heap 28.541596 ## hear 29.801069 ## heart 30.527479 ## hearth 27.654783 ## heat 29.949794 ## heave 25.338264 ## heck 26.314736 ## hedge 26.552853 ## heed 25.973823 ## heel 28.443623 ## height 28.788920 ## heir 28.663651 ## hell 28.893229 ## helm 18.820999 ## help 30.798974 ## hem 24.799167 ## hen 27.769693 ## herb 27.255449 ## herd 28.368372 ## hick 27.155071 ## hide 33.505817 ## hike 29.673329 ## hill 30.568216 ## hilt 27.070227 ## hind 27.043004 ## hinge 27.594689 ## hint 29.773944 ## hip 30.461205 ## hire 29.293206 ## hiss 24.751937 ## hit 28.704630 ## hitch 22.640266 ## hive 26.284008 ## hob 27.768903 ## hoe 28.891516 ## hog 33.051950 ## hoist 27.896230 ## hold 30.107296 ## hole 30.237743 ## home 28.350425 ## hone 15.115893 ## hooch 27.243673 ## hood 29.804046 ## hoof 28.237880 ## hook 28.640542 ## hoop 27.971661 ## hoot 28.320138 ## hop 28.630631 ## hope 30.118342 ## horn 30.671739 ## horse 27.172863 ## hose 28.532592 ## host 29.928436 ## hound 28.025492 ## hour 28.342741 ## house 28.484696 ## howl 29.882205 ## hub 24.414815 ## hue 27.977910 ## huff 27.300025 ## hug 30.027523 ## hulk 29.670829 ## hull 27.386691 ## hum 27.618801 ## hump 23.766176 ## hunch 26.210289 ## hunk 27.926447 ## hunt 29.620609 ## hurl 29.535137 ## hurt 29.520053 ## hush 27.819896 ## hut 30.630943 ## hymn 27.493366 ## ice 30.731029 ## inch 29.946232 ## ink 30.800468 ## inn 27.861033 ## ire 26.723447 ## isle 25.468008 ## itch 23.350409 ## jab 25.029228 ## jack 29.847362 ## jade 27.213245 ## jag 25.884072 ## jail 30.617546 ## jam 30.550399 ## jape 27.557878 ## jar 29.196632 ## jaw 29.312356 ## jazz 28.931246 ## jeep 30.220748 ## jeer 27.899066 ## jerk 29.254698 ## jest 27.494069 ## jet 29.776062 ## jig 27.834120 ## job 27.650134 ## jog 30.756789 ## join 27.958857 ## joke 30.762214 ## jolt 27.829831 ## jot 26.798788 ## joust 25.935201 ## jowl 22.391080 ## joy 28.625190 ## judge 29.528565 ## jug 29.747152 ## juice 30.748211 ## jump 28.660582 ## junk 30.307307 ## jute 17.114919 ## kale 15.157969 ## keel 27.151558 ## keen 27.082869 ## keep 29.018440 ## keg 29.110452 ## kelp 14.669327 ## ken 26.453921 ## key 27.795273 ## kick 28.265981 ## kid 31.147474 ## kill 30.764093 ## kilt 20.279947 ## kin 27.385694 ## kind 28.863627 ## king 29.968847 ## kiss 30.632769 ## kit 28.146698 ## kite 30.164781 ## knack 18.766873 ## knead 28.081432 ## knee 30.586924 ## kneel 27.277025 ## knife 30.516915 ## knight 28.546747 ## knit 29.524578 ## knob 30.306970 ## knock 29.784156 ## knoll 23.180536 ## knot 30.621098 ## know 30.301776 ## lace 30.706212 ## lack 28.754057 ## lad 29.206092 ## lag 27.635288 ## lake 30.762762 ## lamb 28.110608 ## lame 30.739857 ## lamp 30.165033 ## lance 22.244484 ## land 29.917518 ## lane 30.222892 ## lap 33.183172 ## lapse 28.611926 ## lard 27.208034 ## lark 28.220667 ## lash 28.122154 ## lass 16.128095 ## last 26.955220 ## latch 28.580252 ## lath 10.679549 ## lathe 27.323295 ## laugh 28.710287 ## launch 28.194824 ## law 29.903578 ## lawn 27.583820 ## lay 29.335888 ## laze 27.591771 ## leaf 29.700986 ## leak 30.763422 ## lean 29.442059 ## leap 27.707406 ## learn 24.175543 ## lease 30.726270 ## leash 30.587985 ## leave 30.150376 ## ledge 27.798435 ## lee 21.665438 ## leg 27.537070 ## lend 30.524343 ## lens 28.106587 ## let 27.648946 ## lick 28.997999 ## lid 29.488827 ## lie 30.115030 ## life 30.597162 ## lift 29.401616 ## light 30.678981 ## like 30.599316 ## lilt 27.707161 ## limb 30.157025 ## lime 28.303550 ## limp 29.129768 ## line 26.235045 ## link 28.619235 ## lint 26.901138 ## lip 30.725593 ## lisle 10.890954 ## list 29.620130 ## load 30.067233 ## loaf 29.936722 ## loan 29.683805 ## lob 24.919296 ## lobe 24.836406 ## lock 30.434697 ## lodge 29.886322 ## loft 27.380318 ## log 28.348405 ## loin 27.609492 ## look 30.779331 ## loom 23.052392 ## loon 23.236952 ## loop 30.403740 ## loot 28.192278 ## lop 27.347330 ## lope 27.519512 ## lord 30.819611 ## lore 26.471315 ## lose 28.606827 ## loss 29.769572 ## lot 30.455434 ## lounge 27.894191 ## louse 21.047844 ## love 30.692329 ## low 30.426589 ## luck 29.215872 ## lug 28.405999 ## lull 23.452842 ## lump 30.084802 ## lung 27.690819 ## lurch 18.696648 ## lure 27.749300 ## lurk 27.433680 ## lust 27.987128 ## lute 27.613339 ## lye 17.207385 ## lymph 21.913877 ## lynch 26.223350 ## maid 30.346067 ## mail 28.289707 ## make 30.766139 ## mall 27.692920 ## malt 29.138609 ## man 30.764266 ## mane 27.252030 ## manse 27.538113 ## map 30.778773 ## mar 23.320810 ## march 32.028016 ## mare 23.358206 ## mark 28.141993 ## marsh 23.160012 ## mart 23.841553 ## mash 27.988542 ## mask 30.645843 ## mass 28.042997 ## mast 28.205541 ## mat 28.000868 ## match 29.588473 ## mate 28.983335 ## maw 27.607238 ## may 28.386893 ## maze 28.873847 ## mead 25.243513 ## meal 30.675024 ## mean 27.916821 ## meat 28.447604 ## meet 30.007291 ## meld 27.841772 ## melt 30.215635 ## mend 28.390761 ## merge 28.335352 ## mesh 28.392797 ## mess 26.976775 ## mew 14.083737 ## might 27.927201 ## mile 29.171802 ## milk 28.891548 ## mill 26.883501 ## mime 17.803878 ## mince 18.864138 ## mind 30.601619 ## mine 27.740201 ## mink 21.873905 ## mint 28.931426 ## mirth 24.479818 ## miss 29.027242 ## mist 29.617764 ## mite 21.366171 ## mitt 24.748861 ## mix 30.009653 ## moan 27.660101 ## mob 30.483323 ## mock 27.976420 ## mode 26.923837 ## mole 29.351528 ## moll 20.429609 ## mom 29.691467 ## monk 29.974373 ## month 30.413688 ## moo 25.886652 ## mood 28.728312 ## moon 27.717851 ## moose 28.446884 ## moot 23.544318 ## mop 29.708734 ## moss 28.617242 ## moth 21.991771 ## mould 23.578473 ## mount 29.764311 ## mourn 29.548944 ## mouse 28.513133 ## mouth 30.105611 ## move 29.927825 ## mow 26.001323 ## muck 19.329661 ## mud 30.591136 ## muff 24.039079 ## mug 30.231668 ## mulch 24.154102 ## mule 27.959352 ## mum 22.136329 ## munch 24.639375 ## muse 22.359967 ## mush 24.447341 ## must 29.391770 ## myth 27.639201 ## nab 19.704120 ## nail 27.714006 ## name 27.710032 ## nap 28.000798 ## nape 23.251151 ## naught 17.724810 ## neck 29.706826 ## need 30.462957 ## nerve 27.654895 ## nest 28.815941 ## news 29.878218 ## newt 23.559018 ## nick 16.685200 ## niece 27.876016 ## night 28.013509 ## nil 13.596682 ## nip 23.222459 ## nod 27.257482 ## node 25.725616 ## noise 29.788398 ## nonce 27.239432 ## nook 19.401060 ## noon 27.592283 ## noose 26.781645 ## norm 27.653768 ## north 28.567199 ## nose 28.051181 ## notch 26.891124 ## note 27.718496 ## noun 24.143265 ## nudge 24.655938 ## nun 27.655273 ## nurse 27.996215 ## nut 30.362523 ## nymph 26.953702 ## oak 30.695039 ## oath 27.769246 ## oil 30.763237 ## ooze 25.866888 ## orb 16.144901 ## ore 24.897157 ## ought 27.551352 ## ounce 27.650619 ## oust 18.289135 ## owl 30.750781 ## pace 28.539389 ## pack 30.646663 ## pact 29.807502 ## pad 30.152825 ## page 30.488592 ## pail 27.832325 ## pain 28.675425 ## paint 30.763529 ## pair 30.782816 ## pal 30.434316 ## pale 30.683588 ## pall 27.604377 ## palm 30.317847 ## pan 29.631958 ## pane 26.551932 ## pang 17.288332 ## pant 29.720136 ## pap 23.674151 ## par 22.971271 ## pare 21.526191 ## park 29.911882 ## part 30.293852 ## pass 28.327780 ## paste 29.704369 ## pat 30.799201 ## patch 29.940846 ## pate 27.622658 ## path 30.506103 ## paunch 19.583894 ## pause 29.878634 ## pave 27.055506 ## paw 28.388407 ## pawn 27.741102 ## pay 30.671430 ## pea 30.752181 ## peace 29.610377 ## peach 28.096465 ## peak 29.482036 ## peal 27.653556 ## pear 29.671230 ## pearl 30.750042 ## peat 22.761256 ## peck 29.398949 ## pee 27.295093 ## peel 29.556563 ## peep 27.967662 ## peer 29.805705 ## peg 29.140896 ## pelt 20.237975 ## pen 29.852784 ## perch 24.909485 ## perk 27.627271 ## pest 27.479248 ## pet 30.426684 ## pew 22.045119 ## phase 27.711056 ## phrase 27.787653 ## pick 30.157231 ## pie 30.377226 ## piece 28.770123 ## pier 27.814403 ## pierce 27.698789 ## pig 30.753283 ## pike 29.425042 ## pile 30.810383 ## pill 27.985612 ## pimp 27.907083 ## pin 27.752063 ## pinch 27.773916 ## pine 30.143937 ## pint 27.506392 ## pip 21.526947 ## pipe 30.763925 ## piss 27.598993 ## pit 28.976394 ## pitch 29.465769 ## pith 23.850784 ## place 30.666480 ## plaid 29.875519 ## plain 27.586331 ## plan 30.602312 ## plane 27.602735 ## plank 25.335586 ## plant 28.605233 ## plate 29.664735 ## play 30.524699 ## plea 28.757902 ## plead 30.259300 ## please 30.734697 ## pleat 21.328233 ## pledge 28.099641 ## plod 19.531937 ## plot 30.593311 ## plough 25.679316 ## pluck 28.627443 ## plug 28.284626 ## plum 30.819260 ## plume 22.537276 ## plunge 28.537063 ## plush 29.193996 ## poach 19.846049 ## pod 26.827778 ## point 30.507484 ## poise 27.871666 ## poke 28.589210 ## pole 29.001076 ## poll 28.557882 ## pomp 26.711503 ## pond 28.998869 ## pool 30.760601 ## pop 29.959101 ## pope 30.452792 ## porch 28.385620 ## pore 24.638461 ## pork 30.469284 ## port 26.388822 ## pose 28.977740 ## post 28.938241 ## pot 30.581479 ## pouch 27.735522 ## pound 33.395186 ## pour 28.672496 ## pout 22.125989 ## praise 29.083151 ## prank 28.536678 ## pray 29.342469 ## preach 23.397552 ## prep 26.273400 ## press 29.444659 ## prey 28.959635 ## price 30.802732 ## prick 27.637255 ## pride 30.768553 ## priest 26.481982 ## prime 29.324066 ## prince 27.648198 ## print 30.642840 ## prize 29.827205 ## probe 28.433312 ## prod 19.110780 ## prop 24.848337 ## prose 25.614721 ## prove 27.067466 ## prow 22.363380 ## prowl 28.186083 ## pry 25.815743 ## psalm 22.703004 ## pub 29.642290 ## puck 27.251317 ## puff 28.464548 ## puke 24.460181 ## pull 29.259286 ## pulp 28.264001 ## pulse 30.290789 ## pump 28.572732 ## pun 23.291632 ## punch 29.599317 ## punk 29.103420 ## punt 27.439697 ## pup 29.397132 ## purge 27.855784 ## purse 28.298991 ## pus 25.867145 ## push 27.641363 ## put 28.609231 ## putt 27.110570 ## pyre 20.172524 ## quack 27.963914 ## quake 26.057372 ## quart 27.423610 ## quartz 27.888635 ## quay 27.639143 ## queen 28.467058 ## quell 13.649753 ## quench 25.229459 ## quest 27.633144 ## queue 18.830294 ## quill 26.831989 ## quince 15.542794 ## quirk 27.202610 ## quiz 28.051696 ## quote 29.296224 ## race 30.348732 ## rack 28.054096 ## raft 27.310608 ## rag 27.948827 ## rage 30.624519 ## raid 30.199884 ## rail 28.028485 ## rain 29.734264 ## raise 28.713474 ## rake 29.785343 ## ram 23.693490 ## ranch 30.542456 ## range 29.587409 ## rank 27.824877 ## rant 23.020546 ## rap 28.280432 ## rape 28.713580 ## rash 30.348625 ## rasp 23.428894 ## rat 30.336764 ## rate 29.088711 ## rave 28.535131 ## ray 27.680795 ## reach 30.776089 ## realm 27.934424 ## ream 16.644293 ## reap 25.539068 ## rear 29.657994 ## reed 23.808418 ## reef 21.935439 ## reek 25.406985 ## reel 22.324454 ## reign 27.518247 ## rein 22.002497 ## rend 27.533890 ## rent 29.118828 ## rest 30.662561 ## retch 11.396461 ## rhyme 27.481981 ## rib 30.048085 ## rice 30.760883 ## ride 28.422077 ## ridge 27.358145 ## rift 23.956487 ## rig 26.079916 ## right 30.288713 ## rile 19.217696 ## rim 28.057756 ## rime 14.714244 ## rind 23.988432 ## ring 31.436498 ## rink 23.412823 ## rinse 29.864688 ## rip 27.925646 ## rise 30.792136 ## risk 29.314967 ## rite 24.740909 ## roach 28.382154 ## road 30.703069 ## roam 28.821044 ## roar 29.430759 ## roast 27.905684 ## rob 28.751211 ## robe 27.934304 ## rock 32.876298 ## rod 28.779232 ## roe 23.281090 ## role 29.210730 ## roll 27.827992 ## romp 25.602303 ## roof 30.741309 ## rook 21.161667 ## room 30.816053 ## roost 28.915260 ## root 29.996141 ## rope 29.594645 ## rose 30.524390 ## rot 27.897657 ## rouse 16.649619 ## rout 21.769486 ## rove 15.512725 ## rub 30.788958 ## rue 24.174323 ## rug 29.457584 ## rule 30.007344 ## rum 28.527545 ## rump 27.073687 ## run 27.910037 ## rung 23.771942 ## runt 17.972857 ## ruse 19.159126 ## rush 30.018084 ## rust 28.543281 ## rut 24.719857 ## rye 27.240102 ## sack 27.753324 ## sag 27.704774 ## sail 30.208389 ## saint 29.585767 ## sake 26.810909 ## sale 28.153840 ## salt 30.786153 ## salve 25.970566 ## sand 29.717490 ## sap 24.700687 ## sash 25.391162 ## sauce 29.749960 ## save 29.652570 ## saw 27.636290 ## sax 21.785127 ## say 28.190027 ## scald 20.208252 ## scale 29.036205 ## scalp 30.514966 ## scan 27.425974 ## scar 27.923957 ## scare 27.676816 ## scarf 28.111654 ## scene 28.543321 ## scent 30.481542 ## scheme 28.119094 ## school 28.681020 ## scoop 28.313213 ## scope 27.923657 ## score 29.668463 ## scorn 27.727311 ## scotch 26.913655 ## scour 25.195207 ## scourge 27.251368 ## scout 27.249257 ## scrap 27.550278 ## scrape 27.664449 ## scratch 27.981584 ## scream 27.698546 ## screech 23.922024 ## screen 28.008452 ## screw 30.406728 ## scribe 27.421913 ## script 30.773545 ## scrub 27.596252 ## scuff 19.017048 ## sea 29.890391 ## seal 27.977477 ## seam 20.538246 ## sear 21.154893 ## search 27.758374 ## seat 29.138340 ## sect 15.120951 ## see 29.367113 ## seed 28.886332 ## seek 30.773474 ## seem 27.810625 ## seep 21.531404 ## seize 29.954412 ## self 30.775465 ## sell 27.740476 ## send 28.646927 ## sense 28.982817 ## serf 23.204376 ## serge 22.466153 ## serve 27.941297 ## set 33.227006 ## sew 28.605693 ## sex 29.822321 ## shack 28.514611 ## shade 29.365277 ## shaft 27.796449 ## shag 24.582798 ## shah 22.448674 ## shake 29.683430 ## shall 27.174003 ## sham 24.323217 ## shame 28.433837 ## shank 20.988257 ## shape 30.198242 ## shard 19.782625 ## share 30.678458 ## shark 30.461504 ## shave 28.590963 ## shawl 24.556878 ## shay 25.809841 ## sheaf 20.513606 ## shear 26.753653 ## sheath 23.368746 ## shed 28.173310 ## sheen 21.152750 ## sheep 28.694607 ## sheer 26.575477 ## sheet 30.704671 ## shelf 29.732514 ## shell 30.572794 ## shield 30.571683 ## shift 28.657388 ## shin 22.443442 ## shine 27.666438 ## ship 29.915060 ## shirt 28.292016 ## shoal 20.146346 ## shock 28.215074 ## shoe 27.971082 ## shoot 29.202333 ## shop 29.602298 ## shore 27.873866 ## shot 27.978360 ## should 30.348089 ## shout 29.481071 ## shove 27.889890 ## show 28.927793 ## shred 27.635038 ## shrimp 28.837116 ## shrine 21.376081 ## shrink 28.250946 ## shrub 27.702663 ## shrug 25.321972 ## shuck 9.919578 ## shun 22.707524 ## shunt 13.412198 ## shut 27.718034 ## side 28.308460 ## siege 26.987824 ## sigh 25.753196 ## sight 28.344598 ## sign 27.853174 ## silk 27.876480 ## sill 14.679816 ## sin 27.883487 ## sine 18.031589 ## sing 30.430466 ## sink 29.426183 ## sip 30.111676 ## sir 27.227869 ## sit 30.332372 ## site 27.880521 ## size 30.316135 ## skate 29.795315 ## skeet 16.592837 ## sketch 27.976147 ## ski 28.059487 ## skid 25.581922 ## skiff 27.633591 ## skill 29.207410 ## skin 27.676437 ## skip 28.399955 ## skirt 28.011964 ## skit 29.400379 ## skulk 27.431912 ## skull 30.141445 ## skunk 27.165049 ## sky 30.743355 ## slab 24.839174 ## slam 28.070939 ## slang 28.234443 ## slant 27.524399 ## slap 28.635657 ## slash 27.561330 ## slat 23.160326 ## slate 26.296420 ## slave 30.010427 ## sleep 28.395708 ## sleeve 30.129672 ## slice 30.438706 ## slide 28.811382 ## slip 30.783471 ## slit 26.977506 ## slob 27.783406 ## sloe 18.795415 ## sloop 25.663705 ## slop 21.038895 ## slope 27.544444 ## slot 28.400672 ## slouch 25.938633 ## slough 22.200129 ## sludge 18.570522 ## slug 27.642223 ## sluice 14.012267 ## slum 23.950602 ## slump 28.060163 ## smack 28.143355 ## smart 29.229164 ## smash 29.392944 ## smear 30.357042 ## smell 30.812498 ## smelt 18.193641 ## smile 30.411646 ## smirk 27.323052 ## smoke 30.627585 ## snack 27.670819 ## snag 28.751107 ## snail 27.675807 ## snake 28.937450 ## snap 29.397383 ## snare 28.005071 ## snatch 27.820784 ## sneak 28.442618 ## sneer 28.141682 ## sniff 27.662296 ## snip 26.912288 ## snob 27.859795 ## snoop 27.824958 ## snort 26.978440 ## snout 25.824937 ## snow 28.554359 ## snug 27.620609 ## soak 30.249611 ## soap 30.666661 ## sob 27.546484 ## sock 28.062140 ## sod 26.277786 ## sole 28.559181 ## solve 27.733364 ## son 27.732924 ## song 29.219689 ## soot 18.160839 ## soothe 26.013826 ## sop 12.607265 ## sort 28.551775 ## soul 30.323621 ## sound 30.374884 ## soup 29.186591 ## source 30.375163 ## south 24.481148 ## soy 26.788936 ## spa 26.729867 ## space 30.328669 ## spade 28.390582 ## span 27.639028 ## spare 27.237581 ## spark 30.207048 ## spat 27.041572 ## spate 16.837321 ## speak 28.151939 ## spear 29.046963 ## speck 21.201971 ## speech 28.991770 ## speed 29.445522 ## spell 33.172718 ## spend 30.755304 ## sphere 27.769284 ## sphinx 27.530823 ## spice 27.774138 ## spike 30.674156 ## spill 30.763831 ## spin 30.710400 ## spine 28.550323 ## spire 24.222916 ## spit 28.641238 ## spite 25.496610 ## splash 29.251238 ## spleen 18.102867 ## splice 21.628524 ## split 29.277476 ## splurge 22.876642 ## spoil 29.221807 ## spoke 30.521491 ## spoof 21.441697 ## spool 30.687725 ## spoon 28.004932 ## sport 29.046654 ## spot 28.742187 ## spouse 28.259880 ## spout 27.571422 ## sprawl 27.686513 ## spray 27.689982 ## spread 27.919698 ## spree 19.482251 ## sprig 17.463287 ## spring 29.208361 ## sprite 21.243509 ## sprout 28.447100 ## spur 27.702829 ## spurt 22.940851 ## spy 28.828890 ## squad 27.673712 ## squall 22.946767 ## square 28.099638 ## squash 27.812700 ## squat 25.754201 ## squaw 20.001741 ## squawk 22.630947 ## squeak 27.960726 ## squeal 27.694314 ## squeeze 28.317505 ## squint 27.998745 ## squire 24.379804 ## squirm 28.047403 ## squirt 27.718431 ## stab 27.946589 ## stack 28.310509 ## staff 30.130240 ## stag 29.437598 ## stage 28.941652 ## stain 27.681834 ## stair 28.418337 ## stake 26.945766 ## stalk 28.133745 ## stall 29.940390 ## stamp 28.473687 ## stance 27.136141 ## stanch 27.626478 ## stand 29.433721 ## star 29.109119 ## starch 28.818340 ## stare 28.372845 ## start 28.549095 ## starve 28.023264 ## state 28.702207 ## staunch 18.792772 ## stave 21.795689 ## stay 30.435901 ## stead 23.809334 ## steak 27.840238 ## steal 30.207827 ## steam 27.666419 ## steed 22.141144 ## steel 28.195631 ## steer 27.712904 ## stem 27.707491 ## stench 22.455685 ## step 30.739186 ## stew 30.807807 ## stick 29.392069 ## still 30.196167 ## stilt 20.345996 ## sting 27.758628 ## stink 28.007216 ## stint 27.396986 ## stir 30.722033 ## stitch 24.358310 ## stock 30.764153 ## stole 30.212762 ## stone 27.956728 ## stool 30.736556 ## stoop 22.440463 ## stop 29.273806 ## store 29.178392 ## stork 28.142855 ## storm 29.170296 ## stout 27.402736 ## stove 28.768513 ## stow 22.777722 ## strafe 22.550447 ## strain 29.022450 ## strand 27.181899 ## strap 27.780011 ## straw 30.402406 ## stray 29.913361 ## streak 28.349987 ## stream 27.650636 ## street 28.260739 ## stress 30.590306 ## stretch 28.238272 ## stride 29.062386 ## strife 25.706999 ## strike 30.570854 ## string 28.380797 ## strip 30.181726 ## stripe 28.838876 ## strive 27.642035 ## stroke 28.311265 ## stroll 27.745221 ## strut 22.995769 ## stub 27.069914 ## stud 28.874690 ## stuff 29.260305 ## stump 28.567859 ## stunt 27.574268 ## style 30.837174 ## sub 15.341098 ## suck 27.707701 ## sue 26.683142 ## suit 28.894649 ## suite 28.321875 ## sulk 23.044494 ## sum 28.053661 ## sun 28.228913 ## sup 27.601799 ## surf 27.949582 ## surge 26.472446 ## swamp 27.707980 ## swan 27.675086 ## swap 25.015762 ## swarm 27.915984 ## swath 20.190806 ## sway 27.889671 ## swear 29.469883 ## sweat 29.373053 ## sweep 27.938621 ## swell 30.663163 ## swerve 27.619308 ## swig 22.890196 ## swim 29.195984 ## swine 28.084320 ## swing 30.759212 ## swipe 27.817287 ## swirl 27.638619 ## switch 28.376231 ## swoop 23.950609 ## sword 30.341989 ## tab 28.366929 ## tack 26.970734 ## tact 29.510440 ## tag 28.269304 ## tail 28.271705 ## taint 27.820403 ## take 30.284510 ## tale 29.155855 ## talk 28.198582 ## tamp 25.557619 ## tan 28.214984 ## tang 22.815083 ## tank 27.638621 ## tape 29.873764 ## tar 29.456390 ## tart 27.692755 ## task 30.601487 ## taste 30.280520 ## taunt 27.673769 ## tax 30.243494 ## tea 30.606641 ## teach 29.248358 ## teak 27.541255 ## team 30.464693 ## tease 29.500546 ## tech 13.239602 ## tee 28.217614 ## teens 27.636498 ## tell 29.812357 ## tempt 29.898267 ## tend 27.643137 ## tense 29.229456 ## tent 30.577586 ## test 29.636029 ## text 30.368817 ## thank 30.107533 ## thaw 27.903325 ## theft 28.199893 ## theme 28.284179 ## thief 28.126199 ## thigh 30.347141 ## thin 29.012701 ## thing 28.673293 ## think 30.817641 ## thirst 30.711010 ## thong 23.873073 ## thorn 30.830647 ## thought 29.028306 ## thrash 27.270879 ## thread 29.640655 ## threat 27.919126 ## thrift 28.330684 ## thrill 28.276700 ## thrive 28.082461 ## throat 30.775417 ## throne 25.167707 ## throng 18.784358 ## throw 28.148953 ## thrush 21.497175 ## thrust 27.339378 ## thud 25.343479 ## thug 27.566809 ## thumb 30.773304 ## thump 27.584584 ## thwack 10.458867 ## thwart 17.862892 ## tick 28.555221 ## tide 30.108280 ## tie 30.772560 ## tile 29.635348 ## till 24.683675 ## tilt 30.258299 ## time 30.406152 ## tin 27.685336 ## tint 28.434222 ## tip 30.185629 ## tire 30.792419 ## toad 30.155539 ## toast 29.816804 ## toe 27.822706 ## toil 27.891677 ## toll 27.219618 ## tomb 30.770498 ## tome 27.335644 ## ton 27.628018 ## tone 29.453354 ## tongue 30.218350 ## tool 30.692153 ## toot 20.531005 ## tooth 29.206980 ## top 29.393226 ## torch 27.949537 ## torque 25.554940 ## toss 30.002207 ## tote 20.521420 ## touch 30.700810 ## tour 29.887398 ## tout 22.924382 ## town 30.312984 ## toy 30.748915 ## trace 29.829493 ## track 29.747404 ## tract 27.894946 ## trade 30.512226 ## trail 27.711579 ## train 30.435101 ## trait 27.291972 ## tramp 27.184066 ## trance 26.107225 ## trap 29.223517 ## trash 28.236590 ## tray 25.361742 ## tread 25.967649 ## treat 29.511976 ## tree 30.762976 ## trench 27.777331 ## trend 28.130169 ## tribe 27.276295 ## trick 28.105533 ## trill 14.224085 ## trip 29.368229 ## tripe 26.259331 ## troll 20.863388 ## troop 25.373517 ## trot 20.603108 ## trough 14.149857 ## trout 29.716752 ## truce 25.177670 ## truck 28.322350 ## trump 22.668676 ## trunk 30.367173 ## trust 29.101619 ## try 29.997342 ## tryst 17.121382 ## tub 29.731133 ## tube 33.266351 ## tuck 27.313703 ## tug 30.439324 ## tune 29.304849 ## turf 26.229084 ## turn 27.972378 ## tusk 24.486807 ## twain 24.797575 ## tweed 28.289410 ## twin 30.288617 ## twinge 19.568850 ## twist 29.527306 ## twitch 24.830642 ## type 28.007829 ## urge 27.977362 ## urn 20.451987 ## use 30.770943 ## vale 13.887542 ## valve 27.549255 ## vamp 19.512335 ## van 27.665648 ## vase 27.942470 ## vault 28.802514 ## veal 27.271615 ## veer 17.452473 ## veil 27.716576 ## vein 28.094315 ## vent 27.254076 ## verb 28.265422 ## verge 24.411042 ## verse 28.031703 ## verve 20.470940 ## vest 25.676742 ## vet 23.045416 ## vex 26.926715 ## vice 26.501539 ## vie 17.538961 ## view 28.538553 ## vine 27.810184 ## voice 30.478957 ## volt 26.180077 ## vote 27.889958 ## vow 27.089807 ## wad 27.380875 ## wade 27.773562 ## wag 27.830787 ## wage 27.962118 ## wail 27.349547 ## waist 27.860323 ## wait 29.496960 ## waive 27.659946 ## wake 27.931578 ## walk 30.712974 ## wall 28.966136 ## waltz 30.162669 ## wand 25.307027 ## wane 22.699353 ## want 28.952446 ## war 30.526099 ## ward 21.885322 ## ware 25.965068 ## warn 28.450535 ## warp 27.623396 ## wart 27.171709 ## wash 28.460493 ## wasp 28.175661 ## waste 30.665011 ## watch 29.503588 ## watt 27.085970 ## wave 27.989858 ## wax 28.089523 ## way 30.374766 ## wealth 27.877318 ## wear 28.320753 ## weave 29.205567 ## web 30.706879 ## wed 30.257069 ## wedge 27.774720 ## weed 28.980518 ## week 28.276355 ## weep 27.817347 ## weigh 28.644937 ## weight 28.889299 ## weld 21.611974 ## well 30.690699 ## welt 18.403092 ## west 17.351376 ## whack 27.254619 ## wharf 28.398732 ## wheat 28.850855 ## wheel 27.635731 ## whelp 13.669017 ## whiff 23.952003 ## while 29.463900 ## whim 27.786089 ## whine 27.188404 ## whip 30.750829 ## whirl 27.816988 ## whit 20.464442 ## whiz 28.999936 ## whoop 21.052199 ## whoosh 25.897413 ## whore 27.957407 ## whorl 16.451351 ## wick 27.618507 ## wield 25.207159 ## wife 30.753659 ## wig 28.011536 ## will 30.691482 ## wilt 26.979724 ## win 27.963012 ## wine 30.643495 ## wing 30.823217 ## wink 29.375473 ## wipe 30.605434 ## wire 30.746209 ## wish 30.276663 ## wisp 20.396010 ## wit 27.926775 ## witch 28.154017 ## woe 28.245010 ## wolf 30.632733 ## womb 27.771460 ## woo 16.158006 ## wood 27.999059 ## wool 27.237777 ## word 29.472906 ## work 30.098526 ## world 30.403686 ## worm 28.117295 ## would 29.914349 ## wow 27.600665 ## wrack 27.620580 ## wrap 28.818163 ## wrath 27.265065 ## wreak 26.039170 ## wreath 26.833289 ## wreck 28.840220 ## wren 20.453625 ## wrest 27.289892 ## wretch 27.690119 ## wring 14.107434 ## wrist 30.037317 ## writ 13.203893 ## write 28.890214 ## writhe 25.194578 ## yacht 23.711911 ## yak 10.470235 ## yam 27.501519 ## yang 10.469182 ## yank 21.277431 ## yard 28.485562 ## yarn 28.394440 ## yaw 17.851181 ## yawl 17.398311 ## yawn 28.352738 ## yea 25.322896 ## year 28.778021 ## yearn 24.920646 ## yeast 28.698099 ## yell 28.151170 ## yelp 21.727654 ## yen 18.826642 ## yes 30.799022 ## yield 30.726232 ## yoke 28.555621 ## yolk 27.186463 ## yore 19.150790 ## youth 29.497059 ## zeal 26.391270 ## zest 26.177511 ## zinc 24.442679 ## zing 16.515801 ## zip 28.859080 ## zone 29.513093 ## zoo 27.573932 4.4.2.3.4 Logodds to Odd ratios Logodds can be modified to talk about the odds of an event. exp(fixef(mdl.glmmSlope2)[1]) ## (Intercept) ## 6.850044e-79 exp(fixef(mdl.glmmSlope2)[1] + fixef(mdl.glmmSlope2)[2]) ## (Intercept) ## 6.22596e-67 4.4.2.3.5 LogOdds to proportions If you want to talk about the percentage “accuracy” of our model, then we can transform our loggodds into proportions. This shows that the proportion of “grammatical” receiving a “yes” response increases by 99% (or 95% based on our “true” coefficients) plogis(fixef(mdl.glmmSlope2)[1]) ## (Intercept) ## 6.850044e-79 plogis(fixef(mdl.glmmSlope2)[1] + fixef(mdl.glmmSlope2)[2]) ## (Intercept) ## 6.22596e-67 4.4.2.3.6 Plotting english2 &lt;- english2 %&gt;% mutate(prob2 = predict(mdl.glmmSlope2, type = &quot;response&quot;)) english2 %&gt;% ggplot(aes(x = as.numeric(AgeSubject), y = prob2)) + geom_point() + geom_smooth(method = &quot;glm&quot;, method.args = list(family = &quot;binomial&quot;), se = T) + theme_bw(base_size = 20)+ labs(y = &quot;Probability&quot;, x = &quot;&quot;)+ coord_cartesian(ylim = c(0,1))+ scale_x_discrete(limits = c(&quot;Young&quot;, &quot;Old&quot;)) The plot above shows how the two groups differ using a glmm. The results point to an overall increase in the proportion of reaction time when moving from the “Young” to the “Old” group. Let’s use z-scoring next 4.4.2.4 With z-scoring of predictor 4.4.2.4.1 Model estimation english2 &lt;- english2 %&gt;% mutate(`RTlexdec_z` = scale(RTlexdec, center = TRUE, scale = TRUE)) english2[&#39;RTlexdec_z&#39;] &lt;- as.data.frame(scale(english2$RTlexdec)) 4.4.2.4.1.1 Random Intercepts mdl.glmm3 &lt;- english2 %&gt;% glmer(AgeSubject ~ RTlexdec_z + (1|Word), data = ., family = &quot;binomial&quot;) summary(mdl.glmm3) ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: binomial ( logit ) ## Formula: AgeSubject ~ RTlexdec_z + (1 | Word) ## Data: . ## ## AIC BIC logLik deviance df.resid ## 3151.8 3171.1 -1572.9 3145.8 4565 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -26.3468 -0.3058 -0.0166 0.3893 4.0750 ## ## Random effects: ## Groups Name Variance Std.Dev. ## Word (Intercept) 0 0 ## Number of obs: 4568, groups: Word, 2197 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 0.07690 0.04480 1.716 0.0861 . ## RTlexdec_z 3.08341 0.09107 33.856 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ## RTlexdec_z 0.025 ## optimizer (Nelder_Mead) convergence code: 0 (OK) ## boundary (singular) fit: see help(&#39;isSingular&#39;) 4.4.2.4.1.2 Random Slopes mdl.glmmSlope3 &lt;- english2 %&gt;% glmer(AgeSubject ~ RTlexdec_z + (RTlexdec_z|Word), data = ., family = &quot;binomial&quot;) summary(mdl.glmmSlope3) ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: binomial ( logit ) ## Formula: AgeSubject ~ RTlexdec_z + (RTlexdec_z | Word) ## Data: . ## ## AIC BIC logLik deviance df.resid ## 3075.6 3107.7 -1532.8 3065.6 4563 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.3927 -0.2133 -0.0024 0.2512 5.8055 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## Word (Intercept) 0.8508 0.9224 ## RTlexdec_z 1.9696 1.4034 1.00 ## Number of obs: 4568, groups: Word, 2197 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 0.38012 0.07664 4.96 7.05e-07 *** ## RTlexdec_z 4.32050 0.26713 16.17 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ## RTlexdec_z 0.646 ## optimizer (Nelder_Mead) convergence code: 0 (OK) ## Model failed to converge with max|grad| = 0.00335891 (tol = 0.002, component 1) 4.4.2.4.2 Model comparison anova(mdl.glmm3, mdl.glmmSlope3) ## Data: . ## Models: ## mdl.glmm3: AgeSubject ~ RTlexdec_z + (1 | Word) ## mdl.glmmSlope3: AgeSubject ~ RTlexdec_z + (RTlexdec_z | Word) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## mdl.glmm3 3 3151.8 3171.1 -1572.9 3145.8 ## mdl.glmmSlope3 5 3075.6 3107.7 -1532.8 3065.6 80.259 2 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The model comparisons show that the model with both random intercepts and random slopes is improving the model fit. The Is.Singular message tells us that there is a chance there is a complete separation in the model. 4.4.2.4.3 Gettings results 4.4.2.4.3.1 Model’s fit print(tab_model(mdl.glmmSlope3, file = paste0(&quot;outputs/mdl.glmmSlope3.html&quot;))) webshot(paste0(&quot;outputs/mdl.glmmSlope3.html&quot;), paste0(&quot;outputs/mdl.glmmSlope3.png&quot;)) Model fit: Generalised Linear Mixed effects model - Numeric - z scores 4.4.2.4.3.2 Fixed effects fixef(mdl.glmmSlope3) ## (Intercept) RTlexdec_z ## 0.3801193 4.3205029 fixef(mdl.glmmSlope3)[1] ## (Intercept) ## 0.3801193 fixef(mdl.glmmSlope3)[2] ## RTlexdec_z ## 4.320503 4.4.2.4.3.3 Random effects coef(mdl.glmmSlope3)$`Word`[1] ## (Intercept) ## ace 0.4429212637 ## act 0.6115900993 ## add 0.5148513960 ## age 0.4998303024 ## aid 0.3969975952 ## aide 0.0298149457 ## ail -0.5223248920 ## aim 0.5420519930 ## air 0.7025897634 ## aisle 0.2888583972 ## ale 0.3853232087 ## angst 0.1531547853 ## ant 0.5610006668 ## ape 0.4962788323 ## arc -0.4707015084 ## arch 0.4512528389 ## are 0.4198901328 ## arm 0.9816125475 ## art 0.5251614946 ## ash 0.4281455397 ## ask 0.6475872009 ## ass 0.4322048232 ## axe 0.4116260599 ## babe 0.5196373616 ## back 0.6270678266 ## badge 0.4286905200 ## bag 0.6929868460 ## bail 0.1909596118 ## bait 0.5556562438 ## bale -0.5505704375 ## ball 0.5016870267 ## ban -0.0941223592 ## band 0.4224229334 ## bang 0.6481332676 ## bank 0.5996475267 ## bar 0.7043147769 ## bard -0.6135752052 ## barge -0.2315978510 ## bark 0.6462121316 ## barn 0.7065307175 ## base 0.5814176531 ## bash 0.3932383080 ## bat 0.6945639688 ## batch 0.5395463959 ## bath 0.6015430074 ## bay 0.5318171846 ## beach 0.4634627256 ## bead 0.1953244038 ## beak -0.3684048394 ## beam 0.3898833217 ## bean 0.4136863882 ## bear 0.9094956778 ## beard 0.6457097003 ## beast 0.4088095955 ## beat 0.5358319249 ## beau -0.0287634590 ## beck -1.0401672566 ## bed 0.5170928203 ## bee 0.6800920701 ## beech -0.4747123984 ## beef 0.8824327201 ## beep 0.5439011712 ## beer 0.6804450006 ## beet 0.2779529997 ## beg 0.7154007065 ## belch -0.0177078249 ## bell 0.6218300941 ## belt 0.4966436753 ## bench 0.7026657475 ## bend 0.6809424799 ## berth 0.0267365037 ## bet 0.7167968807 ## bib 0.1835735923 ## bid 0.7175521351 ## bide -1.0696921302 ## bile 0.1685029621 ## bilge -0.9124773087 ## bill 0.5302685540 ## bin 0.0456044002 ## bind -0.0913567686 ## binge 0.2704045341 ## birch 0.0357240783 ## bird 0.5779126783 ## bit 0.6674249010 ## bitch 0.4885831627 ## bite 0.7055495815 ## blade 0.6104278444 ## blame 0.5233630982 ## blanch -0.4929583589 ## blast 0.4803043073 ## blaze 0.6144688025 ## bleat 0.0183456161 ## bleed 0.4649603651 ## bleep -0.3797852982 ## blend 0.5596330958 ## bless 0.4862663439 ## blight 0.1428873962 ## blink 0.3883831213 ## bliss 0.6738568960 ## blitz 0.2492738579 ## bloat 0.3462414401 ## blob 0.2451566487 ## block 0.5770305003 ## bloke -0.6463286354 ## blood 0.5343354434 ## bloom 0.6432669970 ## blot 0.4456271471 ## blouse 0.2636920842 ## blow 0.6192294225 ## bluff 0.6172042368 ## blur 0.3869336735 ## blush 0.7131474304 ## boar -0.1955958722 ## board 0.5947657521 ## boast 0.5430369452 ## boat 0.7103581623 ## bob -0.1959878583 ## bog 0.1087750715 ## boil 0.4990938952 ## bolt 0.7183260398 ## bomb 0.4947974370 ## bond 0.5963739485 ## bone 0.6994280481 ## boo 0.4350288449 ## book 0.4228348289 ## boom 0.4175301020 ## boon -0.3196660622 ## boost 0.3884695283 ## boot 0.5611917375 ## booth 0.6558586105 ## booze 0.4659052452 ## bore 0.4517195072 ## boss 0.5923835714 ## bough -0.9627047005 ## bounce 0.7144017667 ## bound 0.4609616571 ## bout -0.2460322292 ## bowl 0.4681865740 ## box 0.4100776287 ## boy 0.6673379100 ## brace 0.5098469818 ## brad -0.9966896627 ## brag 0.5237158832 ## braid 0.3781290908 ## brain 0.6250201213 ## brake 0.7161658576 ## bran -1.1514660807 ## branch 0.4400871815 ## brand 0.4640320808 ## brass 0.6749200766 ## brat 0.4126113388 ## brawl 0.2885613311 ## brawn -1.1862039707 ## breach -0.2587840272 ## bread 0.7076881101 ## break 0.5471484226 ## breast 0.4425448250 ## breath 0.5219254049 ## breed 0.5321428406 ## breeze 0.6850056664 ## brew 0.5745906890 ## bribe 0.5794532261 ## brick 0.4393668579 ## bride 0.5935510820 ## bridge 0.4231040292 ## brig -1.1069673462 ## brim 0.0011982951 ## bring 0.6999609443 ## brink 0.1458544124 ## broach -0.8722497068 ## broad 0.4467782091 ## broil 0.5217749464 ## bronze 0.6189044123 ## brooch -0.1816354895 ## brood -0.7094065232 ## brook -0.2816186167 ## broom 0.7107733646 ## broth -0.8125147519 ## brow 0.1906300586 ## bruise 0.4493189892 ## brunt -0.3376069307 ## brush 0.4320060311 ## brute 0.3523559613 ## buck 0.2429907001 ## bud 0.6724083757 ## budge 0.3955515982 ## buff 0.3494155734 ## bug 0.7075605668 ## build 0.6283170006 ## bulb 0.5497611363 ## bulge 0.4063718473 ## bulk 0.7196745111 ## bull 0.5760512511 ## bum 0.4689530236 ## bump 0.3909613508 ## bun 0.3967498974 ## bunch 0.6140159054 ## bunk -0.1178040820 ## burn 0.4995560188 ## burr -0.1106972838 ## burst 0.4596244774 ## bus 0.6345575285 ## bush 0.4950627199 ## bust 0.5839028146 ## butt 0.4741430727 ## buy 0.6559407337 ## buzz 0.5565872619 ## cab 0.5294183107 ## cad -0.9847086112 ## cage 0.6371676804 ## cake 0.6649785501 ## calf 0.5274908336 ## call 0.6904273541 ## cam 0.3766635610 ## camp 0.4899959221 ## can 0.6049070152 ## cane 0.4140491392 ## cant 0.1419877333 ## cap 0.5390064821 ## cape 0.4614098560 ## car 0.6978534281 ## card 0.4994258311 ## care 0.5003108780 ## cart 0.4410599144 ## carve 0.5078525617 ## case 0.4372412744 ## cash 0.6894698805 ## cask -0.0935208092 ## cast 0.5611781549 ## caste -0.1542136414 ## cat 0.5654445158 ## catch 0.7089143235 ## cause 0.5666375358 ## cave 0.6116670912 ## cease 0.4024118709 ## cell 0.4908951888 ## cent 0.4497920814 ## chafe -1.2907596850 ## chain 0.4069458639 ## chair 0.7067213920 ## chaise -0.8860164593 ## chalk 0.6391613967 ## champ 0.5670900604 ## chance 0.7151706410 ## change 0.5796256110 ## chant 0.4609714796 ## chap 0.3395091276 ## char -1.4035016044 ## charge 0.6170667535 ## charm 0.7141380874 ## chart 0.6652999440 ## chase 0.7041960375 ## chat 0.5316951765 ## cheat 0.5467518041 ## check 0.6746033924 ## cheek 0.4522620030 ## cheer 0.7058148841 ## cheese 0.5942348067 ## chef 0.6381390467 ## chess 0.5119866167 ## chest 0.5252904777 ## chew 0.6735251384 ## chide -1.0316427394 ## chief 0.5860253161 ## child 0.6233290343 ## chime 0.4536347476 ## chin 0.3966131451 ## chip 0.6843399725 ## chive -0.5241066284 ## choice 0.6678582166 ## choir 0.5724690117 ## choke 0.4772918218 ## chomp -0.5612192605 ## choose 0.6035301838 ## chop 0.9983643940 ## chord 0.2455301673 ## chore 0.3173066707 ## chow -0.4270800364 ## chrome 0.2581871849 ## chuck -0.7700118104 ## chum -0.9906823421 ## chump -0.1617254425 ## chunk 0.3989466811 ## church 0.6695445501 ## churn 0.1909576313 ## chute -0.3300191604 ## cinch -0.3794016903 ## cite 0.2108425843 ## claim 0.4379315455 ## clam 0.4344810298 ## clamp 0.3876846450 ## clan -0.0992725513 ## clang 0.2814742891 ## clap 0.8161558694 ## clash 0.4102389252 ## class 0.6040638945 ## clause -0.3708886332 ## claw 0.5015949000 ## clay 0.6467437345 ## cleat -1.1608121728 ## clench -0.2216407913 ## clerk 0.4339031481 ## click 0.5407520901 ## cliff 0.6205279222 ## climb 0.6855431358 ## clinch -0.5458172312 ## cling 0.5020163308 ## clip 1.0024318172 ## cloak 0.4483417620 ## clock 0.6200177865 ## clod -0.4182564481 ## clog -0.1432853614 ## clot 0.3826628239 ## cloth 0.4518648117 ## cloud 0.5013371934 ## clout 0.2867295776 ## clove -0.4005478710 ## clown 0.6369744445 ## club 0.3937626267 ## cluck -0.5049015745 ## clump -0.2729653983 ## clutch 0.4644164337 ## coach 0.6737604782 ## coal 0.7025548180 ## coast 0.6848766971 ## coat 0.4546996482 ## coax 0.2243590701 ## cock 0.3557911627 ## cod 0.2937476474 ## code 0.3960472163 ## coil 0.4088056968 ## coin 0.5965745351 ## coke 0.5005669497 ## colt 0.1265256647 ## comb 0.6074699752 ## come 0.5581581223 ## cone 0.3883937362 ## cook 0.6130689391 ## coop -0.3768099259 ## cop 0.5018807032 ## cope 0.5497701434 ## cord 0.6391450905 ## core 0.5100836741 ## cork 0.6934634272 ## corn 0.5869054622 ## corps 0.1246551604 ## corpse 0.5281024940 ## cost 0.6262580226 ## cot 0.0068911198 ## couch 0.6595442455 ## cough 0.4929198000 ## count 0.9855792497 ## coup -0.4080615350 ## coupe -0.3906861696 ## course 0.5757761177 ## court 0.6951697034 ## cove 0.2951170576 ## cow 0.8271177832 ## cowl -1.2324499079 ## cox 0.4752732076 ## crab 0.5029120517 ## crack 0.5508809131 ## craft 0.5503156696 ## crag -0.3558013234 ## cram 0.2444553420 ## cramp 0.4337985434 ## crane 0.3797959122 ## crank 0.4051238830 ## crap 0.4793985690 ## crash 0.6963574999 ## crate 0.0622187126 ## crave 0.3926514614 ## crawl 0.5542165897 ## craze 0.4512801917 ## creak 0.3892734518 ## cream 0.5471917730 ## crease -0.2275829575 ## creed 0.4953264373 ## creek 0.4191984836 ## creep 0.5953153900 ## crepe -0.4812659870 ## crest 0.4193662727 ## crew 0.5574149597 ## crime 0.3982058904 ## croak 0.0828343227 ## crone 0.1511709627 ## crook 0.5607513010 ## croon -1.2438539401 ## crop 0.5762691165 ## cross 0.5129863005 ## crouch 0.3845189132 ## crow 0.6139742710 ## crowd 0.4498641693 ## crown 0.6369734322 ## crumb 0.6446218071 ## crunch 0.3938972176 ## crush 0.6238758527 ## crust 0.7088958527 ## crutch 0.3759123767 ## crux -0.8852921290 ## cry 0.5266622594 ## crypt 0.3566369268 ## cub 0.3148859746 ## cube 0.6584244564 ## cud -0.9545121103 ## cue 0.4943379735 ## cuff -0.0133739224 ## cull -0.2457906766 ## cult 0.3511649570 ## cup 0.6715360566 ## cur 0.3826861695 ## curb 0.3923568856 ## curd -0.1493564234 ## cure 0.4375410860 ## curl 0.6420152456 ## curse 0.5834827763 ## curve 0.6088632817 ## cusp -0.1028663205 ## cut 0.6951551410 ## cyst -1.0723336520 ## czar -1.0401168759 ## dad 0.6463227623 ## dale -0.8105551944 ## dam 0.2813609637 ## dame 0.1004907206 ## damn 0.4071245379 ## damp 0.8588601588 ## dance 0.7103720686 ## dare 0.7065901712 ## darn 0.1888968716 ## dash 0.5563133042 ## date 0.4411439401 ## daunt -0.3556315756 ## dawn 0.5426375314 ## deal 0.7164347904 ## dean 0.1915160029 ## dearth -0.1247326566 ## debt 0.6032695989 ## deck 0.7186846450 ## deed 0.5566262731 ## deem -1.0409392205 ## deer 0.6416464477 ## dell -1.2078333104 ## den 0.3874845446 ## dent 0.3908835975 ## desk 0.7168412789 ## dial 0.4361995122 ## dice 0.5205086940 ## die 0.5260247926 ## dig 0.6612909549 ## dike -0.9857290330 ## dill -0.2963908698 ## dime 0.4224027759 ## din 0.3410268976 ## dine 0.1504317623 ## dint -1.5868419144 ## dip 0.5595878305 ## dirge 0.1221217200 ## dirt 0.6494075462 ## disc 0.3868454524 ## dish 0.8444292731 ## ditch 0.4103806466 ## dive 0.4615936941 ## do 0.6208465241 ## dock 0.9560543046 ## dodge 0.4566180357 ## doe 0.0867514998 ## dog 0.6072916271 ## dole 0.2519808093 ## doll 0.4122436244 ## dome 0.3791253072 ## doom 0.4070828873 ## door 0.6693984241 ## dope 0.4375157140 ## dose 0.4141679681 ## doubt 0.5678639575 ## dough 0.5405479981 ## douse -1.0920779362 ## draft 0.4703229916 ## drag 0.6869519246 ## drain 0.4910196368 ## drake -0.4352577690 ## dram -1.5123057442 ## drape 0.2214284182 ## draught 0.3166110924 ## draw 0.4902569805 ## drawl 0.4059094664 ## dread 0.3208035589 ## dream 0.7073717023 ## dress 0.5361453708 ## drift 0.3848276775 ## drill 0.6333556599 ## drink 0.6813113982 ## drip 0.6794006691 ## drive 0.6630566042 ## drone 0.3550070434 ## droop -0.5327655804 ## drop 0.5654560364 ## dross 0.3257301998 ## drought 0.1826557224 ## drove 0.3191190579 ## drown 0.3973116514 ## drum 0.6100797665 ## duck 0.9672190709 ## duct -0.4744255806 ## dud -0.4232287237 ## duel 0.5197716290 ## dug 0.4808845652 ## duke 0.3958707454 ## dump 0.5620028960 ## dun 0.3849260718 ## dune 0.3378222509 ## dung -0.9167757548 ## dunk -0.0719639940 ## dusk 0.5423279935 ## dust 0.6929399100 ## dwarf 0.3928328839 ## dwell 0.2605954341 ## ear 0.6504425739 ## earl 0.0204612767 ## earn 0.5007593588 ## earth 0.6335578354 ## ease 0.3961880769 ## east 0.2384007824 ## eat 0.5397167065 ## ebb -0.2669269409 ## edge 0.6125527064 ## eel 0.0806139445 ## egg 0.6950109626 ## elk 0.4034461753 ## elm 0.4220506672 ## end 0.4058767904 ## err -0.6201735826 ## eve 0.4063062234 ## ewe -0.6656386707 ## face 0.6682131650 ## fact 0.6925178932 ## fad 0.2064640526 ## fade 0.5195899348 ## fail 0.3895156208 ## fair 0.5767766516 ## faith 0.7135162852 ## fake 0.4308023027 ## fame 0.3856096578 ## fan 0.4035627108 ## fang -0.0366840277 ## farce -0.4377899917 ## fare 0.3252473652 ## farm 0.7072413129 ## fast 0.6278980228 ## fate 0.6966291458 ## fault 0.6324645139 ## fawn 0.2170402202 ## faze 0.0826687290 ## fear 0.6909231795 ## feast 0.6811306902 ## feat 0.2495299527 ## fee 0.3266107672 ## feed 0.5048241397 ## feel 0.7124661652 ## feint -0.1597903348 ## fell 0.9807799096 ## fen 0.0694441128 ## fence 0.5925239233 ## fern -0.3609427011 ## fetch 0.6380245035 ## feud 0.3363308805 ## fiend -0.8980667739 ## fife -0.9770116094 ## fig 0.3495843315 ## fight 0.4176328525 ## file 0.5672693920 ## fill 0.3114960757 ## film 0.5743900266 ## filth 0.1364013313 ## fin 0.3342209900 ## find 0.5284828040 ## fine 0.4096495476 ## fink -0.4479879073 ## fir 0.0716900633 ## fire 0.6981943190 ## firm 0.6652903604 ## fish 0.6732466091 ## fist 0.0614954810 ## fix 0.6874861718 ## flag 0.6757283555 ## flail -1.1535534673 ## flair 0.1729387398 ## flake 0.3462227449 ## flame 0.6159365044 ## flange -1.2543973742 ## flank 0.1489154425 ## flare 0.6005146094 ## flask 0.4770943691 ## flaw 0.4683324518 ## flax -0.0916548203 ## flea 0.4891334092 ## fleck -0.6624284654 ## flee 0.3788546446 ## fleet 0.3429368436 ## flesh 0.5435309870 ## flex 0.4830194119 ## flick 0.3519056461 ## flight 0.4011325906 ## fling 0.4381148802 ## flint 0.3695055533 ## flip 0.4143730602 ## flirt 0.6280939272 ## float 0.4578079990 ## flock 0.5021114197 ## floe -0.5017494213 ## flog 0.2571289814 ## flood 0.7163611643 ## floor 0.6192436822 ## flop 0.1684900412 ## flour 0.6479276450 ## flow 0.3921807740 ## fluff 0.4186479044 ## fluke 0.4359617924 ## flush 0.5386449289 ## flute 0.4138112711 ## flux 0.1768876206 ## fly 0.9880152489 ## foal -0.1478907690 ## foam 0.4861458022 ## foe 0.4846435786 ## fog 0.4762383942 ## foil 0.4837008808 ## fold 0.6866974240 ## folk 0.5643332395 ## font -0.4448918540 ## food 0.5797872707 ## fool 0.7125991509 ## foot 0.6715347198 ## force 0.4085970476 ## ford -0.0225140816 ## forge 0.0439336969 ## fork 0.6409814699 ## form 0.4220034126 ## fort -0.1227219887 ## found 0.6803130182 ## fowl 0.6943013240 ## fox 0.7136467159 ## frame 0.3219341195 ## fraud 0.1840990439 ## fray -0.0965806430 ## freak 0.5483055191 ## freeze 0.4509914162 ## freight 0.3099099119 ## fret -0.6012925821 ## friend 0.5838251129 ## frieze -0.0777543670 ## fright 0.3948110347 ## frill 0.1816973496 ## fringe 0.3216268245 ## frock -0.2683251636 ## frog 0.5956626309 ## front 0.6717800059 ## frost 0.4283250458 ## froth -0.7703028391 ## frown 0.3877946699 ## fruit 0.6606363811 ## fry 0.8160620955 ## fuel 0.6735371077 ## full 0.6065348740 ## fun 0.5765542384 ## fund 0.4164828065 ## funk 0.3075558528 ## fur 0.6039625949 ## fuse 0.3327689534 ## fuss 0.4234105660 ## fuzz -0.1038072768 ## gab -0.2263582528 ## gag -0.0369143396 ## gain 0.4114132422 ## gait -0.4445070737 ## gal -0.5233233634 ## gale 0.0125359753 ## gall 0.0154366975 ## game 0.6727776704 ## gang 0.4631150642 ## gap 0.5400004306 ## garb -0.6764675860 ## gas 0.3909333124 ## gash -0.8162884986 ## gasp 0.3921498832 ## gate 0.3393209006 ## gauge -0.2357079330 ## gauze -0.3359303535 ## gay 0.4098276730 ## gaze 0.3306705734 ## gear 0.6303493758 ## gel 0.3167474790 ## gem 0.4543173005 ## gene 0.0981220517 ## get 0.5747493922 ## ghost 0.5850051476 ## ghoul -0.6410637814 ## gibe -0.0549189251 ## gift 0.7099443761 ## gig -0.5607555478 ## gill -1.2520465763 ## gilt -0.2891315924 ## gin 0.4003151723 ## gird 0.3794415782 ## girl 0.4670327714 ## gist -0.4333561350 ## give 0.7069901731 ## glance 0.4934456592 ## gland 0.4044971857 ## glare 0.6987870479 ## glass 0.6919990606 ## glaze 0.4845145462 ## gleam -0.1040181892 ## glean -1.2485298877 ## glee 0.0728941224 ## glen -0.2903600404 ## glide 0.3704938229 ## glimpse 0.4061328727 ## glint 0.0491470024 ## gloat -0.1334806809 ## globe 0.3025016760 ## gloom 0.5760902861 ## gloss 0.6530786656 ## glove 0.3990324736 ## glow 0.3951878507 ## glue 0.5507498383 ## gnaw -0.1291339407 ## gnome -0.8051828835 ## go 0.5035420855 ## goad 0.3072879333 ## goal 0.6512951275 ## goat 0.4990115183 ## gob -1.0121702771 ## god 0.3875314856 ## gold 0.4040131926 ## golf 0.3745224840 ## gong -0.3111087943 ## goon -1.1775983632 ## goose 0.3986031977 ## gore -0.6793975016 ## gouge -0.6907298805 ## gourd -0.7063628687 ## gout -0.2291179959 ## gown 0.3179244049 ## grab 0.4125753649 ## grace 0.5827950829 ## grade 0.4863646898 ## graft -0.0228860883 ## grail -0.6662097201 ## grain 0.4459889189 ## gram -0.1602665234 ## grant 0.5633310957 ## grape 0.5340379900 ## graph 0.4738488604 ## grasp 0.4647185831 ## grass 0.4208116743 ## grate 0.1626695747 ## grave 0.5575450728 ## graze 0.3321163863 ## grease 0.4162252585 ## greed 0.4764931334 ## greet -0.3880427555 ## grid 0.3671858385 ## grill 0.3977631359 ## grille -0.9257655687 ## grime 0.1147366208 ## grin 0.2900455950 ## grind 0.4765886378 ## grip 0.3846140221 ## gripe -0.1031223542 ## grist -0.8213952945 ## grit -0.3667287461 ## groan 0.4411744147 ## groin 0.0457485701 ## groom 0.5969886854 ## groove 0.4421310499 ## grope -0.1324237151 ## grouch 0.0962267698 ## ground 0.6676956850 ## group 0.5471349829 ## grouse 0.0285217467 ## grove 0.0959340162 ## grow 0.7173251193 ## growl 0.4194240882 ## grub -0.5483959377 ## grudge 0.3159123200 ## grunt 0.3432107142 ## guard 0.7011296837 ## guess 0.4966560409 ## guest 0.5268433872 ## guide 0.7144782157 ## guild -0.1937930981 ## guile -0.4769061445 ## guilt 0.4225406422 ## guise -0.1989561178 ## gulf 0.1815369998 ## gull -0.5777323498 ## gulp 0.4671294760 ## gum 0.4105168197 ## gun 0.5759532439 ## gush 0.1012979161 ## gust -0.0707987070 ## gut 0.3085093131 ## guy 0.4486544990 ## gyp -0.1559009214 ## hack 0.3559951914 ## hag 0.3767188770 ## hail 0.6852210247 ## hair 0.4188747271 ## hall 0.5025704220 ## halt 0.6991906227 ## ham 0.7148308124 ## hand 0.6913468102 ## hang 0.6155964170 ## hank 0.2969114941 ## hark 0.3226840113 ## harm 0.4302710295 ## harp 0.5982080432 ## hart 0.1968917696 ## hash 0.3198258951 ## haste 0.6675828684 ## hat 0.5083096704 ## hatch 0.5945925476 ## hate 0.7075982232 ## haul 0.7148289009 ## haunt 0.0285405028 ## have 0.6383830619 ## haw 0.2876955115 ## hawk 0.4749269168 ## hay 0.7132852004 ## haze 0.5014569942 ## head 0.7154374433 ## heal 0.5055856531 ## heap 0.4838716496 ## hear 0.6137265407 ## heart 0.6886060565 ## hearth 0.3924237036 ## heat 0.6290596637 ## heave 0.1536015376 ## heck 0.2542756529 ## hedge 0.2788321254 ## heed 0.2191330817 ## heel 0.4737695532 ## height 0.5093729702 ## heir 0.4964592792 ## hell 0.5201268784 ## helm -0.5184145782 ## help 0.7165892638 ## hem 0.0980192284 ## hen 0.4042742194 ## herb 0.3512639737 ## herd 0.4660110545 ## hick 0.3409037361 ## hide 0.9956597405 ## hike 0.6005578962 ## hill 0.6927754486 ## hilt 0.3321552804 ## hind 0.3293473807 ## hinge 0.3862346323 ## hint 0.6109291645 ## hip 0.6817757892 ## hire 0.5613676820 ## hiss 0.0931452393 ## hit 0.5006812645 ## hitch -0.1245808761 ## hive 0.2511112602 ## hob 0.4041932129 ## hoe 0.5199515987 ## hog 0.9488368902 ## hoist 0.4173266724 ## hold 0.6452945010 ## hole 0.6586986941 ## home 0.4641108048 ## hone -0.9004516230 ## hooch 0.3500350009 ## hood 0.6140343756 ## hoof 0.4525578082 ## hook 0.4940730311 ## hoop 0.4251022150 ## hoot 0.4610395870 ## hop 0.4930515092 ## hope 0.6463872652 ## horn 0.7034735120 ## horse 0.3427394241 ## hose 0.4829435303 ## host 0.6268569610 ## hound 0.4306567977 ## hour 0.4633182569 ## house 0.4779544958 ## howl 0.6220915564 ## hub 0.0583857143 ## hue 0.4257532295 ## huff 0.3558470279 ## hug 0.6370714127 ## hulk 0.6002987411 ## hull 0.3647860967 ## hum 0.3887298146 ## hump -0.0084912122 ## hunch 0.2435006106 ## hunk 0.4204396423 ## hunt 0.5951208012 ## hurl 0.5863106064 ## hurt 0.5847551909 ## hush 0.4094515464 ## hut 0.6992729959 ## hymn 0.3757912010 ## ice 0.7095831677 ## inch 0.6286930150 ## ink 0.7167374874 ## inn 0.4136937831 ## ire 0.2964059190 ## isle 0.1669698973 ## itch -0.0513609098 ## jab 0.1217394018 ## jack 0.6184996685 ## jade 0.3469066960 ## jag 0.2098669760 ## jail 0.6978623899 ## jam 0.6909380279 ## jape 0.3824285641 ## jar 0.5514096544 ## jaw 0.5633401854 ## jazz 0.5240463886 ## jeep 0.6569925155 ## jeer 0.4176274988 ## jerk 0.5573964395 ## jest 0.3758564014 ## jet 0.6111473502 ## jig 0.4109324086 ## job 0.3919440067 ## jog 0.7122428049 ## join 0.4237814226 ## joke 0.7127937047 ## jolt 0.4104784090 ## jot 0.3041787571 ## joust 0.2151349880 ## jowl -0.1502754153 ## joy 0.4924385896 ## judge 0.5856313731 ## jug 0.6081687287 ## juice 0.7113517319 ## jump 0.4960873847 ## junk 0.6659129966 ## jute -0.6943175441 ## kale -0.8961277284 ## keel 0.3405405971 ## keen 0.3334639980 ## keep 0.5330381206 ## keg 0.5425239073 ## kelp -0.9465162056 ## ken 0.2686139624 ## key 0.4068747073 ## kick 0.4554513760 ## kid 0.7524599528 ## kill 0.7129868440 ## kilt -0.3679511263 ## kin 0.3646781982 ## kind 0.5170743790 ## king 0.6310225978 ## kiss 0.6994575591 ## kit 0.4431519565 ## kite 0.6511743649 ## knack -0.5239842303 ## knead 0.4364323859 ## knee 0.6947043092 ## kneel 0.3534793493 ## knife 0.6875172528 ## knight 0.4844020826 ## knit 0.5852221012 ## knob 0.6658368012 ## knock 0.6119307015 ## knoll -0.0688737674 ## knot 0.6982591425 ## know 0.6653423666 ## lace 0.7070310484 ## lack 0.5057775142 ## lad 0.5523850558 ## lag 0.3904348081 ## lake 0.7128417585 ## lamb 0.4393870460 ## lame 0.7104980008 ## lamp 0.6511999141 ## lance -0.1653985220 ## land 0.6257306531 ## lane 0.6572127622 ## lap 0.9623881767 ## lapse 0.4911259298 ## lard 0.3463838755 ## lark 0.4507872795 ## lash 0.4406212066 ## lass -0.7960962923 ## last 0.3202680635 ## latch 0.4878572052 ## lath -1.3580161049 ## lathe 0.3582459429 ## laugh 0.5012123777 ## launch 0.4481188969 ## law 0.6242955315 ## lawn 0.3851043280 ## lay 0.5657124544 ## laze 0.3859238416 ## leaf 0.6034082289 ## leak 0.7129206913 ## lean 0.5767145507 ## leap 0.3978172645 ## learn 0.0336862350 ## lease 0.7090980512 ## leash 0.6948458868 ## leave 0.6497642719 ## ledge 0.4072382327 ## lee -0.2250936459 ## leg 0.3802552895 ## lend 0.6882844973 ## lens 0.4390162659 ## let 0.3918214571 ## lick 0.5309305670 ## lid 0.5814820139 ## lie 0.6460918690 ## life 0.6957603102 ## lift 0.5725428808 ## light 0.7041987343 ## like 0.6960128450 ## lilt 0.3978249750 ## limb 0.6504210249 ## lime 0.4593255263 ## limp 0.5445166924 ## line 0.2460508971 ## link 0.4918768115 ## lint 0.3147309103 ## lip 0.7090282819 ## lisle -1.3362073435 ## list 0.5950932036 ## load 0.6411162801 ## loaf 0.6277341495 ## loan 0.6016359004 ## lob 0.1103962651 ## lobe 0.1018521819 ## lock 0.6790460131 ## lodge 0.6225163975 ## loft 0.3641287695 ## log 0.4639514566 ## loin 0.3877581022 ## look 0.7145577505 ## loom -0.0820927119 ## loon -0.0630575610 ## loop 0.6758539228 ## loot 0.4478520741 ## lop 0.3607235362 ## lope 0.3784757473 ## lord 0.7187075832 ## lore 0.2704249955 ## lose 0.4905970622 ## loss 0.6104256709 ## lot 0.6811442048 ## lounge 0.4171131966 ## louse -0.2887781748 ## love 0.7055755345 ## low 0.6782072812 ## luck 0.5533396667 ## lug 0.4698970155 ## lull -0.0407971703 ## lump 0.6430054297 ## lung 0.3961397494 ## lurch -0.5312231429 ## lure 0.4021873852 ## lurk 0.3696297175 ## lust 0.4266967503 ## lute 0.3881491548 ## lye -0.6848103580 ## lymph -0.1994762337 ## lynch 0.2448475398 ## maid 0.6699095963 ## mail 0.4578983424 ## make 0.7131886456 ## mall 0.3963561243 ## malt 0.5454275886 ## man 0.7130046318 ## mane 0.3508970333 ## manse 0.3803895564 ## map 0.7144935273 ## mar -0.0544113401 ## march 0.8433549119 ## mare -0.0505554860 ## mark 0.4426703267 ## marsh -0.0709899471 ## mart -0.0007199717 ## mash 0.4268438178 ## mask 0.7007808998 ## mass 0.4324584661 ## mast 0.4492242594 ## mat 0.4281144561 ## match 0.5918077779 ## mate 0.5294186092 ## maw 0.3875188681 ## may 0.4679189385 ## maze 0.5181297562 ## mead 0.1438231590 ## meal 0.7037904222 ## mean 0.4194467355 ## meat 0.4741792262 ## meet 0.6349868657 ## meld 0.4117075123 ## melt 0.6564643978 ## mend 0.4683246430 ## merge 0.4626060433 ## mesh 0.4685299845 ## mess 0.3225227101 ## mew -1.0069061102 ## might 0.4205172367 ## mile 0.5488492235 ## milk 0.5199000348 ## mill 0.3129186720 ## mime -0.6232666625 ## mince -0.5139392793 ## mind 0.6962471440 ## mine 0.4012328311 ## mink -0.2035993040 ## mint 0.5240665909 ## mirth 0.0650920593 ## miss 0.5339444158 ## mist 0.5948281022 ## mite -0.2559535853 ## mitt 0.0928269945 ## mix 0.6352290682 ## moan 0.3929717037 ## mob 0.6840580837 ## mock 0.4255929973 ## mode 0.3170637859 ## mole 0.5673804151 ## moll -0.3525162715 ## mom 0.6024279611 ## monk 0.6315936223 ## month 0.6768807896 ## moo 0.2101315611 ## mood 0.5031230163 ## moon 0.3989279215 ## moose 0.4741056392 ## moot -0.0313660607 ## mop 0.6041547341 ## moss 0.4916713766 ## moth -0.1914446221 ## mould -0.0278429798 ## mount 0.6099373684 ## mourn 0.5877337076 ## mouse 0.4809374031 ## mouth 0.6451207624 ## move 0.6267944063 ## mow 0.2219523720 ## muck -0.4659349562 ## mud 0.6951385500 ## muff 0.0196444767 ## mug 0.6581176019 ## mulch 0.0315074312 ## mule 0.4238328380 ## mum -0.1765389134 ## munch 0.0815426021 ## muse -0.1534796759 ## mush 0.0617436608 ## must 0.5715279914 ## myth 0.3908160879 ## nab -0.4273274031 ## nail 0.3985313601 ## name 0.3981215371 ## nap 0.4281067275 ## nape -0.0615934484 ## naught -0.6314387847 ## neck 0.6040096537 ## need 0.6819560059 ## nerve 0.3924344193 ## nest 0.5121587874 ## news 0.6216797480 ## newt -0.0298508135 ## nick -0.7386342094 ## niece 0.4152402039 ## night 0.4294175928 ## nil -1.0571354896 ## nip -0.0645621026 ## nod 0.3514740544 ## node 0.1935273557 ## noise 0.6124192062 ## nonce 0.3495977703 ## nook -0.4585769086 ## noon 0.3859765401 ## noose 0.3024017525 ## norm 0.3923178562 ## north 0.4865113252 ## nose 0.4333023280 ## notch 0.3136969130 ## note 0.3989943699 ## noun 0.0303865364 ## nudge 0.0832438044 ## nun 0.3924739778 ## nurse 0.4276339815 ## nut 0.6715649494 ## nymph 0.3201397723 ## oak 0.7058748183 ## oath 0.4042280308 ## oil 0.7128925004 ## ooze 0.2080926921 ## orb -0.7943446102 ## ore 0.1081144671 ## ought 0.3817712895 ## ounce 0.3919930711 ## oust -0.5732268371 ## owl 0.7116206910 ## pace 0.4836440481 ## pack 0.7008939259 ## pact 0.6143907950 ## pad 0.6499900882 ## page 0.6845642858 ## pail 0.4107337631 ## pain 0.4976691607 ## paint 0.7129211121 ## pair 0.7149127451 ## pal 0.6790057550 ## pale 0.7046738682 ## pall 0.3872286418 ## palm 0.6670007204 ## pan 0.5962917306 ## pane 0.2787186218 ## pang -0.6764386921 ## pant 0.6053832842 ## pap -0.0179803903 ## par -0.0904523611 ## pare -0.2394485765 ## park 0.6251516250 ## part 0.6645271060 ## pass 0.4618239411 ## paste 0.6037036203 ## pat 0.7166080711 ## patch 0.6281366740 ## pate 0.3891089813 ## path 0.6863697603 ## paunch -0.4397238395 ## pause 0.6217221364 ## pave 0.3306464717 ## paw 0.4680759291 ## pawn 0.4013276388 ## pay 0.7034198719 ## pea 0.7117487206 ## peace 0.5940665331 ## peach 0.4379720879 ## peak 0.5808362137 ## peal 0.3922962396 ## pear 0.6003417153 ## pearl 0.7115414380 ## peat -0.1121041398 ## peck 0.5722695988 ## pee 0.3553415861 ## peel 0.5885181228 ## peep 0.4246896473 ## peer 0.6142284348 ## peg 0.5456639844 ## pelt -0.3722920676 ## pen 0.6190325102 ## perch 0.1093928657 ## perk 0.3896076758 ## pest 0.3743467318 ## pet 0.6781808537 ## pew -0.1859449277 ## phase 0.3982369421 ## phrase 0.4061264194 ## pick 0.6504424818 ## pie 0.6730807980 ## piece 0.5074347841 ## pier 0.4088956306 ## pierce 0.3969614963 ## pig 0.7118643999 ## pike 0.5749596106 ## pile 0.7177539590 ## pill 0.4265407516 ## pimp 0.4184427386 ## pin 0.4024559456 ## pinch 0.4047131140 ## pine 0.6491028765 ## pint 0.3771262221 ## pip -0.2393704892 ## pipe 0.7129727072 ## piss 0.3866683616 ## pit 0.5287021558 ## pitch 0.5791580132 ## pith 0.0002308830 ## place 0.7029363186 ## plaid 0.6214025677 ## plain 0.3853688583 ## plan 0.6963172072 ## plane 0.3870545705 ## plank 0.1533274301 ## plant 0.4904334078 ## plate 0.5996716076 ## play 0.6883202441 ## plea 0.5061751402 ## plead 0.6609653919 ## please 0.7099606747 ## pleat -0.2598620540 ## pledge 0.4382991081 ## plod -0.4450907029 ## plot 0.6953631443 ## plough 0.1887582307 ## pluck 0.4927250546 ## plug 0.4573755824 ## plum 0.7186694254 ## plume -0.1351982805 ## plunge 0.4834041764 ## plush 0.5511375209 ## poach -0.4127057501 ## pod 0.3071594759 ## point 0.6865468030 ## poise 0.4147940906 ## poke 0.4887811915 ## pole 0.5312467191 ## poll 0.4855507208 ## pomp 0.2951700644 ## pond 0.5310195426 ## pool 0.7126326141 ## pop 0.6300182727 ## pope 0.6809114643 ## porch 0.4677885077 ## pore 0.0814435715 ## pork 0.6826118271 ## port 0.2619209380 ## pose 0.5288418129 ## post 0.5247692945 ## pot 0.6941729098 ## pouch 0.4007525647 ## pound 0.9842358014 ## pour 0.4973681037 ## pout -0.1776056708 ## praise 0.5397088881 ## prank 0.4833644831 ## pray 0.5663914667 ## preach -0.0464972103 ## prep 0.2500034336 ## press 0.5769812398 ## prey 0.5269750858 ## price 0.7169632362 ## prick 0.3906233635 ## pride 0.7134450301 ## priest 0.2715073761 ## prime 0.5645483160 ## prince 0.3917433766 ## print 0.7004711738 ## prize 0.6164212858 ## probe 0.4727115346 ## prod -0.4885155926 ## prop 0.1030828479 ## prose 0.1820968767 ## prove 0.3318833720 ## prow -0.1531278534 ## prowl 0.4472193402 ## pry 0.2028226538 ## psalm -0.1181101804 ## pub 0.5973564323 ## puck 0.3508277830 ## puff 0.4759268725 ## puke 0.0630615367 ## pull 0.5578703822 ## pulp 0.4552478363 ## pulse 0.6641681750 ## pump 0.4870820606 ## pun -0.0574190238 ## punch 0.5929272946 ## punk 0.5418001391 ## punt 0.3702504511 ## pup 0.5720825353 ## purge 0.4131617297 ## purse 0.4588558540 ## pus 0.2081186396 ## push 0.3910393285 ## put 0.4907933342 ## putt 0.3363344737 ## pyre -0.3790244507 ## quack 0.4243033613 ## quake 0.2277473817 ## quart 0.3686109072 ## quartz 0.4165403646 ## quay 0.3908093325 ## queen 0.4761853152 ## quell -1.0516846753 ## quench 0.1423761597 ## quest 0.3901906664 ## queue -0.5174252671 ## quill 0.3075950871 ## quince -0.8564342649 ## quirk 0.3458069991 ## quiz 0.4333554337 ## quote 0.5616784446 ## race 0.6701827844 ## rack 0.4336030479 ## raft 0.3569542074 ## rag 0.4227475292 ## rage 0.6986105359 ## raid 0.6548385961 ## rail 0.4309617292 ## rain 0.6068395415 ## raise 0.5015934814 ## rake 0.6121063012 ## ram -0.0159852295 ## ranch 0.6901534659 ## range 0.5916999791 ## rank 0.4099652765 ## rant -0.0853697206 ## rap 0.4569421283 ## rape 0.5016042267 ## rash 0.6701744484 ## rasp -0.0432660817 ## rat 0.6689492736 ## rate 0.5402831429 ## rave 0.4832046864 ## ray 0.3951058878 ## reach 0.7142177008 ## realm 0.4212651488 ## ream -0.7428649050 ## reap 0.1743048154 ## rear 0.5989762222 ## reed -0.0041351272 ## reef -0.1972610678 ## reek 0.1606781599 ## reel -0.1571533417 ## reign 0.3783576723 ## rein -0.1903400885 ## rend 0.3799583520 ## rent 0.5433887652 ## rest 0.7025265547 ## retch -1.2840524241 ## rhyme 0.3746176613 ## rib 0.6391923059 ## rice 0.7126479630 ## ride 0.4715467983 ## ridge 0.3618384343 ## rift 0.0111298063 ## rig 0.2300584529 ## right 0.6639970482 ## rile -0.4774830230 ## rim 0.4339845604 ## rime -0.9418858977 ## rind 0.0144239258 ## ring 0.7823690309 ## rink -0.0449236693 ## rinse 0.6202857200 ## rip 0.4203583811 ## rise 0.7158833540 ## risk 0.5636098407 ## rite 0.0920045074 ## roach 0.4674319335 ## road 0.7067019119 ## roam 0.5126854075 ## roar 0.5755486324 ## roast 0.4182984047 ## rob 0.5054846425 ## robe 0.4212498256 ## rock 0.9308037965 ## rod 0.5083739853 ## roe -0.0585066446 ## role 0.5528622297 ## roll 0.4102877782 ## romp 0.1808176397 ## roof 0.7106286581 ## rook -0.2770353243 ## room 0.7183424056 ## roost 0.5223997685 ## root 0.6338375807 ## rope 0.5924444041 ## rose 0.6882919185 ## rot 0.4174727352 ## rouse -0.7422998365 ## rout -0.2143660106 ## rove -0.8595524883 ## rub 0.7155538573 ## rue 0.0335895979 ## rug 0.5783136669 ## rule 0.6349922950 ## rum 0.4824249808 ## rump 0.3325290967 ## run 0.4187473872 ## rung -0.0078981351 ## runt -0.6058566174 ## ruse -0.4835315989 ## rush 0.6360988464 ## rust 0.4840446378 ## rut 0.0898419420 ## rye 0.3496744173 ## sack 0.4025861577 ## sag 0.3975979760 ## sail 0.6557164441 ## saint 0.5915298608 ## sake 0.3054191581 ## sale 0.4438880377 ## salt 0.7152631745 ## salve 0.2187816969 ## sand 0.6050565664 ## sap 0.0878630220 ## sash 0.1590537445 ## sauce 0.6084579072 ## save 0.5984173362 ## saw 0.3905161576 ## sax -0.2127502883 ## say 0.4475740521 ## scald -0.3753536791 ## scale 0.5348163130 ## scalp 0.6873001412 ## scan 0.3688325473 ## scar 0.4201832047 ## scare 0.3946951924 ## scarf 0.4395382785 ## scene 0.4840500223 ## scent 0.6838754952 ## scheme 0.4403055352 ## school 0.4982467899 ## scoop 0.4603220848 ## scope 0.4201519702 ## score 0.6000556544 ## scorn 0.3999030371 ## scotch 0.3160138328 ## scour 0.1388500393 ## scourge 0.3508290297 ## scout 0.3506289272 ## scrap 0.3816496458 ## scrape 0.3934230975 ## scratch 0.4261252400 ## scream 0.3969368880 ## screech 0.0075766523 ## screen 0.4288960952 ## screw 0.6761630064 ## scribe 0.3684469624 ## script 0.7139655684 ## scrub 0.3863897471 ## scuff -0.4981793153 ## sea 0.6228830945 ## seal 0.4257027390 ## seam -0.3413224223 ## sear -0.2777341554 ## search 0.4031072133 ## seat 0.5454002035 ## sect -0.8999355216 ## see 0.5689866324 ## seed 0.5194159543 ## seek 0.7139622240 ## seem 0.4084967973 ## seep -0.2389110924 ## seize 0.6295361903 ## self 0.7141539351 ## sell 0.4012612270 ## send 0.4947310526 ## sense 0.5293652379 ## serf -0.0664160751 ## serge -0.1425312293 ## serve 0.4219711315 ## set 0.9669488975 ## sew 0.4904816216 ## sex 0.6159169286 ## shack 0.4810892235 ## shade 0.5687978698 ## shaft 0.4070345634 ## shag 0.0757031136 ## shah -0.1443336225 ## shake 0.6015978397 ## shall 0.3428559439 ## sham 0.0489405637 ## shame 0.4727599069 ## shank -0.2949150309 ## shape 0.6546701205 ## shard -0.4192279230 ## share 0.7041695833 ## shark 0.6818036081 ## shave 0.4889620705 ## shawl 0.0730368920 ## shay 0.2022106514 ## sheaf -0.3438747676 ## shear 0.2995215132 ## sheath -0.0494682133 ## shed 0.4459015150 ## sheen -0.2779541983 ## sheep 0.4996480912 ## sheer 0.2811575368 ## sheet 0.7068479567 ## shelf 0.6066592112 ## shell 0.6932806241 ## shield 0.6931562238 ## shift 0.4958110926 ## shin -0.1448729049 ## shine 0.3936248990 ## ship 0.6254786209 ## shirt 0.4581365587 ## shoal -0.3817241295 ## shock 0.4502022052 ## shoe 0.4250423887 ## shoot 0.5519975344 ## shop 0.5932350340 ## shore 0.4150172732 ## shot 0.4257927190 ## should 0.6701159685 ## shout 0.5807266253 ## shove 0.4166697509 ## show 0.5236910944 ## shred 0.3903858272 ## shrimp 0.5143430667 ## shrine -0.2549261634 ## shrink 0.4539057005 ## shrub 0.3973645574 ## shrug 0.1519221958 ## shuck -1.4363774646 ## shun -0.1176442218 ## shunt -1.0761787159 ## shut 0.3989466344 ## side 0.4598322812 ## siege 0.3236580366 ## sigh 0.1963816121 ## sight 0.4635581575 ## sign 0.4128833922 ## silk 0.4152868088 ## sill -0.9454292887 ## sin 0.4160093412 ## sine -0.5997832110 ## sing 0.6786107494 ## sink 0.5750773606 ## sip 0.6457398010 ## sir 0.3484243495 ## sit 0.6684986776 ## site 0.4157035556 ## size 0.6667809768 ## skate 0.6131324969 ## skeet -0.7481508803 ## sketch 0.4255647843 ## ski 0.4341589878 ## skid 0.1787243629 ## skiff 0.3902376291 ## skill 0.5525217274 ## skin 0.3946567654 ## skip 0.4692663484 ## skirt 0.4292577403 ## skit 0.5724160203 ## skulk 0.3694423042 ## skull 0.6488171992 ## skunk 0.3419390955 ## sky 0.7108378474 ## slab 0.1021443513 ## slam 0.4353506932 ## slang 0.4522011081 ## slant 0.3789882850 ## slap 0.4935700131 ## slash 0.3827872060 ## slat -0.0709568802 ## slate 0.2523940473 ## slave 0.6353105780 ## sleep 0.4688280106 ## sleeve 0.6476027001 ## slice 0.6794575610 ## slide 0.5116881981 ## slip 0.7149915884 ## slit 0.3225943460 ## slob 0.4056883969 ## sloe -0.5210215171 ## sloop 0.1871446652 ## slop -0.2896970042 ## slope 0.3810459900 ## slot 0.4693449594 ## slouch 0.2154898196 ## slough -0.1699602252 ## sludge -0.5442241518 ## slug 0.3911352235 ## sluice -1.0142579773 ## slum 0.0105263906 ## slump 0.4342298512 ## smack 0.4428068727 ## smart 0.5547634403 ## smash 0.5716500236 ## smear 0.6710422092 ## smell 0.7179780683 ## smelt -0.5831181823 ## smile 0.6766288648 ## smirk 0.3582200088 ## smoke 0.6989230235 ## snack 0.3940767735 ## snag 0.5054743665 ## snail 0.3945914600 ## snake 0.5246861909 ## snap 0.5721071454 ## snare 0.4285531702 ## snatch 0.4095438408 ## sneak 0.4736650218 ## sneer 0.4426350655 ## sniff 0.3932119463 ## snip 0.3158721124 ## snob 0.4135666870 ## snoop 0.4099735598 ## snort 0.3226971268 ## snout 0.2037728095 ## snow 0.4851868717 ## snug 0.3889020437 ## soak 0.6599678855 ## soap 0.7029280211 ## sob 0.3812770634 ## sock 0.4344340542 ## sod 0.2504686717 ## sole 0.4856847736 ## solve 0.4005274276 ## son 0.4004822781 ## song 0.5537875986 ## soot -0.5864654198 ## soothe 0.2232498387 ## sop -1.1591721308 ## sort 0.4849212374 ## soul 0.6675941200 ## sound 0.6728383469 ## soup 0.5503739083 ## source 0.6729082727 ## south 0.0652294150 ## soy 0.3031549013 ## spa 0.2970695018 ## space 0.6681157586 ## spade 0.4683012564 ## span 0.3907979369 ## spare 0.3494246734 ## spark 0.6555785561 ## spat 0.3292071466 ## spate -0.7229379133 ## speak 0.4436922880 ## spear 0.5359790535 ## speck -0.2728814830 ## speech 0.5302870583 ## speed 0.5770693375 ## spell 0.9613479545 ## spend 0.7120724971 ## sphere 0.4042319153 ## sphinx 0.3796466634 ## spice 0.4047325977 ## spike 0.7037231010 ## spill 0.7129656689 ## spin 0.7074585336 ## spine 0.4847710148 ## spire 0.0386015569 ## spit 0.4941619703 ## spite 0.1699295065 ## splash 0.5570397618 ## spleen -0.5924357224 ## splice -0.2288975348 ## split 0.5597450844 ## splurge -0.1002071716 ## spoil 0.5540042891 ## spoke 0.6879898977 ## spoof -0.2481621072 ## spool 0.7051260481 ## spoon 0.4285327354 ## sport 0.5359462208 ## spot 0.5045540044 ## spouse 0.4548230229 ## spout 0.3838265433 ## sprawl 0.3956958988 ## spray 0.3960537089 ## spread 0.4197436147 ## spree -0.4502054718 ## sprig -0.6583895101 ## spring 0.5526199153 ## sprite -0.2685975183 ## sprout 0.4741292781 ## spur 0.3973935043 ## spurt -0.0935863650 ## spy 0.5134927774 ## squad 0.3943750187 ## squall -0.0929776735 ## square 0.4383059276 ## squash 0.4087199054 ## squat 0.1964756936 ## squaw -0.3966431899 ## squawk -0.1255408571 ## squeak 0.4239746220 ## squeal 0.3965000322 ## squeeze 0.4607647912 ## squint 0.4278958404 ## squire 0.0547801972 ## squirm 0.4329130394 ## squirt 0.3989877044 ## stab 0.4225167228 ## stack 0.4600439723 ## staff 0.6476384168 ## stag 0.5762546632 ## stage 0.5251203098 ## stain 0.3952127950 ## stair 0.4711615776 ## stake 0.3193355830 ## stalk 0.4418163619 ## stall 0.6280899938 ## stamp 0.4768688499 ## stance 0.3389588618 ## stanch 0.3895027918 ## stand 0.5758526478 ## star 0.5423871362 ## starch 0.5124065660 ## stare 0.4664708767 ## start 0.4846445657 ## starve 0.4304239944 ## state 0.5004411746 ## staunch -0.5213060833 ## stave -0.2116612836 ## stay 0.6791303022 ## stead -0.0040413015 ## steak 0.4115552010 ## steal 0.6556128545 ## steam 0.3936229975 ## steed -0.1760420031 ## steel 0.4481974911 ## steer 0.3984256453 ## stem 0.3978616568 ## stench -0.1436106630 ## step 0.7104275575 ## stew 0.7174967837 ## stick 0.5715583688 ## still 0.6544575358 ## stilt -0.3611379726 ## sting 0.4031331292 ## stink 0.4287687215 ## stint 0.3658448282 ## stir 0.7086564275 ## stitch 0.0525604114 ## stock 0.7129862604 ## stole 0.6561674545 ## stone 0.4235623353 ## stool 0.7101379041 ## stoop -0.1451800544 ## stop 0.5593653529 ## store 0.5495292426 ## stork 0.4427599247 ## storm 0.5486938183 ## stout 0.3664389276 ## stove 0.5072683556 ## stow -0.1104065272 ## strafe -0.1338401010 ## strain 0.5334517063 ## strand 0.3436894971 ## strap 0.4053399203 ## straw 0.6757182559 ## stray 0.6253042857 ## streak 0.4641142402 ## stream 0.3919957669 ## street 0.4549115789 ## stress 0.6950819796 ## stretch 0.4525948797 ## stride 0.5375692887 ## strife 0.1916126049 ## strike 0.6930475038 ## string 0.4672910181 ## strip 0.6529683584 ## stripe 0.5145241398 ## strive 0.3911115206 ## stroke 0.4601214524 ## stroll 0.4017575164 ## strut -0.0879243153 ## stub 0.3321284066 ## stud 0.5182169286 ## stuff 0.5579753599 ## stump 0.4865810288 ## stunt 0.3841311442 ## style 0.7205198432 ## sub -0.8772349158 ## suck 0.3978809934 ## sue 0.2922644261 ## suit 0.5202746510 ## suite 0.4612154910 ## sulk -0.0829006520 ## sum 0.4335581218 ## sun 0.4516291488 ## sup 0.3869577672 ## surf 0.4228254182 ## surge 0.2705418903 ## swamp 0.3979094428 ## swan 0.3945166391 ## swap 0.1203464608 ## swarm 0.4193622586 ## swath -0.3771428577 ## sway 0.4166484453 ## swear 0.5795812043 ## sweat 0.5695988086 ## sweep 0.4216950785 ## swell 0.7025946811 ## swerve 0.3887633670 ## swig -0.0988098683 ## swim 0.5513417407 ## swine 0.4367197074 ## swing 0.7124850174 ## swipe 0.4091825994 ## swirl 0.3907563649 ## switch 0.4668208026 ## swoop 0.0105260403 ## sword 0.6694880366 ## tab 0.4658618850 ## tack 0.3218981187 ## tact 0.5837614661 ## tag 0.4557941818 ## tail 0.4560424400 ## taint 0.4095047606 ## take 0.6635654933 ## tale 0.5472058439 ## talk 0.4485013805 ## tamp 0.1762076582 ## tan 0.4501934049 ## tang -0.1065540195 ## tank 0.3907565890 ## tape 0.6212205963 ## tar 0.5781918746 ## tart 0.3963598478 ## task 0.6962347909 ## taste 0.6631508501 ## taunt 0.3943852843 ## tax 0.6593343514 ## tea 0.6967651300 ## teach 0.5567436962 ## teak 0.3807209852 ## team 0.6821384944 ## tease 0.5827443523 ## tech -1.0939461581 ## tee 0.4504653904 ## teens 0.3905369142 ## tell 0.6148905912 ## tempt 0.6237481836 ## tend 0.3912217892 ## tense 0.5547946494 ## tent 0.6937415733 ## test 0.5967120764 ## text 0.6722533681 ## thank 0.6453213730 ## thaw 0.4180556718 ## theft 0.4486371877 ## theme 0.4573282644 ## thief 0.4410376567 ## thigh 0.6700206132 ## thin 0.5324461070 ## thing 0.4974501012 ## think 0.7185078061 ## thirst 0.7075244854 ## thong 0.0025310604 ## thorn 0.7198490460 ## thought 0.5340539857 ## thrash 0.3528474381 ## thread 0.5971888874 ## threat 0.4196847127 ## thrift 0.4621267940 ## thrill 0.4565570624 ## thrive 0.4365313832 ## throat 0.7141548729 ## throne 0.1360092327 ## throng -0.5221724183 ## throw 0.4433842637 ## thrush -0.2424476075 ## thrust 0.3599236343 ## thud 0.1541410654 ## thug 0.3833580456 ## thumb 0.7139320597 ## thump 0.3851926259 ## thwack -1.3807722719 ## thwart -0.6171944862 ## tick 0.4852781922 ## tide 0.6453499809 ## tie 0.7138583702 ## tile 0.5966393299 ## till 0.0861079784 ## tilt 0.6608630329 ## time 0.6761022182 ## tin 0.3955739452 ## tint 0.4728003411 ## tip 0.6533711351 ## tire 0.7159129524 ## toad 0.6502701167 ## toast 0.6152950186 ## toe 0.4097036420 ## toil 0.4168540867 ## toll 0.3475586511 ## tomb 0.7136529851 ## tome 0.3595173898 ## ton 0.3896617344 ## tone 0.5778778005 ## tongue 0.6567431004 ## tool 0.7055573143 ## toot -0.3420714116 ## tooth 0.5524209503 ## top 0.5716231720 ## torch 0.4228207262 ## torque 0.1759307693 ## toss 0.6344630918 ## tote -0.3430924751 ## touch 0.7064746225 ## tour 0.6226259100 ## tout -0.0952850911 ## town 0.6664988971 ## toy 0.7114112372 ## trace 0.6166577554 ## track 0.6081945934 ## tract 0.4171982298 ## trade 0.6870366633 ## trail 0.3982816413 ## train 0.6791223254 ## trait 0.3550182611 ## tramp 0.3439133327 ## trance 0.2328757478 ## trap 0.5541822915 ## trash 0.4524210664 ## tray 0.1560241156 ## tread 0.2184965593 ## treat 0.5839225472 ## tree 0.7128801062 ## trench 0.4050634525 ## trend 0.4414485586 ## tribe 0.3534116365 ## trick 0.4389068337 ## trill -0.9924333132 ## trip 0.5691022473 ## tripe 0.2485523492 ## troll -0.3077973519 ## troop 0.1572383363 ## trot -0.3346297175 ## trough -1.0001073953 ## trout 0.6050270714 ## truce 0.1370396140 ## truck 0.4612649955 ## trump -0.1216554030 ## trunk 0.6720856929 ## trust 0.5416143084 ## try 0.6339591947 ## tryst -0.6936545860 ## tub 0.6065161697 ## tube 0.9710066137 ## tuck 0.3572735638 ## tug 0.6795214012 ## tune 0.5625680203 ## turf 0.2454477951 ## turn 0.4251762005 ## tusk 0.0658116943 ## twain 0.0978503683 ## tweed 0.4578676651 ## twin 0.6639871295 ## twinge -0.4412745484 ## twist 0.5855022323 ## twitch 0.1012613522 ## type 0.4288318014 ## urge 0.4256918944 ## urn -0.3502132763 ## use 0.7136931203 ## vale -1.0271371555 ## valve 0.3815424027 ## vamp -0.4471003083 ## van 0.3935456240 ## vase 0.4220954210 ## vault 0.5107748421 ## veal 0.3529227751 ## veer -0.6595118309 ## veil 0.3988018346 ## vein 0.4377503798 ## vent 0.3511095377 ## verb 0.4553964383 ## verge 0.0579961970 ## verse 0.4312977501 ## verve -0.3482590258 ## vest 0.1884937222 ## vet -0.0828050253 ## vex 0.3173577662 ## vice 0.2735327069 ## vie -0.6505831705 ## view 0.4835578098 ## vine 0.4084499752 ## voice 0.6836048121 ## volt 0.2403914702 ## vote 0.4166767237 ## vow 0.3341724827 ## wad 0.3641875326 ## wade 0.4046844035 ## wag 0.4105905334 ## wage 0.4241180925 ## wail 0.3609623915 ## waist 0.4136206644 ## wait 0.5823737144 ## waive 0.3929558755 ## wake 0.4209682721 ## walk 0.7077046833 ## wall 0.5276454447 ## waltz 0.6509983980 ## wand 0.1503714846 ## wane -0.1184865954 ## want 0.5262338942 ## war 0.6884318348 ## ward -0.2024225128 ## ware 0.2182219672 ## warn 0.4744821828 ## warp 0.3891875241 ## wart 0.3426262731 ## wash 0.4755088550 ## wasp 0.4461385750 ## waste 0.7027578728 ## watch 0.5830571015 ## watt 0.3337828516 ## wave 0.4269790728 ## wax 0.4372562106 ## way 0.6728259728 ## wealth 0.4153732039 ## wear 0.4610994343 ## weave 0.5523302490 ## web 0.7070998702 ## wed 0.6607343506 ## wedge 0.4047926377 ## weed 0.5291270392 ## week 0.4565218502 ## weep 0.4091887220 ## weigh 0.4945272158 ## weight 0.5197220282 ## weld -0.2306306286 ## well 0.7054074569 ## welt -0.5614888197 ## west -0.6699577498 ## whack 0.3511707699 ## wharf 0.4691446493 ## wheat 0.5157589833 ## wheel 0.3904584404 ## whelp -1.0496900270 ## whiff 0.0106696173 ## while 0.5789656600 ## whim 0.4059655880 ## whine 0.3443370108 ## whip 0.7116281818 ## whirl 0.4091523982 ## whit -0.3489260686 ## whiz 0.5311302684 ## whoop -0.2883259957 ## whoosh 0.2112390970 ## whore 0.4236323130 ## whorl -0.7627530485 ## wick 0.3886820590 ## wield 0.1400763917 ## wife 0.7119029586 ## wig 0.4292142124 ## will 0.7054877192 ## wilt 0.3228393861 ## win 0.4242101484 ## wine 0.7005649904 ## wing 0.7190845171 ## wink 0.5698492285 ## wipe 0.6966418582 ## wire 0.7111327937 ## wish 0.6627542683 ## wisp -0.3559947047 ## wit 0.4204796908 ## witch 0.4439064670 ## woe 0.4532896728 ## wolf 0.6994288317 ## womb 0.4044563243 ## woo -0.7929897168 ## wood 0.4279273221 ## wool 0.3494362172 ## word 0.5798947642 ## work 0.6443923195 ## world 0.6758082892 ## worm 0.4401197825 ## would 0.6254040988 ## wow 0.3868415563 ## wrack 0.3888945360 ## wrap 0.5123883472 ## wrath 0.3522556691 ## wreak 0.2258550272 ## wreath 0.3077379071 ## wreck 0.5146626362 ## wren -0.3500511922 ## wrest 0.3548004346 ## wretch 0.3960672498 ## wring -1.0044820911 ## wrist 0.6380822668 ## writ -1.0976343576 ## write 0.5198170323 ## writhe 0.1387777447 ## yacht -0.0140847626 ## yak -1.3796354650 ## yam 0.3766225683 ## yang -1.3796752708 ## yank -0.2650992783 ## yard 0.4780938936 ## yarn 0.4686981657 ## yaw -0.6183874180 ## yawl -0.6650962496 ## yawn 0.4643977766 ## yea 0.1520120392 ## year 0.5082492774 ## yearn 0.1105385909 ## yeast 0.5000092140 ## yell 0.4436131516 ## yelp -0.2186835663 ## yen -0.5178110963 ## yes 0.7165871732 ## yield 0.7090935202 ## yoke 0.4853180111 ## yolk 0.3441380481 ## yore -0.4843829130 ## youth 0.5823842698 ## zeal 0.2621717479 ## zest 0.2401278634 ## zinc 0.0612578299 ## zing -0.7560967377 ## zip 0.5166070163 ## zone 0.5840377042 ## zoo 0.3840845368 coef(mdl.glmmSlope3)$`Word`[2] ## RTlexdec_z ## ace 4.416057 ## act 4.672691 ## add 4.525501 ## age 4.502646 ## aid 4.346184 ## aide 3.787507 ## ail 2.947415 ## aim 4.566887 ## air 4.811148 ## aisle 4.181648 ## ale 4.328421 ## angst 3.975172 ## ant 4.595718 ## ape 4.497242 ## arc 3.025961 ## arch 4.428734 ## are 4.381015 ## arm 5.235687 ## art 4.541188 ## ash 4.393576 ## ask 4.727461 ## ass 4.399752 ## axe 4.368441 ## babe 4.532783 ## back 4.696240 ## badge 4.394405 ## bag 4.796537 ## bail 4.032692 ## bait 4.587586 ## bale 2.904439 ## ball 4.505471 ## ban 3.598934 ## band 4.384869 ## bang 4.728292 ## bank 4.654520 ## bar 4.813773 ## bard 2.808576 ## barge 3.389762 ## bark 4.725369 ## barn 4.817145 ## base 4.626783 ## bash 4.340464 ## bat 4.798937 ## batch 4.563075 ## bath 4.657404 ## bay 4.551314 ## beach 4.447312 ## bead 4.039334 ## beak 3.181608 ## beam 4.335359 ## bean 4.371576 ## bear 5.125960 ## beard 4.724604 ## beast 4.364156 ## beat 4.557423 ## beau 3.698379 ## beck 2.159507 ## bed 4.528911 ## bee 4.776918 ## beech 3.019858 ## beef 5.084783 ## beep 4.569700 ## beer 4.777455 ## beet 4.165055 ## beg 4.830640 ## belch 3.715201 ## bell 4.688271 ## belt 4.497797 ## bench 4.811264 ## bend 4.778212 ## berth 3.782824 ## bet 4.832765 ## bib 4.021454 ## bid 4.833914 ## bide 2.114584 ## bile 3.998524 ## bilge 2.353790 ## bill 4.548958 ## bin 3.811531 ## bind 3.603142 ## binge 4.153570 ## birch 3.796498 ## bird 4.621450 ## bit 4.757644 ## bitch 4.485533 ## bite 4.815652 ## blade 4.670922 ## blame 4.538451 ## blanch 2.992097 ## blast 4.472936 ## blaze 4.677071 ## bleat 3.770057 ## bleed 4.449590 ## bleep 3.164292 ## blend 4.593637 ## bless 4.482008 ## blight 3.959550 ## blink 4.333076 ## bliss 4.767431 ## blitz 4.121419 ## bloat 4.268957 ## blob 4.115154 ## block 4.620107 ## bloke 2.758741 ## blood 4.555146 ## bloom 4.720888 ## blot 4.420174 ## blouse 4.143356 ## blow 4.684314 ## bluff 4.681233 ## blur 4.330871 ## blush 4.827212 ## boar 3.444540 ## board 4.647092 ## boast 4.568385 ## boat 4.822968 ## bob 3.443944 ## bog 3.907647 ## boil 4.501525 ## bolt 4.835091 ## bomb 4.494988 ## bond 4.649539 ## bone 4.806338 ## boo 4.404049 ## book 4.385495 ## boom 4.377424 ## boon 3.255765 ## boost 4.333208 ## boot 4.596008 ## booth 4.740046 ## booze 4.451028 ## bore 4.429444 ## boss 4.643467 ## bough 2.277368 ## bounce 4.829121 ## bound 4.443506 ## bout 3.367800 ## bowl 4.454499 ## box 4.366085 ## boy 4.757512 ## brace 4.517886 ## brad 2.225659 ## brag 4.538988 ## braid 4.317475 ## brain 4.693125 ## brake 4.831805 ## bran 1.990163 ## branch 4.411745 ## brand 4.448178 ## brass 4.769048 ## brat 4.369940 ## brawl 4.181196 ## brawn 1.937309 ## breach 3.348398 ## bread 4.818906 ## break 4.574641 ## breast 4.415485 ## breath 4.536264 ## breed 4.551810 ## breeze 4.784394 ## brew 4.616395 ## bribe 4.623794 ## brick 4.410649 ## bride 4.645244 ## bridge 4.385905 ## brig 2.057869 ## brim 3.743967 ## bring 4.807149 ## brink 3.964064 ## broach 2.414997 ## broad 4.421926 ## broil 4.536035 ## bronze 4.683819 ## brooch 3.465781 ## brood 2.662766 ## brook 3.313655 ## broom 4.823600 ## broth 2.505885 ## brow 4.032191 ## bruise 4.425792 ## brunt 3.228467 ## brush 4.399450 ## brute 4.278260 ## buck 4.111859 ## bud 4.765227 ## budge 4.343983 ## buff 4.273787 ## bug 4.818711 ## build 4.698141 ## bulb 4.578616 ## bulge 4.360447 ## bulk 4.837143 ## bull 4.618617 ## bum 4.455665 ## bump 4.336999 ## bun 4.345807 ## bunch 4.676381 ## bunk 3.562902 ## burn 4.502228 ## burr 3.573715 ## burst 4.441472 ## bus 4.707636 ## bush 4.495392 ## bust 4.630564 ## butt 4.463562 ## buy 4.740171 ## buzz 4.589003 ## cab 4.547664 ## cad 2.243888 ## cage 4.711607 ## cake 4.753922 ## calf 4.544732 ## call 4.792643 ## cam 4.315245 ## camp 4.487682 ## can 4.662522 ## cane 4.372128 ## cant 3.958181 ## cap 4.562253 ## cape 4.444188 ## car 4.803942 ## card 4.502030 ## care 4.503377 ## cart 4.413225 ## carve 4.514852 ## case 4.407415 ## cash 4.791186 ## cask 3.599850 ## cast 4.595988 ## caste 3.507504 ## cat 4.602479 ## catch 4.820771 ## cause 4.604294 ## cave 4.672808 ## cease 4.354421 ## cell 4.489051 ## cent 4.426511 ## chafe 1.778225 ## chain 4.361320 ## chair 4.817435 ## chaise 2.394051 ## chalk 4.714641 ## champ 4.604983 ## chance 4.830290 ## change 4.624056 ## chant 4.443521 ## chap 4.258714 ## char 1.606686 ## charge 4.681023 ## charm 4.828719 ## chart 4.754411 ## chase 4.813592 ## chat 4.551129 ## cheat 4.574038 ## check 4.768567 ## cheek 4.430269 ## cheer 4.816055 ## cheese 4.646284 ## chef 4.713085 ## chess 4.521142 ## chest 4.541384 ## chew 4.766926 ## chide 2.172477 ## chief 4.633793 ## child 4.690551 ## chime 4.432358 ## chin 4.345599 ## chip 4.783381 ## chive 2.944704 ## choice 4.758304 ## choir 4.613167 ## choke 4.468353 ## chomp 2.888236 ## choose 4.660427 ## chop 5.261176 ## chord 4.115723 ## chore 4.224932 ## chow 3.092332 ## chrome 4.134981 ## chuck 2.570554 ## chum 2.234799 ## chump 3.496075 ## chunk 4.349149 ## church 4.760869 ## churn 4.032689 ## chute 3.240012 ## cinch 3.164876 ## cite 4.062945 ## claim 4.408465 ## clam 4.403215 ## clamp 4.332014 ## clan 3.591098 ## clang 4.170412 ## clap 4.983942 ## clash 4.366331 ## class 4.661239 ## clause 3.177828 ## claw 4.505331 ## clay 4.726177 ## cleat 1.975943 ## clench 3.404912 ## clerk 4.402336 ## click 4.564909 ## cliff 4.686290 ## climb 4.785212 ## clinch 2.911671 ## cling 4.505972 ## clip 5.267364 ## cloak 4.424305 ## clock 4.685513 ## clod 3.105757 ## clog 3.524132 ## clot 4.324373 ## cloth 4.429665 ## cloud 4.504938 ## clout 4.178408 ## clove 3.132701 ## clown 4.711313 ## club 4.341261 ## cluck 2.973925 ## clump 3.326821 ## clutch 4.448763 ## coach 4.767284 ## coal 4.811095 ## coast 4.784198 ## coat 4.433978 ## coax 4.083510 ## cock 4.283487 ## cod 4.189087 ## code 4.344738 ## coil 4.364150 ## coin 4.649844 ## coke 4.503766 ## colt 3.934655 ## comb 4.666422 ## come 4.591393 ## cone 4.333093 ## cook 4.674941 ## coop 3.168819 ## cop 4.505765 ## cope 4.578630 ## cord 4.714616 ## core 4.518246 ## cork 4.797262 ## corn 4.635132 ## corps 3.931809 ## corpse 4.545662 ## cost 4.695008 ## cot 3.752628 ## couch 4.745654 ## cough 4.492131 ## count 5.241723 ## coup 3.121269 ## coupe 3.147706 ## course 4.618199 ## court 4.799859 ## cove 4.191170 ## cow 5.000620 ## cowl 1.866945 ## cox 4.465282 ## crab 4.507335 ## crack 4.580320 ## craft 4.579460 ## crag 3.200784 ## cram 4.114087 ## cramp 4.402177 ## crane 4.320011 ## crank 4.358548 ## crap 4.471558 ## crash 4.801666 ## crate 3.836810 ## crave 4.339571 ## crawl 4.585396 ## craze 4.428776 ## creak 4.334431 ## cream 4.574707 ## crease 3.395871 ## creed 4.495793 ## creek 4.379963 ## creep 4.647928 ## crepe 3.009887 ## crest 4.380218 ## crew 4.590262 ## crime 4.348022 ## croak 3.868178 ## crone 3.972153 ## crook 4.595338 ## croon 1.849593 ## crop 4.618949 ## cross 4.522663 ## crouch 4.327197 ## crow 4.676318 ## crowd 4.426621 ## crown 4.711312 ## crumb 4.722949 ## crunch 4.341466 ## crush 4.691384 ## crust 4.820743 ## crutch 4.314102 ## crux 2.395153 ## cry 4.543471 ## crypt 4.284774 ## cub 4.221249 ## cube 4.743950 ## cud 2.289833 ## cue 4.494289 ## cuff 3.721795 ## cull 3.368168 ## cult 4.276448 ## cup 4.763900 ## cur 4.324408 ## curb 4.339123 ## curd 3.514894 ## cure 4.407871 ## curl 4.718983 ## curse 4.629925 ## curve 4.668542 ## cusp 3.585630 ## cut 4.799836 ## cyst 2.110565 ## czar 2.159583 ## dad 4.725537 ## dale 2.508866 ## dam 4.170240 ## dame 3.895042 ## damn 4.361592 ## damp 5.048917 ## dance 4.822989 ## dare 4.817235 ## darn 4.029554 ## dash 4.588586 ## date 4.413353 ## daunt 3.201042 ## dawn 4.567778 ## deal 4.832214 ## dean 4.033539 ## dearth 3.552360 ## debt 4.660031 ## deck 4.835637 ## deed 4.589062 ## deem 2.158332 ## deer 4.718422 ## dell 1.904399 ## den 4.331709 ## dent 4.336881 ## desk 4.832832 ## dial 4.405830 ## dice 4.534108 ## die 4.542501 ## dig 4.748311 ## dike 2.242336 ## dill 3.291178 ## dime 4.384838 ## din 4.261023 ## dine 3.971028 ## dint 1.327730 ## dip 4.593568 ## dirge 3.927954 ## dirt 4.730231 ## disc 4.330737 ## dish 5.026960 ## ditch 4.366546 ## dive 4.444468 ## do 4.686774 ## dock 5.196800 ## dodge 4.436897 ## doe 3.874138 ## dog 4.666150 ## dole 4.125537 ## doll 4.369381 ## dome 4.318991 ## doom 4.361529 ## door 4.760647 ## dope 4.407833 ## dose 4.372309 ## doubt 4.606160 ## dough 4.564599 ## douse 2.080524 ## draft 4.457750 ## drag 4.787355 ## drain 4.489240 ## drake 3.079889 ## dram 1.441138 ## drape 4.079051 ## draught 4.223874 ## draw 4.488080 ## drawl 4.359743 ## dread 4.230253 ## dream 4.818424 ## dress 4.557900 ## drift 4.327667 ## drill 4.705807 ## drink 4.778773 ## drip 4.775866 ## drive 4.750998 ## drone 4.282294 ## droop 2.931529 ## drop 4.602497 ## dross 4.237749 ## drought 4.020058 ## drove 4.227690 ## drown 4.346661 ## drum 4.670393 ## duck 5.213787 ## duct 3.020295 ## dud 3.098192 ## duel 4.532987 ## dug 4.473819 ## duke 4.344469 ## dump 4.597243 ## dun 4.327816 ## dune 4.256147 ## dung 2.347250 ## dunk 3.632649 ## dusk 4.567307 ## dust 4.796466 ## dwarf 4.339847 ## dwell 4.138645 ## ear 4.731805 ## earl 3.773276 ## earn 4.504059 ## earth 4.706115 ## ease 4.344952 ## east 4.104875 ## eat 4.563334 ## ebb 3.336008 ## edge 4.674155 ## eel 3.864799 ## egg 4.799617 ## elk 4.355995 ## elm 4.384302 ## end 4.359693 ## err 2.798536 ## eve 4.360347 ## ewe 2.729360 ## face 4.758844 ## fact 4.795824 ## fad 4.056283 ## fade 4.532710 ## fail 4.334800 ## fair 4.619721 ## faith 4.827773 ## fake 4.397618 ## fame 4.328857 ## fan 4.356172 ## fang 3.686328 ## farce 3.076037 ## fare 4.237014 ## farm 4.818226 ## fast 4.697503 ## fate 4.802079 ## fault 4.704451 ## fawn 4.072375 ## faze 3.867926 ## fear 4.793397 ## feast 4.778498 ## feat 4.121808 ## fee 4.239089 ## feed 4.510244 ## feel 4.826176 ## feint 3.499019 ## fell 5.234420 ## fen 3.847804 ## fence 4.643681 ## fern 3.192961 ## fetch 4.712911 ## feud 4.253878 ## fiend 2.375716 ## fife 2.255600 ## fig 4.274043 ## fight 4.377581 ## file 4.605256 ## fill 4.216091 ## film 4.616090 ## filth 3.949681 ## fin 4.250668 ## find 4.546241 ## fine 4.365434 ## fink 3.060520 ## fir 3.851221 ## fire 4.804461 ## firm 4.754397 ## fish 4.766502 ## fist 3.835710 ## fix 4.788168 ## flag 4.770278 ## flail 1.986987 ## flair 4.005273 ## flake 4.268929 ## flame 4.679304 ## flange 1.833551 ## flank 3.968721 ## flare 4.655839 ## flask 4.468052 ## flaw 4.454721 ## flax 3.602689 ## flea 4.486370 ## fleck 2.734244 ## flee 4.318579 ## fleet 4.263929 ## flesh 4.569137 ## flex 4.477068 ## flick 4.277575 ## flight 4.352475 ## fling 4.408744 ## flint 4.304354 ## flip 4.372621 ## flirt 4.697801 ## float 4.438708 ## flock 4.506116 ## floe 2.978721 ## flog 4.133371 ## flood 4.832102 ## floor 4.684335 ## flop 3.998505 ## flour 4.727979 ## flow 4.338855 ## fluff 4.379125 ## fluke 4.405468 ## flush 4.561703 ## flute 4.371766 ## flux 4.011282 ## fly 5.245429 ## foal 3.517124 ## foam 4.481824 ## foe 4.479539 ## fog 4.466750 ## foil 4.478104 ## fold 4.786968 ## folk 4.600788 ## font 3.065231 ## food 4.624302 ## fool 4.826378 ## foot 4.763897 ## force 4.363832 ## ford 3.707888 ## forge 3.808989 ## fork 4.717410 ## form 4.384230 ## fort 3.555419 ## found 4.777254 ## fowl 4.798537 ## fox 4.827972 ## frame 4.231973 ## fraud 4.022254 ## fray 3.595194 ## freak 4.576402 ## freeze 4.428336 ## freight 4.213678 ## fret 2.827264 ## friend 4.630446 ## frieze 3.623838 ## fright 4.342857 ## frill 4.018600 ## fringe 4.231505 ## frock 3.333881 ## frog 4.648457 ## front 4.764271 ## frost 4.393849 ## froth 2.570111 ## frown 4.332181 ## fruit 4.747315 ## fry 4.983799 ## fuel 4.766944 ## full 4.664999 ## fun 4.619383 ## fund 4.375831 ## funk 4.210096 ## fur 4.661085 ## fuse 4.248458 ## fuss 4.386371 ## fuzz 3.584198 ## gab 3.397735 ## gag 3.685977 ## gain 4.368117 ## gait 3.065816 ## gal 2.945896 ## gale 3.761217 ## gall 3.765631 ## game 4.765789 ## gang 4.446783 ## gap 4.563765 ## garb 2.712884 ## gas 4.336957 ## gash 2.500143 ## gasp 4.338808 ## gate 4.258427 ## gauge 3.383509 ## gauze 3.231018 ## gay 4.365705 ## gaze 4.245266 ## gear 4.701233 ## gel 4.224081 ## gem 4.433397 ## gene 3.891438 ## get 4.616637 ## ghost 4.632241 ## ghoul 2.766751 ## gibe 3.658583 ## gift 4.822339 ## gig 2.888942 ## gill 1.837128 ## gilt 3.302224 ## gin 4.351231 ## gird 4.319472 ## girl 4.452744 ## gist 3.082783 ## give 4.817844 ## glance 4.492931 ## gland 4.357594 ## glare 4.805362 ## glass 4.795034 ## glaze 4.479342 ## gleam 3.583878 ## glean 1.842479 ## glee 3.853053 ## glen 3.300354 ## glide 4.305858 ## glimpse 4.360083 ## glint 3.816922 ## gloat 3.539050 ## globe 4.202406 ## gloom 4.618677 ## gloss 4.735816 ## glove 4.349280 ## glow 4.343430 ## glue 4.580121 ## gnaw 3.545663 ## gnome 2.517041 ## go 4.508293 ## goad 4.209688 ## goal 4.733103 ## goat 4.501400 ## gob 2.202105 ## god 4.331781 ## gold 4.356858 ## golf 4.311987 ## gong 3.268785 ## goon 1.950402 ## goose 4.348627 ## gore 2.708426 ## gouge 2.691183 ## gourd 2.667397 ## gout 3.393536 ## gown 4.225872 ## grab 4.369885 ## grace 4.628878 ## grade 4.482157 ## graft 3.707322 ## grail 2.728491 ## grain 4.420725 ## gram 3.498294 ## grant 4.599263 ## grape 4.554693 ## graph 4.463114 ## grasp 4.449222 ## grass 4.382417 ## grate 3.989649 ## grave 4.590460 ## graze 4.247465 ## grease 4.375439 ## greed 4.467138 ## greet 3.151728 ## grid 4.300824 ## grill 4.347348 ## grille 2.333571 ## grime 3.916718 ## grin 4.183454 ## grind 4.467283 ## grip 4.327342 ## gripe 3.585241 ## grist 2.492373 ## grit 3.184158 ## groan 4.413399 ## groin 3.811751 ## groom 4.650474 ## groove 4.414855 ## grope 3.540658 ## grouch 3.888554 ## ground 4.758056 ## group 4.574621 ## grouse 3.785540 ## grove 3.888109 ## grow 4.833568 ## growl 4.380306 ## grub 2.907747 ## grudge 4.222811 ## grunt 4.264346 ## guard 4.808927 ## guess 4.497816 ## guest 4.543747 ## guide 4.829237 ## guild 3.447283 ## guile 3.016521 ## guilt 4.385048 ## guise 3.439427 ## gulf 4.018356 ## gull 2.863111 ## gulp 4.452891 ## gum 4.366753 ## gun 4.618468 ## gush 3.896270 ## gust 3.634422 ## gut 4.211547 ## guy 4.424781 ## gyp 3.504937 ## hack 4.283798 ## hag 4.315329 ## hail 4.784722 ## hair 4.379470 ## hall 4.506815 ## halt 4.805977 ## ham 4.829773 ## hand 4.794042 ## hang 4.678786 ## hank 4.193900 ## hark 4.233114 ## harm 4.396810 ## harp 4.652329 ## hart 4.041718 ## hash 4.228765 ## haste 4.757885 ## hat 4.515547 ## hatch 4.646828 ## hate 4.818769 ## haul 4.829770 ## haunt 3.785568 ## have 4.713456 ## haw 4.179878 ## hawk 4.464755 ## hay 4.827422 ## haze 4.505121 ## head 4.830696 ## heal 4.511403 ## heap 4.478364 ## hear 4.675941 ## heart 4.789872 ## hearth 4.339224 ## heat 4.699271 ## heave 3.975851 ## heck 4.129029 ## hedge 4.166392 ## heed 4.075559 ## heel 4.462994 ## height 4.517165 ## heir 4.497517 ## hell 4.533527 ## helm 2.953365 ## help 4.832449 ## hem 3.891282 ## hen 4.357255 ## herb 4.276599 ## herd 4.451189 ## hick 4.260836 ## hide 5.257060 ## hike 4.655905 ## hill 4.796216 ## hilt 4.247525 ## hind 4.243252 ## hinge 4.329807 ## hint 4.671685 ## hip 4.779479 ## hire 4.596276 ## hiss 3.883866 ## hit 4.503940 ## hitch 3.552591 ## hive 4.124214 ## hob 4.357132 ## hoe 4.533261 ## hog 5.185818 ## hoist 4.377115 ## hold 4.723972 ## hole 4.744367 ## home 4.448297 ## hone 2.372087 ## hooch 4.274729 ## hood 4.676410 ## hoof 4.430720 ## hook 4.493886 ## hoop 4.388945 ## hoot 4.443625 ## hop 4.492332 ## hope 4.725635 ## horn 4.812493 ## horse 4.263629 ## hose 4.476952 ## host 4.695919 ## hound 4.397397 ## hour 4.447092 ## house 4.469361 ## howl 4.688669 ## hub 3.830978 ## hue 4.389936 ## huff 4.283572 ## hug 4.711461 ## hulk 4.655511 ## hull 4.297173 ## hum 4.333604 ## hump 3.729224 ## hunch 4.112635 ## hunk 4.381851 ## hunt 4.647632 ## hurl 4.634227 ## hurt 4.631861 ## hush 4.365132 ## hut 4.806102 ## hymn 4.313918 ## ice 4.821789 ## inch 4.698713 ## ink 4.832674 ## inn 4.371587 ## ire 4.193131 ## isle 3.996192 ## itch 3.663997 ## jab 3.927372 ## jack 4.683204 ## jade 4.269969 ## jag 4.061460 ## jail 4.803955 ## jam 4.793420 ## jape 4.324016 ## jar 4.581125 ## jaw 4.599277 ## jazz 4.539491 ## jeep 4.741771 ## jeer 4.377572 ## jerk 4.590234 ## jest 4.314017 ## jet 4.672017 ## jig 4.367386 ## job 4.338494 ## jog 4.825836 ## join 4.386936 ## joke 4.826674 ## jolt 4.366695 ## jot 4.204958 ## joust 4.069476 ## jowl 3.513496 ## joy 4.491399 ## judge 4.633194 ## jug 4.667485 ## juice 4.824480 ## jump 4.496950 ## junk 4.755344 ## jute 2.685725 ## kale 2.378666 ## keel 4.260283 ## keen 4.249516 ## keep 4.553172 ## keg 4.567605 ## kelp 2.301999 ## ken 4.150845 ## key 4.361211 ## kick 4.435122 ## kid 4.887026 ## kill 4.826968 ## kilt 3.182298 ## kin 4.297009 ## kind 4.528883 ## king 4.702257 ## kiss 4.806383 ## kit 4.416408 ## kite 4.732919 ## knack 2.944890 ## knead 4.406184 ## knee 4.799150 ## kneel 4.279970 ## knife 4.788215 ## knight 4.479171 ## knit 4.632571 ## knob 4.755228 ## knock 4.673209 ## knoll 3.637351 ## knot 4.804559 ## know 4.754476 ## lace 4.817906 ## lack 4.511694 ## lad 4.582609 ## lag 4.336198 ## lake 4.826747 ## lamb 4.410680 ## lame 4.823181 ## lamp 4.732958 ## lance 3.490486 ## land 4.694206 ## lane 4.742106 ## lap 5.206437 ## lapse 4.489402 ## lard 4.269174 ## lark 4.428026 ## lash 4.412558 ## lass 2.530866 ## last 4.229438 ## latch 4.484428 ## lath 1.675893 ## lathe 4.287222 ## laugh 4.504748 ## launch 4.423966 ## law 4.692022 ## lawn 4.328088 ## lay 4.602886 ## laze 4.329335 ## leaf 4.660242 ## leak 4.826867 ## lean 4.619627 ## leap 4.347430 ## learn 3.793397 ## lease 4.821051 ## leash 4.799366 ## leave 4.730773 ## ledge 4.361765 ## lee 3.399659 ## leg 4.320709 ## lend 4.789383 ## lens 4.410116 ## let 4.338308 ## lick 4.549965 ## lid 4.626880 ## lie 4.725186 ## life 4.800757 ## lift 4.613279 ## light 4.813596 ## like 4.801141 ## lilt 4.347442 ## limb 4.731773 ## lime 4.441017 ## limp 4.570637 ## line 4.116515 ## link 4.490544 ## lint 4.221013 ## lip 4.820945 ## lisle 1.709076 ## list 4.647590 ## load 4.717615 ## loaf 4.697254 ## loan 4.657545 ## lob 3.910114 ## lobe 3.897114 ## lock 4.775326 ## lodge 4.689315 ## loft 4.296173 ## log 4.448055 ## loin 4.332125 ## look 4.829358 ## loom 3.617238 ## loon 3.646200 ## loop 4.770469 ## loot 4.423560 ## lop 4.290992 ## lope 4.318002 ## lord 4.835672 ## lore 4.153601 ## lose 4.488597 ## loss 4.670919 ## lot 4.778518 ## lounge 4.376790 ## louse 3.302761 ## love 4.815691 ## low 4.774050 ## luck 4.584061 ## lug 4.457102 ## lull 3.680070 ## lump 4.720490 ## lung 4.344878 ## lurch 2.933876 ## lure 4.354080 ## lurk 4.304543 ## lust 4.391371 ## lute 4.332720 ## lye 2.700190 ## lymph 3.438636 ## lynch 4.114684 ## maid 4.761425 ## mail 4.438845 ## make 4.827275 ## mall 4.345208 ## malt 4.572023 ## man 4.826995 ## mane 4.276041 ## manse 4.320914 ## map 4.829260 ## mar 3.659355 ## march 5.025326 ## mare 3.665222 ## mark 4.415676 ## marsh 3.634131 ## mart 3.741048 ## mash 4.391595 ## mask 4.808396 ## mass 4.400138 ## mast 4.425648 ## mat 4.393529 ## match 4.642591 ## mate 4.547665 ## maw 4.331761 ## may 4.454092 ## maze 4.530489 ## mead 3.960973 ## meal 4.812975 ## mean 4.380340 ## meat 4.463617 ## meet 4.708289 ## meld 4.368565 ## melt 4.740968 ## mend 4.454709 ## merge 4.446008 ## mesh 4.455022 ## mess 4.232868 ## mew 2.210114 ## might 4.381969 ## mile 4.577229 ## milk 4.533182 ## mill 4.218256 ## mime 2.793830 ## mince 2.960174 ## mind 4.801498 ## mine 4.352628 ## mink 3.432363 ## mint 4.539522 ## mirth 3.841182 ## miss 4.554551 ## mist 4.647187 ## mite 3.352705 ## mitt 3.883382 ## mix 4.708658 ## moan 4.340058 ## mob 4.782952 ## mock 4.389692 ## mode 4.224563 ## mole 4.605425 ## moll 3.205782 ## mom 4.658750 ## monk 4.703126 ## month 4.772032 ## moo 4.061863 ## mood 4.507656 ## moon 4.349121 ## moose 4.463505 ## moot 3.694419 ## mop 4.661377 ## moss 4.490232 ## moth 3.450856 ## mould 3.699780 ## mount 4.670176 ## mourn 4.636393 ## mouse 4.473900 ## mouth 4.723708 ## move 4.695824 ## mow 4.079849 ## muck 3.033213 ## mud 4.799811 ## muff 3.772033 ## mug 4.743483 ## mulch 3.790083 ## mule 4.387014 ## mum 3.473536 ## munch 3.866212 ## muse 3.508621 ## mush 3.836088 ## must 4.611735 ## myth 4.336778 ## nab 3.091956 ## nail 4.348517 ## name 4.347894 ## nap 4.393517 ## nape 3.648428 ## naught 2.781396 ## neck 4.661157 ## need 4.779754 ## nerve 4.339241 ## nest 4.521404 ## news 4.688042 ## newt 3.696725 ## nick 2.618296 ## niece 4.373940 ## night 4.395511 ## nil 2.133689 ## nip 3.643911 ## nod 4.276919 ## node 4.036599 ## noise 4.673952 ## nonce 4.274064 ## nook 3.044409 ## noon 4.329415 ## noose 4.202254 ## norm 4.339063 ## north 4.482381 ## nose 4.401422 ## notch 4.219440 ## note 4.349222 ## noun 3.788377 ## nudge 3.868801 ## nun 4.339301 ## nurse 4.392797 ## nut 4.763943 ## nymph 4.229243 ## oak 4.816147 ## oath 4.357185 ## oil 4.826824 ## ooze 4.058761 ## orb 2.533531 ## ore 3.906642 ## ought 4.323016 ## ounce 4.338569 ## oust 2.869967 ## owl 4.824889 ## pace 4.478018 ## pack 4.808568 ## pact 4.676952 ## pad 4.731117 ## page 4.783722 ## pail 4.367083 ## pain 4.499357 ## paint 4.826868 ## pair 4.829898 ## pal 4.775265 ## pale 4.814319 ## pall 4.331320 ## palm 4.756999 ## pan 4.649414 ## pane 4.166220 ## pang 2.712928 ## pant 4.663247 ## pap 3.714786 ## par 3.604518 ## pare 3.377817 ## park 4.693325 ## part 4.753235 ## pass 4.444818 ## paste 4.660691 ## pat 4.832477 ## patch 4.697866 ## pate 4.334181 ## path 4.786469 ## paunch 3.073094 ## pause 4.688107 ## pave 4.245229 ## paw 4.454331 ## pawn 4.352772 ## pay 4.812411 ## pea 4.825084 ## peace 4.646028 ## peach 4.408527 ## peak 4.625898 ## peal 4.339030 ## pear 4.655576 ## pearl 4.824769 ## peat 3.571575 ## peck 4.612864 ## pee 4.282803 ## peel 4.637586 ## peep 4.388318 ## peer 4.676705 ## peg 4.572383 ## pelt 3.175693 ## pen 4.684014 ## perch 3.908587 ## perk 4.334940 ## pest 4.311720 ## pet 4.774010 ## pew 3.459224 ## phase 4.348069 ## phrase 4.360073 ## pick 4.731805 ## pie 4.766250 ## piece 4.514216 ## pier 4.364287 ## pierce 4.346129 ## pig 4.825260 ## pike 4.616956 ## pile 4.834221 ## pill 4.391134 ## pimp 4.378813 ## pin 4.354489 ## pinch 4.357923 ## pine 4.729767 ## pint 4.315949 ## pip 3.377936 ## pipe 4.826946 ## piss 4.330467 ## pit 4.546575 ## pitch 4.623344 ## pith 3.742495 ## place 4.811676 ## plaid 4.687620 ## plain 4.328490 ## plan 4.801605 ## plane 4.331055 ## plank 3.975434 ## plant 4.488348 ## plate 4.654556 ## play 4.789437 ## plea 4.512299 ## plead 4.747816 ## please 4.822363 ## pleat 3.346758 ## pledge 4.409025 ## plod 3.064928 ## plot 4.800153 ## plough 4.029343 ## pluck 4.491835 ## plug 4.438050 ## plum 4.835614 ## plume 3.536436 ## plunge 4.477653 ## plush 4.580711 ## poach 3.114203 ## pod 4.209493 ## point 4.786739 ## poise 4.373261 ## poke 4.485834 ## pole 4.550446 ## poll 4.480919 ## pomp 4.191251 ## pond 4.550101 ## pool 4.826429 ## pop 4.700729 ## pope 4.778164 ## porch 4.453893 ## pore 3.866062 ## pork 4.780752 ## port 4.140662 ## pose 4.546787 ## post 4.540591 ## pot 4.798342 ## pouch 4.351897 ## pound 5.239679 ## pour 4.498899 ## pout 3.471913 ## praise 4.563322 ## prank 4.477593 ## pray 4.603920 ## preach 3.671397 ## prep 4.122529 ## press 4.620032 ## prey 4.543947 ## price 4.833018 ## prick 4.336485 ## pride 4.827665 ## priest 4.155248 ## prime 4.601115 ## prince 4.338189 ## print 4.807925 ## prize 4.680041 ## probe 4.461384 ## prod 2.998857 ## prop 3.898986 ## prose 4.019208 ## prove 4.247111 ## prow 3.509156 ## prowl 4.422597 ## pry 4.050742 ## psalm 3.562436 ## pub 4.651034 ## puck 4.275935 ## puff 4.466276 ## puke 3.838093 ## pull 4.590955 ## pulp 4.434812 ## pulse 4.752689 ## pump 4.483249 ## pun 3.654779 ## punch 4.644295 ## punk 4.566504 ## punt 4.305487 ## pup 4.612579 ## purge 4.370778 ## purse 4.440302 ## pus 4.058800 ## push 4.337118 ## put 4.488895 ## putt 4.253883 ## pyre 3.165450 ## quack 4.387730 ## quake 4.088666 ## quart 4.302993 ## quartz 4.375918 ## quay 4.336768 ## queen 4.466669 ## quell 2.141983 ## quench 3.958772 ## quest 4.335827 ## queue 2.954870 ## quill 4.210156 ## quince 2.439060 ## quirk 4.268296 ## quiz 4.401503 ## quote 4.596749 ## race 4.761840 ## rack 4.401880 ## raft 4.285257 ## rag 4.385363 ## rage 4.805094 ## raid 4.738494 ## rail 4.397861 ## rain 4.665462 ## raise 4.505328 ## rake 4.673476 ## ram 3.717822 ## ranch 4.792226 ## range 4.642427 ## rank 4.365914 ## rant 3.612252 ## rap 4.437390 ## rape 4.505345 ## rash 4.761828 ## rasp 3.676313 ## rat 4.759964 ## rate 4.564195 ## rave 4.477349 ## ray 4.343305 ## reach 4.828840 ## realm 4.383107 ## ream 2.611859 ## reap 4.007352 ## rear 4.653498 ## reed 3.735852 ## reef 3.442006 ## reek 3.986619 ## reel 3.503031 ## reign 4.317823 ## rein 3.452537 ## rend 4.320258 ## rent 4.568921 ## rest 4.811052 ## retch 1.788430 ## rhyme 4.312132 ## rib 4.714688 ## rice 4.826452 ## ride 4.459612 ## ridge 4.292688 ## rift 3.759078 ## rig 4.092182 ## right 4.752429 ## rile 3.015643 ## rim 4.402460 ## rime 2.309044 ## rind 3.764090 ## ring 4.932534 ## rink 3.673791 ## rinse 4.685921 ## rip 4.381727 ## rise 4.831375 ## risk 4.599688 ## rite 3.882130 ## roach 4.453351 ## road 4.817405 ## roam 4.522205 ## roar 4.617853 ## roast 4.378593 ## rob 4.511249 ## robe 4.383084 ## rock 5.158381 ## rod 4.515645 ## roe 3.653124 ## role 4.583335 ## roll 4.366405 ## romp 4.017261 ## roof 4.823380 ## rook 3.320628 ## room 4.835116 ## roost 4.536986 ## root 4.706541 ## rope 4.643560 ## rose 4.789394 ## rot 4.377337 ## rouse 2.612718 ## rout 3.415981 ## rove 2.434316 ## rub 4.830873 ## rue 3.793251 ## rug 4.622060 ## rule 4.708297 ## rum 4.476163 ## rump 4.248093 ## run 4.379276 ## rung 3.730126 ## runt 2.820320 ## ruse 3.006440 ## rush 4.709981 ## rust 4.478627 ## rut 3.878840 ## rye 4.274180 ## sack 4.354687 ## sag 4.347097 ## sail 4.739830 ## saint 4.642168 ## sake 4.206845 ## sale 4.417528 ## salt 4.830431 ## salve 4.075024 ## sand 4.662749 ## sap 3.875829 ## sash 3.984147 ## sauce 4.667925 ## save 4.652648 ## saw 4.336322 ## sax 3.418439 ## say 4.423136 ## scald 3.171035 ## scale 4.555877 ## scalp 4.787885 ## scan 4.303330 ## scar 4.381461 ## scare 4.342680 ## scarf 4.410910 ## scene 4.478636 ## scent 4.782674 ## scheme 4.412077 ## school 4.500236 ## scoop 4.442533 ## scope 4.381413 ## score 4.655141 ## scorn 4.350604 ## scotch 4.222965 ## scour 3.953407 ## scourge 4.275937 ## scout 4.275633 ## scrap 4.322831 ## scrape 4.340745 ## scratch 4.390502 ## scream 4.346091 ## screech 3.753671 ## screen 4.394718 ## screw 4.770940 ## scribe 4.302743 ## script 4.828457 ## scrub 4.330043 ## scuff 2.984153 ## sea 4.689873 ## seal 4.389859 ## seam 3.222814 ## sear 3.319565 ## search 4.355479 ## seat 4.571981 ## sect 2.372872 ## see 4.607868 ## seed 4.532446 ## seek 4.828452 ## seem 4.363680 ## seep 3.378635 ## seize 4.699996 ## self 4.828743 ## sell 4.352671 ## send 4.494887 ## sense 4.547584 ## serf 3.641090 ## serge 3.525279 ## serve 4.384181 ## set 5.213376 ## sew 4.488421 ## sex 4.679274 ## shack 4.474131 ## shade 4.607581 ## shaft 4.361455 ## shag 3.857327 ## shah 3.522537 ## shake 4.657487 ## shall 4.263806 ## sham 3.816607 ## shame 4.461457 ## shank 3.293424 ## shape 4.738238 ## shard 3.104279 ## share 4.813552 ## shark 4.779522 ## shave 4.486109 ## shawl 3.853271 ## shay 4.049811 ## sheaf 3.218931 ## shear 4.197872 ## sheath 3.666876 ## shed 4.420592 ## sheen 3.319230 ## sheep 4.502368 ## sheer 4.169931 ## sheet 4.817627 ## shelf 4.665188 ## shell 4.796984 ## shield 4.796795 ## shift 4.496530 ## shin 3.521716 ## shine 4.341052 ## ship 4.693822 ## shirt 4.439208 ## shoal 3.161342 ## shock 4.427135 ## shoe 4.388854 ## shoot 4.582019 ## shop 4.644763 ## shore 4.373601 ## shot 4.389996 ## should 4.761739 ## shout 4.625731 ## shove 4.376115 ## show 4.538950 ## shred 4.336124 ## shrimp 4.524727 ## shrine 3.354268 ## shrink 4.432770 ## shrub 4.346742 ## shrug 3.973296 ## shuck 1.556665 ## shun 3.563145 ## shunt 2.104715 ## shut 4.349149 ## side 4.441788 ## siege 4.234596 ## sigh 4.040942 ## sight 4.447457 ## sign 4.370354 ## silk 4.374011 ## sill 2.303653 ## sin 4.375110 ## sine 2.829561 ## sing 4.774664 ## sink 4.617136 ## sip 4.724650 ## sir 4.272278 ## sit 4.759278 ## site 4.374645 ## size 4.756664 ## skate 4.675037 ## skeet 2.603816 ## sketch 4.389649 ## ski 4.402725 ## skid 4.014076 ## skiff 4.335898 ## skill 4.582817 ## skin 4.342622 ## skip 4.456142 ## skirt 4.395268 ## skit 4.613086 ## skulk 4.304258 ## skull 4.729332 ## skunk 4.262411 ## sky 4.823698 ## slab 3.897558 ## slam 4.404539 ## slang 4.430177 ## slant 4.318782 ## slap 4.493120 ## slash 4.324562 ## slat 3.634181 ## slate 4.126166 ## slave 4.708782 ## sleep 4.455475 ## sleeve 4.727484 ## slice 4.775952 ## slide 4.520688 ## slip 4.830018 ## slit 4.232977 ## slob 4.359407 ## sloe 2.949398 ## sloop 4.026888 ## slop 3.301363 ## slope 4.321913 ## slot 4.456262 ## slouch 4.070016 ## slough 3.483545 ## sludge 2.914095 ## slug 4.337264 ## sluice 2.198928 ## slum 3.758160 ## slump 4.402833 ## smack 4.415883 ## smart 4.586228 ## smash 4.611921 ## smear 4.763148 ## smell 4.834562 ## smelt 2.854917 ## smile 4.771648 ## smirk 4.287183 ## smoke 4.805569 ## snack 4.341739 ## snag 4.511233 ## snail 4.342523 ## snake 4.540464 ## snap 4.612616 ## snare 4.394196 ## snatch 4.365273 ## sneak 4.462835 ## sneer 4.415622 ## sniff 4.340424 ## snip 4.222749 ## snob 4.371394 ## snoop 4.365927 ## snort 4.233134 ## snout 4.052188 ## snow 4.480365 ## snug 4.333866 ## soak 4.746298 ## soap 4.811663 ## sob 4.322264 ## sock 4.403144 ## sod 4.123237 ## sole 4.481123 ## solve 4.351554 ## son 4.351486 ## song 4.584743 ## soot 2.849824 ## soothe 4.081823 ## sop 1.978438 ## sort 4.479961 ## soul 4.757902 ## sound 4.765881 ## soup 4.579549 ## source 4.765987 ## south 3.841391 ## soy 4.203400 ## spa 4.194141 ## space 4.758695 ## spade 4.454674 ## span 4.336751 ## spare 4.273800 ## spark 4.739620 ## spat 4.243039 ## spate 2.642178 ## speak 4.417230 ## spear 4.557647 ## speck 3.326948 ## speech 4.548986 ## speed 4.620166 ## spell 5.204854 ## spend 4.825576 ## sphere 4.357191 ## sphinx 4.319784 ## spice 4.357952 ## spike 4.812873 ## spill 4.826936 ## spin 4.818556 ## spine 4.479733 ## spire 3.800876 ## spit 4.494021 ## spite 4.000695 ## splash 4.589691 ## spleen 2.840740 ## splice 3.393871 ## split 4.593807 ## splurge 3.589676 ## spoil 4.585073 ## spoke 4.788934 ## spoof 3.364560 ## spool 4.815007 ## spoon 4.394165 ## sport 4.557597 ## spot 4.509833 ## spouse 4.434166 ## spout 4.326144 ## sprawl 4.344203 ## spray 4.344747 ## spread 4.380792 ## spree 3.057146 ## sprig 2.740390 ## spring 4.582966 ## sprite 3.333467 ## sprout 4.463541 ## spur 4.346786 ## spurt 3.599750 ## spy 4.523433 ## squad 4.342193 ## squall 3.600676 ## square 4.409035 ## squash 4.364019 ## squat 4.041085 ## squaw 3.138642 ## squawk 3.551130 ## squeak 4.387230 ## squeal 4.345426 ## squeeze 4.443207 ## squint 4.393196 ## squire 3.825493 ## squirm 4.400830 ## squirt 4.349212 ## stab 4.385011 ## stack 4.442110 ## staff 4.727539 ## stag 4.618927 ## stage 4.541125 ## stain 4.343468 ## stair 4.459026 ## stake 4.228019 ## stalk 4.414376 ## stall 4.697795 ## stamp 4.467709 ## stance 4.257876 ## stanch 4.334780 ## stand 4.618315 ## star 4.567397 ## starch 4.521781 ## stare 4.451889 ## start 4.479540 ## starve 4.397043 ## state 4.503575 ## staunch 2.948965 ## stave 3.420096 ## stay 4.775454 ## stead 3.735994 ## steak 4.368333 ## steal 4.739672 ## steam 4.341049 ## steed 3.474292 ## steel 4.424085 ## steer 4.348356 ## stem 4.347498 ## stench 3.523637 ## step 4.823074 ## stew 4.833830 ## stick 4.611781 ## still 4.737914 ## stilt 3.192664 ## sting 4.355519 ## stink 4.394524 ## stint 4.298784 ## stir 4.820379 ## stitch 3.822115 ## stock 4.826967 ## stole 4.740516 ## stone 4.386602 ## stool 4.822633 ## stoop 3.521249 ## stop 4.593229 ## store 4.578264 ## stork 4.415812 ## storm 4.576993 ## stout 4.299688 ## stove 4.513963 ## stow 3.574158 ## strafe 3.538503 ## strain 4.553801 ## strand 4.265074 ## strap 4.358877 ## straw 4.770263 ## stray 4.693557 ## streak 4.448303 ## stream 4.338573 ## street 4.434301 ## stress 4.799725 ## stretch 4.430776 ## stride 4.560066 ## strife 4.033686 ## strike 4.796630 ## string 4.453136 ## strip 4.735648 ## stripe 4.525003 ## strive 4.337228 ## stroke 4.442228 ## stroll 4.353426 ## strut 3.608365 ## stub 4.247484 ## stud 4.530621 ## stuff 4.591115 ## stump 4.482487 ## stunt 4.326607 ## style 4.838429 ## sub 2.407412 ## suck 4.347528 ## sue 4.186830 ## suit 4.533752 ## suite 4.443892 ## sulk 3.616008 ## sum 4.401811 ## sun 4.429307 ## sup 4.330908 ## surf 4.385481 ## surge 4.153779 ## swamp 4.347571 ## swan 4.342409 ## swap 3.925253 ## swarm 4.380212 ## swath 3.168313 ## sway 4.376083 ## swear 4.623988 ## sweat 4.608800 ## sweep 4.383761 ## swell 4.811156 ## swerve 4.333655 ## swig 3.591802 ## swim 4.581021 ## swine 4.406622 ## swing 4.826204 ## swipe 4.364723 ## swirl 4.336687 ## switch 4.452421 ## swoop 3.758159 ## sword 4.760783 ## tab 4.450962 ## tack 4.231918 ## tact 4.630349 ## tag 4.435644 ## tail 4.436022 ## taint 4.365213 ## take 4.751772 ## tale 4.574729 ## talk 4.424548 ## tamp 4.010247 ## tan 4.427122 ## tang 3.580019 ## tank 4.336688 ## tape 4.687344 ## tar 4.621874 ## tart 4.345213 ## task 4.801479 ## taste 4.751141 ## taunt 4.342209 ## tax 4.745334 ## tea 4.802286 ## teach 4.589241 ## teak 4.321418 ## team 4.780031 ## tease 4.628801 ## tech 2.077681 ## tee 4.427536 ## teens 4.336353 ## tell 4.677712 ## tempt 4.691189 ## tend 4.337396 ## tense 4.586275 ## tent 4.797686 ## test 4.650053 ## text 4.764991 ## thank 4.724013 ## thaw 4.378224 ## theft 4.424754 ## theme 4.437978 ## thief 4.413191 ## thigh 4.761594 ## thin 4.552271 ## thing 4.499024 ## think 4.835368 ## thirst 4.818657 ## thong 3.745994 ## thorn 4.837409 ## thought 4.554718 ## thrash 4.279008 ## thread 4.650779 ## threat 4.380702 ## thrift 4.445279 ## thrill 4.436805 ## thrive 4.406335 ## throat 4.828745 ## throne 3.949084 ## throng 2.947647 ## throw 4.416762 ## thrush 3.373254 ## thrust 4.289775 ## thud 3.976672 ## thug 4.325431 ## thumb 4.828406 ## thump 4.328222 ## thwack 1.641269 ## thwart 2.803069 ## tick 4.480504 ## tide 4.724057 ## tie 4.828294 ## tile 4.649943 ## till 3.873158 ## tilt 4.747660 ## time 4.770847 ## tin 4.344017 ## tint 4.461519 ## tip 4.736261 ## tire 4.831420 ## toad 4.731543 ## toast 4.678327 ## toe 4.365516 ## toil 4.376396 ## toll 4.270961 ## tomb 4.827981 ## tome 4.289157 ## ton 4.335022 ## tone 4.621397 ## tongue 4.741392 ## tool 4.815663 ## toot 3.221675 ## tooth 4.582663 ## top 4.611880 ## torch 4.385474 ## torque 4.009826 ## toss 4.707492 ## tote 3.220121 ## touch 4.817059 ## tour 4.689482 ## tout 3.597165 ## town 4.756235 ## toy 4.824570 ## trace 4.680401 ## track 4.667524 ## tract 4.376919 ## trade 4.787484 ## trail 4.348137 ## train 4.775442 ## trait 4.282311 ## tramp 4.265415 ## trance 4.096469 ## trap 4.585343 ## trash 4.430512 ## tray 3.979537 ## tread 4.074591 ## treat 4.630594 ## tree 4.826805 ## trench 4.358456 ## trend 4.413817 ## tribe 4.279867 ## trick 4.409949 ## trill 2.232135 ## trip 4.608044 ## tripe 4.120321 ## troll 3.273823 ## troop 3.981385 ## trot 3.232997 ## trough 2.220459 ## trout 4.662705 ## truce 3.950652 ## truck 4.443968 ## trump 3.557042 ## trunk 4.764736 ## trust 4.566221 ## try 4.706726 ## tryst 2.686733 ## tub 4.664970 ## tube 5.219550 ## tuck 4.285743 ## tug 4.776049 ## tune 4.598102 ## turf 4.115597 ## turn 4.389058 ## tusk 3.842277 ## twain 3.891025 ## tweed 4.438799 ## twin 4.752414 ## twinge 3.070735 ## twist 4.632997 ## twitch 3.896215 ## type 4.394620 ## urge 4.389843 ## urn 3.209286 ## use 4.828042 ## vale 2.179332 ## valve 4.322668 ## vamp 3.061871 ## van 4.340931 ## vase 4.384370 ## vault 4.519298 ## veal 4.279123 ## veer 2.738682 ## veil 4.348929 ## vein 4.408190 ## vent 4.276364 ## verb 4.435039 ## verge 3.830386 ## verse 4.398372 ## verve 3.212260 ## vest 4.028941 ## vet 3.616154 ## vex 4.225010 ## vice 4.158329 ## vie 2.752267 ## view 4.477887 ## vine 4.363609 ## voice 4.782262 ## volt 4.107904 ## vote 4.376126 ## vow 4.250594 ## wad 4.296262 ## wade 4.357879 ## wag 4.366866 ## wage 4.387448 ## wail 4.291355 ## waist 4.371476 ## wait 4.628237 ## waive 4.340034 ## wake 4.382655 ## walk 4.818931 ## wall 4.544967 ## waltz 4.732651 ## wand 3.970937 ## wane 3.561864 ## want 4.542819 ## war 4.789607 ## ward 3.434153 ## ware 4.074173 ## warn 4.464078 ## warp 4.334300 ## wart 4.263456 ## wash 4.465640 ## wasp 4.420953 ## waste 4.811404 ## watch 4.629277 ## watt 4.250001 ## wave 4.391801 ## wax 4.407438 ## way 4.765862 ## wealth 4.374142 ## wear 4.443716 ## weave 4.582525 ## web 4.818011 ## wed 4.747465 ## wedge 4.358044 ## weed 4.547221 ## week 4.436751 ## weep 4.364733 ## weigh 4.494577 ## weight 4.532911 ## weld 3.391234 ## well 4.815435 ## welt 2.887826 ## west 2.722788 ## whack 4.276457 ## wharf 4.455957 ## wheat 4.526881 ## wheel 4.336234 ## whelp 2.145018 ## whiff 3.758377 ## while 4.623052 ## whim 4.359829 ## whine 4.266059 ## whip 4.824901 ## whirl 4.364677 ## whit 3.211245 ## whiz 4.550269 ## whoop 3.303449 ## whoosh 4.063548 ## whore 4.386709 ## whorl 2.581598 ## wick 4.333531 ## wield 3.955273 ## wife 4.825319 ## wig 4.395202 ## will 4.815558 ## wilt 4.233350 ## win 4.387588 ## wine 4.808068 ## wing 4.836245 ## wink 4.609181 ## wipe 4.802099 ## wire 4.824147 ## wish 4.750538 ## wisp 3.200490 ## wit 4.381912 ## witch 4.417556 ## woe 4.431833 ## wolf 4.806339 ## womb 4.357532 ## woo 2.535593 ## wood 4.393244 ## wool 4.273818 ## word 4.624465 ## work 4.722600 ## world 4.770400 ## worm 4.411795 ## would 4.693709 ## wow 4.330731 ## wrack 4.333855 ## wrap 4.521753 ## wrath 4.278108 ## wreak 4.085787 ## wreath 4.210373 ## wreck 4.525213 ## wren 3.209533 ## wrest 4.281980 ## wretch 4.344768 ## wring 2.213803 ## wrist 4.712999 ## writ 2.072069 ## write 4.533056 ## writhe 3.953297 ## yacht 3.720713 ## yak 1.642999 ## yam 4.315183 ## yang 1.642938 ## yank 3.338789 ## yard 4.469573 ## yarn 4.455277 ## yaw 2.801254 ## yawl 2.730185 ## yawn 4.448734 ## yea 3.973433 ## year 4.515455 ## yearn 3.910330 ## yeast 4.502918 ## yell 4.417110 ## yelp 3.409412 ## yen 2.954283 ## yes 4.832446 ## yield 4.821044 ## yoke 4.480565 ## yolk 4.265757 ## yore 3.005145 ## youth 4.628253 ## zeal 4.141043 ## zest 4.107503 ## zinc 3.835348 ## zing 2.591726 ## zip 4.528172 ## zone 4.630769 ## zoo 4.326536 4.4.2.4.4 Plotting 4.4.2.4.4.1 Normal english2 &lt;- english2 %&gt;% mutate(prob3 = predict(mdl.glmmSlope3, type = &quot;response&quot;)) english2 %&gt;% ggplot(aes(x = as.numeric(AgeSubject), y = prob3)) + geom_point() + geom_smooth(method = &quot;glm&quot;, method.args = list(family = &quot;binomial&quot;), se = T) + theme_bw(base_size = 20)+ labs(y = &quot;Probability&quot;, x = &quot;&quot;)+ coord_cartesian(ylim = c(0,1))+ scale_x_discrete(limits = c(&quot;Young&quot;, &quot;Old&quot;)) We obtain the exact same plots, but the model estimations are different. Let’s use another type of predictions 4.4.2.4.4.2 z-scores z_vals &lt;- seq(-3, 3, 0.01) n = nrow(english2) dfPredNew &lt;- data.frame(RTlexdec_z = z_vals) ### store the predicted probabilities for each value of RTlexdec_z pp &lt;- cbind(dfPredNew, prob = predict(mdl.glmmSlope3, newdata = dfPredNew, type = &quot;response&quot;, re.form = NA))#re.form is used to cancel random effects pp %&gt;% ggplot(aes(x = RTlexdec_z, y = prob)) + geom_point() + theme_bw(base_size = 20)+ labs(y = &quot;Probability&quot;, x = &quot;&quot;)+ coord_cartesian(ylim = c(-0.1, 1.1), expand = FALSE) + scale_y_discrete(limits = c(0,1), labels = c(&quot;Young&quot;, &quot;Old&quot;)) + scale_x_continuous(breaks = c(-3, -2, -1, 0, 1, 2, 3)) + annotate(&quot;rect&quot;, xmin = -0.5, xmax = 0.5, ymin = -Inf, ymax = Inf, show.legend = FALSE, alpha=0.15) We obtain the exact same plots, but the model estimations are different. "],["4.5-cumulative-logit-link-mixed-effects-models.html", "4.5 Cumulative Logit Link Mixed-effects Models", " 4.5 Cumulative Logit Link Mixed-effects Models These models work perfectly with rating data. Ratings are inherently ordered, 1, 2, … n, and expect to observe an increase (or decrease) in overall ratings from 1 to n. To demonstrate this, we will use an example using the package “ordinal”. We use two datasets. We previously ran these two models, however, in this subset of the full dataset, we did not take into account the fact that there were multiple producing speakers and items. 4.5.1 Ratings of percept of nasality The first comes from a likert-scale a rating experiment where six participants rated the percept of nasality in the production of particular consonants in Arabic. The data came from nine producing subjects. The ratings were from 1 to 5, with 1 reflecting an oral percept; 5 a nasal percept. 4.5.1.1 Importing and pre-processing We start by importing the data and process it. We change the reference level in the predictor rating &lt;- read_csv(&quot;data/rating.csv&quot;)[-1] rating ## # A tibble: 405 × 5 ## Response Context Subject Item Rater ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2 n-3 p04 noo3-w R01 ## 2 4 isolation p04 noo3-v R01 ## 3 2 o-3 p04 djuu3-w R01 ## 4 4 isolation p04 djuu3-v R01 ## 5 3 n-7 p04 nuu7-w R01 ## 6 3 isolation p04 nuu7-v R01 ## 7 1 3--3 p04 3oo3-w R01 ## 8 2 isolation p04 3oo3-v R01 ## 9 2 o-7 p04 loo7-w R01 ## 10 1 o-3 p04 bii3-w R01 ## # ℹ 395 more rows rating &lt;- rating %&gt;% mutate(Response = factor(Response), Context = factor(Context), Subject = factor(Subject), Item = factor(Item)) %&gt;% mutate(Context = relevel(Context, &quot;isolation&quot;)) rating %&gt;% head(10) ## # A tibble: 10 × 5 ## Response Context Subject Item Rater ## &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; ## 1 2 n-3 p04 noo3-w R01 ## 2 4 isolation p04 noo3-v R01 ## 3 2 o-3 p04 djuu3-w R01 ## 4 4 isolation p04 djuu3-v R01 ## 5 3 n-7 p04 nuu7-w R01 ## 6 3 isolation p04 nuu7-v R01 ## 7 1 3--3 p04 3oo3-w R01 ## 8 2 isolation p04 3oo3-v R01 ## 9 2 o-7 p04 loo7-w R01 ## 10 1 o-3 p04 bii3-w R01 4.5.1.2 Model specifications 4.5.1.2.1 No random effects We run our first clm model as a simple, i.e., with no random effects system.time(mdl.clm &lt;- rating %&gt;% clm(Response ~ Context, data = .)) ## user system elapsed ## 0.02 0.01 0.01 summary(mdl.clm) ## formula: Response ~ Context ## data: . ## ## link threshold nobs logLik AIC niter max.grad cond.H ## logit flexible 405 -526.16 1086.31 5(0) 3.61e-09 1.3e+02 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## Context3--3 -0.1384 0.5848 -0.237 0.8130 ## Context3-n 3.5876 0.4721 7.600 2.96e-14 *** ## Context3-o -0.4977 0.3859 -1.290 0.1971 ## Context7-n 2.3271 0.5079 4.582 4.60e-06 *** ## Context7-o 0.2904 0.4002 0.726 0.4680 ## Contextn-3 2.8957 0.6685 4.331 1.48e-05 *** ## Contextn-7 2.2678 0.4978 4.556 5.22e-06 *** ## Contextn-n 2.8697 0.4317 6.647 2.99e-11 *** ## Contextn-o 3.5152 0.4397 7.994 1.30e-15 *** ## Contexto-3 -0.2540 0.4017 -0.632 0.5272 ## Contexto-7 -0.6978 0.3769 -1.851 0.0641 . ## Contexto-n 2.9640 0.4159 7.126 1.03e-12 *** ## Contexto-o -0.6147 0.3934 -1.562 0.1182 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Threshold coefficients: ## Estimate Std. Error z value ## 1|2 -1.4615 0.2065 -7.077 ## 2|3 0.4843 0.1824 2.655 ## 3|4 1.5492 0.2044 7.578 ## 4|5 3.1817 0.2632 12.089 4.5.1.2.2 Random effects 1 - Intercepts only We run our first clmm model as a simple, i.e., with random intercepts system.time(mdl.clmm.Int &lt;- rating %&gt;% clmm(Response ~ Context + (1|Subject) + (1|Item), data = .)) ## user system elapsed ## 3.89 0.14 4.10 summary(mdl.clmm.Int) ## Cumulative Link Mixed Model fitted with the Laplace approximation ## ## formula: Response ~ Context + (1 | Subject) + (1 | Item) ## data: . ## ## link threshold nobs logLik AIC niter max.grad cond.H ## logit flexible 405 -520.89 1079.79 1395(2832) 7.26e-04 1.2e+02 ## ## Random effects: ## Groups Name Variance Std.Dev. ## Item (Intercept) 1.272e-14 1.128e-07 ## Subject (Intercept) 1.942e-01 4.407e-01 ## Number of groups: Item 45, Subject 9 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## Context3--3 -0.1634 0.5798 -0.282 0.7781 ## Context3-n 3.6779 0.4804 7.657 1.91e-14 *** ## Context3-o -0.5156 0.3873 -1.331 0.1831 ## Context7-n 2.3775 0.5185 4.585 4.54e-06 *** ## Context7-o 0.3279 0.4046 0.810 0.4177 ## Contextn-3 3.0361 0.6677 4.547 5.43e-06 *** ## Contextn-7 2.3599 0.4925 4.792 1.65e-06 *** ## Contextn-n 2.9633 0.4339 6.830 8.52e-12 *** ## Contextn-o 3.6644 0.4495 8.153 3.56e-16 *** ## Contexto-3 -0.2772 0.4000 -0.693 0.4883 ## Contexto-7 -0.7334 0.3800 -1.930 0.0536 . ## Contexto-n 3.0672 0.4220 7.268 3.65e-13 *** ## Contexto-o -0.6505 0.4015 -1.620 0.1052 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Threshold coefficients: ## Estimate Std. Error z value ## 1|2 -1.5141 0.2554 -5.928 ## 2|3 0.5077 0.2358 2.153 ## 3|4 1.6039 0.2538 6.319 ## 4|5 3.2921 0.3072 10.718 4.5.1.2.3 Random effects 2 - Intercepts and Slopes We run our second clmm model as a simple, i.e., with random intercepts and random slopes. Because the model will run for a while, we added an if condition to say f the model was run previously, simply load the rds file rather than running it. system.time(mdl.clmm.Slope &lt;- rating %&gt;% clmm(Response ~ Context + (Context|Subject) + (1|Item), data = .)) ## user system elapsed ## 827.75 29.52 861.15 summary(mdl.clmm.Slope) ## Cumulative Link Mixed Model fitted with the Laplace approximation ## ## formula: Response ~ Context + (Context | Subject) + (1 | Item) ## data: . ## ## link threshold nobs logLik AIC niter max.grad cond.H ## logit flexible 405 -492.53 1231.05 55305(218422) 8.87e-02 1.5e+04 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## Item (Intercept) 0.05939 0.2437 ## Subject (Intercept) 0.70845 0.8417 ## Context3--3 2.34447 1.5312 -0.755 ## Context3-n 4.43319 2.1055 -0.258 0.654 ## Context3-o 1.37733 1.1736 -0.677 0.985 0.649 ## Context7-n 4.33218 2.0814 -0.544 0.729 0.389 0.709 ## Context7-o 1.55843 1.2484 -0.809 0.740 0.068 0.682 0.431 ## Contextn-3 7.99273 2.8271 -0.251 0.725 0.807 0.773 0.204 ## Contextn-7 4.87737 2.2085 -0.276 0.563 0.516 0.553 -0.090 ## Contextn-n 3.60679 1.8992 -0.659 0.924 0.662 0.916 0.420 ## Contextn-o 2.26056 1.5035 -0.730 0.633 0.022 0.615 0.141 ## Contexto-3 1.00547 1.0027 -0.159 0.484 0.443 0.513 -0.189 ## Contexto-7 1.48508 1.2186 -0.889 0.738 0.196 0.637 0.456 ## Contexto-n 2.76687 1.6634 -0.874 0.871 0.398 0.787 0.578 ## Contexto-o 1.78059 1.3344 -0.883 0.645 0.300 0.547 0.739 ## ## ## ## ## ## ## ## ## 0.336 ## 0.547 0.824 ## 0.744 0.867 0.825 ## 0.915 0.429 0.639 0.747 ## 0.457 0.840 0.969 0.771 0.626 ## 0.946 0.290 0.511 0.721 0.811 0.359 ## 0.919 0.469 0.581 0.837 0.769 0.434 0.970 ## 0.561 0.031 -0.057 0.411 0.345 -0.221 0.723 0.733 ## Number of groups: Item 45, Subject 9 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## Context3--3 -0.2625 0.8280 -0.317 0.75120 ## Context3-n 4.6025 0.9754 4.718 2.38e-06 *** ## Context3-o -0.5739 0.5821 -0.986 0.32413 ## Context7-n 2.5260 0.9164 2.756 0.00584 ** ## Context7-o 0.3748 0.6183 0.606 0.54433 ## Contextn-3 4.1834 1.4119 2.963 0.00305 ** ## Contextn-7 2.9393 0.9457 3.108 0.00188 ** ## Contextn-n 3.5724 0.8166 4.375 1.21e-05 *** ## Contextn-o 4.4321 0.7515 5.898 3.69e-09 *** ## Contexto-3 -0.3567 0.5562 -0.641 0.52138 ## Contexto-7 -0.8254 0.5861 -1.408 0.15905 ## Contexto-n 3.6329 0.7410 4.903 9.44e-07 *** ## Contexto-o -0.6508 0.6248 -1.042 0.29755 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Threshold coefficients: ## Estimate Std. Error z value ## 1|2 -1.7147 0.3662 -4.682 ## 2|3 0.5701 0.3481 1.638 ## 3|4 1.8427 0.3666 5.026 ## 4|5 3.9828 0.4399 9.054 4.5.1.3 Testing significance We can evaluate whether “Context” improves the model fit, by comparing a null model with our model. Of course “Context” is improving the model fit. mdl.clm.Null &lt;- rating %&gt;% clm(Response ~ 1, data = .) 4.5.1.3.1 Null vs no random anova(mdl.clm, mdl.clm.Null) ## Likelihood ratio tests of cumulative link models: ## ## formula: link: threshold: ## mdl.clm.Null Response ~ 1 logit flexible ## mdl.clm Response ~ Context logit flexible ## ## no.par AIC logLik LR.stat df Pr(&gt;Chisq) ## mdl.clm.Null 4 1281.1 -636.56 ## mdl.clm 17 1086.3 -526.16 220.8 13 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 4.5.1.3.2 No random vs Random Intercepts anova(mdl.clm, mdl.clmm.Int) ## Likelihood ratio tests of cumulative link models: ## ## formula: link: threshold: ## mdl.clm Response ~ Context logit flexible ## mdl.clmm.Int Response ~ Context + (1 | Subject) + (1 | Item) logit flexible ## ## no.par AIC logLik LR.stat df Pr(&gt;Chisq) ## mdl.clm 17 1086.3 -526.16 ## mdl.clmm.Int 19 1079.8 -520.89 10.525 2 0.005182 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 4.5.1.3.3 No random vs Random Intercepts anova(mdl.clmm.Int, mdl.clmm.Slope) ## Likelihood ratio tests of cumulative link models: ## ## formula: link: ## mdl.clmm.Int Response ~ Context + (1 | Subject) + (1 | Item) logit ## mdl.clmm.Slope Response ~ Context + (Context | Subject) + (1 | Item) logit ## threshold: ## mdl.clmm.Int flexible ## mdl.clmm.Slope flexible ## ## no.par AIC logLik LR.stat df Pr(&gt;Chisq) ## mdl.clmm.Int 19 1079.8 -520.89 ## mdl.clmm.Slope 123 1231.1 -492.53 56.737 104 1 The model comparison above shows that using random intercepts is enough in our case. By subject Random Slopes are not needed; subjects “seem” to show similarities in how they produced the items. In our publication, by Rater Random Slopes for context were needed. 4.5.1.4 Model’s fit print(tab_model(mdl.clmm.Int, file = paste0(&quot;outputs/mdl.clmm.Int.html&quot;))) webshot(paste0(&quot;outputs/mdl.clmm.Int.html&quot;), paste0(&quot;outputs/mdl.clmm.Int.png&quot;)) Model fit: Cumulative Logit Mixed effects model 4.5.1.5 Interpreting a cumulative model As a way to interpret the model, we can look at the coefficients and make sense of the results. A CLM model is a Logistic model with a cumulative effect. The “Coefficients” are the estimates for each level of the fixed effect; the “Threshold coefficients” are those of the response. For the former, a negative coefficient indicates a negative association with the response; and a positive is positively associated with the response. The p values are indicating the significance of each level. For the “Threshold coefficients”, we can see the cumulative effects of ratings 1|2, 2|3, 3|4 and 4|5 which indicate an overall increase in the ratings from 1 to 5. 4.5.1.6 Plotting 4.5.1.6.1 No confidence intervals We use a modified version of a plotting function that allows us to visualise the effects. For this, we use the base R plotting functions. The version below is without confidence intervals. par(oma=c(1, 0, 0, 3),mgp=c(2, 1, 0)) xlimNas = c(min(mdl.clmm.Int$beta), max(mdl.clmm.Int$beta)) ylimNas = c(0,1) plot(0,0,xlim=xlimNas, ylim=ylimNas, type=&quot;n&quot;, ylab=expression(Probability), xlab=&quot;&quot;, xaxt = &quot;n&quot;,main=&quot;Predicted curves - Nasalisation&quot;,cex=2,cex.lab=1.5,cex.main=1.5,cex.axis=1.5) axis(side = 1, at = c(0,mdl.clmm.Int$beta),labels = levels(rating$Context), las=2,cex=2,cex.lab=1.5,cex.axis=1.5) xsNas = seq(xlimNas[1], xlimNas[2], length.out=100) lines(xsNas, plogis(mdl.clmm.Int$Theta[1] - xsNas), col=&#39;black&#39;) lines(xsNas, plogis(mdl.clmm.Int$Theta[2] - xsNas)-plogis(mdl.clmm.Int$Theta[1] - xsNas), col=&#39;red&#39;) lines(xsNas, plogis(mdl.clmm.Int$Theta[3] - xsNas)-plogis(mdl.clmm.Int$Theta[2] - xsNas), col=&#39;green&#39;) lines(xsNas, plogis(mdl.clmm.Int$Theta[4] - xsNas)-plogis(mdl.clmm.Int$Theta[3] - xsNas), col=&#39;orange&#39;) lines(xsNas, 1-(plogis(mdl.clmm.Int$Theta[4] - xsNas)), col=&#39;blue&#39;) abline(v=c(0,mdl.clmm.Int$beta),lty=3) abline(h=0, lty=&quot;dashed&quot;) abline(h=0.2, lty=&quot;dashed&quot;) abline(h=0.4, lty=&quot;dashed&quot;) abline(h=0.6, lty=&quot;dashed&quot;) abline(h=0.8, lty=&quot;dashed&quot;) abline(h=1, lty=&quot;dashed&quot;) legend(par(&#39;usr&#39;)[2], par(&#39;usr&#39;)[4], bty=&#39;n&#39;, xpd=NA,lty=1, col=c(&quot;black&quot;, &quot;red&quot;, &quot;green&quot;, &quot;orange&quot;, &quot;blue&quot;), legend=c(&quot;Oral&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;Nasal&quot;),cex=0.75) 4.5.1.6.2 With confidence intervals Here is an attempt to add the 97.5% confidence intervals to these plots. This is an experimental attempt and any feedback is welcome! par(oma=c(1, 0, 0, 3),mgp=c(2, 1, 0)) xlimNas = c(min(mdl.clmm.Int$beta), max(mdl.clmm.Int$beta)) ylimNas = c(0,1) plot(0,0,xlim=xlimNas, ylim=ylimNas, type=&quot;n&quot;, ylab=expression(Probability), xlab=&quot;&quot;, xaxt = &quot;n&quot;,main=&quot;Predicted curves - Nasalisation&quot;,cex=2,cex.lab=1.5,cex.main=1.5,cex.axis=1.5) axis(side = 1, at = c(0,mdl.clmm.Int$beta),labels = levels(rating$Context), las=2,cex=2,cex.lab=1.5,cex.axis=1.5) xsNas = seq(xlimNas[1], xlimNas[2], length.out=100) #+CI lines(xsNas, plogis(mdl.clmm.Int$Theta[1]+(summary(mdl.clmm.Int)$coefficient[,2][[1]]/1.96) - xsNas), col=&#39;black&#39;) lines(xsNas, plogis(mdl.clmm.Int$Theta[2]+(summary(mdl.clmm.Int)$coefficient[,2][[2]]/1.96) - xsNas)-plogis(mdl.clmm.Int$Theta[1]+(summary(mdl.clmm.Int)$coefficient[,2][[1]]/1.96) - xsNas), col=&#39;red&#39;) lines(xsNas, plogis(mdl.clmm.Int$Theta[3]+(summary(mdl.clmm.Int)$coefficient[,2][[3]]/1.96) - xsNas)-plogis(mdl.clmm.Int$Theta[2]+(summary(mdl.clmm.Int)$coefficient[,2][[2]]/1.96) - xsNas), col=&#39;green&#39;) lines(xsNas, plogis(mdl.clmm.Int$Theta[4]+(summary(mdl.clmm.Int)$coefficient[,2][[4]]/1.96) - xsNas)-plogis(mdl.clmm.Int$Theta[3]+(summary(mdl.clmm.Int)$coefficient[,2][[3]]/1.96) - xsNas), col=&#39;orange&#39;) lines(xsNas, 1-(plogis(mdl.clmm.Int$Theta[4]+(summary(mdl.clmm.Int)$coefficient[,2][[4]]/1.96) - xsNas)), col=&#39;blue&#39;) #-CI lines(xsNas, plogis(mdl.clmm.Int$Theta[1]-(summary(mdl.clmm.Int)$coefficient[,2][[1]]/1.96) - xsNas), col=&#39;black&#39;) lines(xsNas, plogis(mdl.clmm.Int$Theta[2]-(summary(mdl.clmm.Int)$coefficient[,2][[2]]/1.96) - xsNas)-plogis(mdl.clmm.Int$Theta[1]-(summary(mdl.clmm.Int)$coefficient[,2][[1]]/1.96) - xsNas), col=&#39;red&#39;) lines(xsNas, plogis(mdl.clmm.Int$Theta[3]-(summary(mdl.clmm.Int)$coefficient[,2][[3]]/1.96) - xsNas)-plogis(mdl.clmm.Int$Theta[2]-(summary(mdl.clmm.Int)$coefficient[,2][[2]]/1.96) - xsNas), col=&#39;green&#39;) lines(xsNas, plogis(mdl.clmm.Int$Theta[4]-(summary(mdl.clmm.Int)$coefficient[,2][[4]]/1.96) - xsNas)-plogis(mdl.clmm.Int$Theta[3]-(summary(mdl.clmm.Int)$coefficient[,2][[3]]/1.96) - xsNas), col=&#39;orange&#39;) lines(xsNas, 1-(plogis(mdl.clmm.Int$Theta[4]-(summary(mdl.clmm.Int)$coefficient[,2][[4]]/1.96) - xsNas)), col=&#39;blue&#39;) ## fill area around CI using c(x, rev(x)), c(y2, rev(y1)) polygon(c(xsNas, rev(xsNas)), c(plogis(mdl.clmm.Int$Theta[1]+(summary(mdl.clmm.Int)$coefficient[,2][[1]]/1.96) - xsNas), rev(plogis(mdl.clmm.Int$Theta[1]-(summary(mdl.clmm.Int)$coefficient[,2][[1]]/1.96) - xsNas))), col = &quot;gray90&quot;) polygon(c(xsNas, rev(xsNas)), c(plogis(mdl.clmm.Int$Theta[2]+(summary(mdl.clmm.Int)$coefficient[,2][[2]]/1.96) - xsNas)-plogis(mdl.clmm.Int$Theta[1]+(summary(mdl.clmm.Int)$coefficient[,2][[1]]/1.96) - xsNas), rev(plogis(mdl.clmm.Int$Theta[2]-(summary(mdl.clmm.Int)$coefficient[,2][[2]]/1.96) - xsNas)-plogis(mdl.clmm.Int$Theta[1]-(summary(mdl.clmm.Int)$coefficient[,2][[1]]/1.96) - xsNas))), col = &quot;gray90&quot;) polygon(c(xsNas, rev(xsNas)), c(plogis(mdl.clmm.Int$Theta[3]+(summary(mdl.clmm.Int)$coefficient[,2][[3]]/1.96) - xsNas)-plogis(mdl.clmm.Int$Theta[2]+(summary(mdl.clmm.Int)$coefficient[,2][[2]]/1.96) - xsNas), rev(plogis(mdl.clmm.Int$Theta[3]-(summary(mdl.clmm.Int)$coefficient[,2][[3]]/1.96) - xsNas)-plogis(mdl.clmm.Int$Theta[2]-(summary(mdl.clmm.Int)$coefficient[,2][[2]]/1.96) - xsNas))), col = &quot;gray90&quot;) polygon(c(xsNas, rev(xsNas)), c(plogis(mdl.clmm.Int$Theta[4]+(summary(mdl.clmm.Int)$coefficient[,2][[4]]/1.96) - xsNas)-plogis(mdl.clmm.Int$Theta[3]+(summary(mdl.clmm.Int)$coefficient[,2][[3]]/1.96) - xsNas), rev(plogis(mdl.clmm.Int$Theta[4]-(summary(mdl.clmm.Int)$coefficient[,2][[4]]/1.96) - xsNas)-plogis(mdl.clmm.Int$Theta[3]-(summary(mdl.clmm.Int)$coefficient[,2][[3]]/1.96) - xsNas))), col = &quot;gray90&quot;) polygon(c(xsNas, rev(xsNas)), c(1-(plogis(mdl.clmm.Int$Theta[4]-(summary(mdl.clmm.Int)$coefficient[,2][[4]]/1.96) - xsNas)), rev(1-(plogis(mdl.clmm.Int$Theta[4]+(summary(mdl.clmm.Int)$coefficient[,2][[4]]/1.96) - xsNas)))), col = &quot;gray90&quot;) lines(xsNas, plogis(mdl.clmm.Int$Theta[1] - xsNas), col=&#39;black&#39;) lines(xsNas, plogis(mdl.clmm.Int$Theta[2] - xsNas)-plogis(mdl.clmm.Int$Theta[1] - xsNas), col=&#39;red&#39;) lines(xsNas, plogis(mdl.clmm.Int$Theta[3] - xsNas)-plogis(mdl.clmm.Int$Theta[2] - xsNas), col=&#39;green&#39;) lines(xsNas, plogis(mdl.clmm.Int$Theta[4] - xsNas)-plogis(mdl.clmm.Int$Theta[3] - xsNas), col=&#39;orange&#39;) lines(xsNas, 1-(plogis(mdl.clmm.Int$Theta[4] - xsNas)), col=&#39;blue&#39;) abline(v=c(0,mdl.clmm.Int$beta),lty=3) abline(h=0, lty=&quot;dashed&quot;) abline(h=0.2, lty=&quot;dashed&quot;) abline(h=0.4, lty=&quot;dashed&quot;) abline(h=0.6, lty=&quot;dashed&quot;) abline(h=0.8, lty=&quot;dashed&quot;) abline(h=1, lty=&quot;dashed&quot;) legend(par(&#39;usr&#39;)[2], par(&#39;usr&#39;)[4], bty=&#39;n&#39;, xpd=NA,lty=1, col=c(&quot;black&quot;, &quot;red&quot;, &quot;green&quot;, &quot;orange&quot;, &quot;blue&quot;), legend=c(&quot;Oral&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;Nasal&quot;),cex=0.75) Check if the results are different between our initial model (with clm) and our new model (with clmm). 4.5.2 Subjective estimates of the weight of the referents of 81 English nouns. This dataset comes from the LanguageR package. It contains the subjective estimates of the weight of the referents of 81 English nouns. This dataset is a little complex. Data comes from multiple subjects who rated 81 nouns. The nouns are from a a class of animals and plants. The subjects are either males or females. We can model it in various ways. Here we decided to explore whether the ratings given to a particular word are different, when the class is either animal or a plant and if males rated the nouns differently from males. We will only use subject as a random effect. We also model the contribution of frequency. 4.5.2.1 Importing and pre-processing weightRatings &lt;- weightRatings %&gt;% mutate(Rating = factor(Rating), Subject = factor(Subject), Sex = factor(Sex), Word = factor(Word), Class = factor(Class)) weightRatings %&gt;% head(10) ## Subject Rating Trial Sex Word Frequency Class ## 1 A1 5 1 F horse 7.771910 animal ## 2 A1 1 2 F gherkin 2.079442 plant ## 3 A1 3 3 F hedgehog 3.637586 animal ## 4 A1 1 4 F bee 5.700444 animal ## 5 A1 1 5 F peanut 4.595120 plant ## 6 A1 2 6 F pear 4.727388 plant ## 7 A1 3 7 F pineapple 3.988984 plant ## 8 A1 2 8 F frog 5.129899 animal ## 9 A1 1 9 F blackberry 4.060443 plant ## 10 A1 3 10 F pigeon 5.262690 animal 4.5.2.2 Model specifications 4.5.2.2.1 No random effects We run our first clm model as a simple, i.e., with no random effects system.time(mdl.clm.1 &lt;- weightRatings %&gt;% clm(Rating ~ Class * Sex * Frequency, data = .)) ## user system elapsed ## 0.07 0.04 0.04 summary(mdl.clm) ## formula: Response ~ Context ## data: . ## ## link threshold nobs logLik AIC niter max.grad cond.H ## logit flexible 405 -526.16 1086.31 5(0) 3.61e-09 1.3e+02 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## Context3--3 -0.1384 0.5848 -0.237 0.8130 ## Context3-n 3.5876 0.4721 7.600 2.96e-14 *** ## Context3-o -0.4977 0.3859 -1.290 0.1971 ## Context7-n 2.3271 0.5079 4.582 4.60e-06 *** ## Context7-o 0.2904 0.4002 0.726 0.4680 ## Contextn-3 2.8957 0.6685 4.331 1.48e-05 *** ## Contextn-7 2.2678 0.4978 4.556 5.22e-06 *** ## Contextn-n 2.8697 0.4317 6.647 2.99e-11 *** ## Contextn-o 3.5152 0.4397 7.994 1.30e-15 *** ## Contexto-3 -0.2540 0.4017 -0.632 0.5272 ## Contexto-7 -0.6978 0.3769 -1.851 0.0641 . ## Contexto-n 2.9640 0.4159 7.126 1.03e-12 *** ## Contexto-o -0.6147 0.3934 -1.562 0.1182 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Threshold coefficients: ## Estimate Std. Error z value ## 1|2 -1.4615 0.2065 -7.077 ## 2|3 0.4843 0.1824 2.655 ## 3|4 1.5492 0.2044 7.578 ## 4|5 3.1817 0.2632 12.089 4.5.2.2.2 Random effects 1 - Intercepts only We run our first model as a simple, i.e., with random intercepts system.time(mdl.clmm.Int.1 &lt;- weightRatings %&gt;% clmm(Rating ~ Class * Sex * Frequency + (1|Subject:Word), data = .)) ## user system elapsed ## 14.36 0.19 14.36 summary(mdl.clmm.Int) ## Cumulative Link Mixed Model fitted with the Laplace approximation ## ## formula: Response ~ Context + (1 | Subject) + (1 | Item) ## data: . ## ## link threshold nobs logLik AIC niter max.grad cond.H ## logit flexible 405 -520.89 1079.79 1395(2832) 7.26e-04 1.2e+02 ## ## Random effects: ## Groups Name Variance Std.Dev. ## Item (Intercept) 1.272e-14 1.128e-07 ## Subject (Intercept) 1.942e-01 4.407e-01 ## Number of groups: Item 45, Subject 9 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## Context3--3 -0.1634 0.5798 -0.282 0.7781 ## Context3-n 3.6779 0.4804 7.657 1.91e-14 *** ## Context3-o -0.5156 0.3873 -1.331 0.1831 ## Context7-n 2.3775 0.5185 4.585 4.54e-06 *** ## Context7-o 0.3279 0.4046 0.810 0.4177 ## Contextn-3 3.0361 0.6677 4.547 5.43e-06 *** ## Contextn-7 2.3599 0.4925 4.792 1.65e-06 *** ## Contextn-n 2.9633 0.4339 6.830 8.52e-12 *** ## Contextn-o 3.6644 0.4495 8.153 3.56e-16 *** ## Contexto-3 -0.2772 0.4000 -0.693 0.4883 ## Contexto-7 -0.7334 0.3800 -1.930 0.0536 . ## Contexto-n 3.0672 0.4220 7.268 3.65e-13 *** ## Contexto-o -0.6505 0.4015 -1.620 0.1052 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Threshold coefficients: ## Estimate Std. Error z value ## 1|2 -1.5141 0.2554 -5.928 ## 2|3 0.5077 0.2358 2.153 ## 3|4 1.6039 0.2538 6.319 ## 4|5 3.2921 0.3072 10.718 4.5.2.2.3 Random effects 2 - Intercepts and Slopes We run our second model as a simple, i.e., with random intercepts and random slopes for subject by class. system.time(mdl.clmm.Slope.1 &lt;- weightRatings %&gt;% clmm(Rating ~ Class * Sex * Frequency + (Class|Subject:Word), data = .)) ## user system elapsed ## 32.11 0.76 33.07 summary(mdl.clmm.Slope) ## Cumulative Link Mixed Model fitted with the Laplace approximation ## ## formula: Response ~ Context + (Context | Subject) + (1 | Item) ## data: . ## ## link threshold nobs logLik AIC niter max.grad cond.H ## logit flexible 405 -492.53 1231.05 55305(218422) 8.87e-02 1.5e+04 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## Item (Intercept) 0.05939 0.2437 ## Subject (Intercept) 0.70845 0.8417 ## Context3--3 2.34447 1.5312 -0.755 ## Context3-n 4.43319 2.1055 -0.258 0.654 ## Context3-o 1.37733 1.1736 -0.677 0.985 0.649 ## Context7-n 4.33218 2.0814 -0.544 0.729 0.389 0.709 ## Context7-o 1.55843 1.2484 -0.809 0.740 0.068 0.682 0.431 ## Contextn-3 7.99273 2.8271 -0.251 0.725 0.807 0.773 0.204 ## Contextn-7 4.87737 2.2085 -0.276 0.563 0.516 0.553 -0.090 ## Contextn-n 3.60679 1.8992 -0.659 0.924 0.662 0.916 0.420 ## Contextn-o 2.26056 1.5035 -0.730 0.633 0.022 0.615 0.141 ## Contexto-3 1.00547 1.0027 -0.159 0.484 0.443 0.513 -0.189 ## Contexto-7 1.48508 1.2186 -0.889 0.738 0.196 0.637 0.456 ## Contexto-n 2.76687 1.6634 -0.874 0.871 0.398 0.787 0.578 ## Contexto-o 1.78059 1.3344 -0.883 0.645 0.300 0.547 0.739 ## ## ## ## ## ## ## ## ## 0.336 ## 0.547 0.824 ## 0.744 0.867 0.825 ## 0.915 0.429 0.639 0.747 ## 0.457 0.840 0.969 0.771 0.626 ## 0.946 0.290 0.511 0.721 0.811 0.359 ## 0.919 0.469 0.581 0.837 0.769 0.434 0.970 ## 0.561 0.031 -0.057 0.411 0.345 -0.221 0.723 0.733 ## Number of groups: Item 45, Subject 9 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## Context3--3 -0.2625 0.8280 -0.317 0.75120 ## Context3-n 4.6025 0.9754 4.718 2.38e-06 *** ## Context3-o -0.5739 0.5821 -0.986 0.32413 ## Context7-n 2.5260 0.9164 2.756 0.00584 ** ## Context7-o 0.3748 0.6183 0.606 0.54433 ## Contextn-3 4.1834 1.4119 2.963 0.00305 ** ## Contextn-7 2.9393 0.9457 3.108 0.00188 ** ## Contextn-n 3.5724 0.8166 4.375 1.21e-05 *** ## Contextn-o 4.4321 0.7515 5.898 3.69e-09 *** ## Contexto-3 -0.3567 0.5562 -0.641 0.52138 ## Contexto-7 -0.8254 0.5861 -1.408 0.15905 ## Contexto-n 3.6329 0.7410 4.903 9.44e-07 *** ## Contexto-o -0.6508 0.6248 -1.042 0.29755 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Threshold coefficients: ## Estimate Std. Error z value ## 1|2 -1.7147 0.3662 -4.682 ## 2|3 0.5701 0.3481 1.638 ## 3|4 1.8427 0.3666 5.026 ## 4|5 3.9828 0.4399 9.054 4.5.2.3 Testing significance We can evaluate whether “Context” improves the model fit, by comparing a null model with our model. Of course “Context” is improving the model fit. mdl.clm.Null.1 &lt;- weightRatings %&gt;% clm(Rating ~ 1, data = .) 4.5.2.3.1 Null vs no random anova(mdl.clm.1, mdl.clm.Null.1) ## Likelihood ratio tests of cumulative link models: ## ## formula: link: threshold: ## mdl.clm.Null.1 Rating ~ 1 logit flexible ## mdl.clm.1 Rating ~ Class * Sex * Frequency logit flexible ## ## no.par AIC logLik LR.stat df Pr(&gt;Chisq) ## mdl.clm.Null.1 6 5430.2 -2709.1 ## mdl.clm.1 13 4800.2 -2387.1 644.05 7 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 4.5.2.3.2 No random vs Random Intercepts anova(mdl.clm.1, mdl.clmm.Int.1) ## Likelihood ratio tests of cumulative link models: ## ## formula: link: ## mdl.clm.1 Rating ~ Class * Sex * Frequency logit ## mdl.clmm.Int.1 Rating ~ Class * Sex * Frequency + (1 | Subject:Word) logit ## threshold: ## mdl.clm.1 flexible ## mdl.clmm.Int.1 flexible ## ## no.par AIC logLik LR.stat df Pr(&gt;Chisq) ## mdl.clm.1 13 4800.2 -2387.1 ## mdl.clmm.Int.1 14 4801.5 -2386.8 0.661 1 0.4162 4.5.2.3.3 Random Intercepts vs Random Slope anova(mdl.clmm.Int.1, mdl.clmm.Slope.1) ## Likelihood ratio tests of cumulative link models: ## ## formula: ## mdl.clmm.Int.1 Rating ~ Class * Sex * Frequency + (1 | Subject:Word) ## mdl.clmm.Slope.1 Rating ~ Class * Sex * Frequency + (Class | Subject:Word) ## link: threshold: ## mdl.clmm.Int.1 logit flexible ## mdl.clmm.Slope.1 logit flexible ## ## no.par AIC logLik LR.stat df Pr(&gt;Chisq) ## mdl.clmm.Int.1 14 4801.5 -2386.8 ## mdl.clmm.Slope.1 16 4789.3 -2378.7 16.196 2 0.0003041 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The model comparison above shows that using random intercepts is enough in our case. By subject Random Slopes are not needed; subjects “seem” to show similarities in how they produced the items. 4.5.2.4 Model’s fit print(tab_model(mdl.clmm.Int.1, file = paste0(&quot;outputs/mdl.clmm.Int.1.html&quot;))) webshot(paste0(&quot;outputs/mdl.clmm.Int.1.html&quot;), paste0(&quot;outputs/mdl.clmm.Int.1.png&quot;)) Model fit: Cumulative Logit Mixed effects model 4.5.2.5 Interpreting a cumulative model As a way to interpret the model, we can look at the coefficients and make sense of the results. A CLM model is a Logistic model with a cumulative effect. The “Coefficients” are the estimates for each level of the fixed effect; the “Threshold coefficients” are those of the response. For the former, a negative coefficient indicates a negative association with the response; and a positive is positively associated with the response. The p values are indicating the significance of each level. For the “Threshold coefficients”, we can see the cumulative effects of ratings 1|2, 2|3, 3|4 and 4|5 which indicate an overall increase in the ratings from 1 to 5. 4.5.2.6 Plotting 4.5.2.6.1 No confidence intervals We use a modified version of a plotting function that allows us to visualise the effects. For this, we use the base R plotting functions. The version below is without confidence intervals. par(oma = c(4, 0, 0, 3), mgp = c(2, 1, 0)) xlim = c(min(mdl.clmm.Int.1$beta), max(mdl.clmm.Int.1$beta)) ylim = c(0, 1) plot(0, 0, xlim = xlim, ylim = ylim, type = &quot;n&quot;, ylab = expression(Probability), xlab = &quot;&quot;, xaxt = &quot;n&quot;, main = &quot;Predicted curves&quot;, cex = 2, cex.lab = 1.5, cex.main = 1.5, cex.axis = 1.5) axis(side = 1, at = mdl.clmm.Int.1$beta, labels = names(mdl.clmm.Int.1$beta), las = 2, cex = 0.75, cex.lab = 0.75, cex.axis = 0.75) xs = seq(xlim[1], xlim[2], length.out = 100) lines(xs, plogis(mdl.clmm.Int.1$Theta[1] - xs), col = &#39;black&#39;) lines(xs, plogis(mdl.clmm.Int.1$Theta[2] - xs) - plogis(mdl.clmm.Int.1$Theta[1] - xs), col = &#39;red&#39;) lines(xs, plogis(mdl.clmm.Int.1$Theta[3] - xs) - plogis(mdl.clmm.Int.1$Theta[2] - xs), col = &#39;green&#39;) lines(xs, plogis(mdl.clmm.Int.1$Theta[4] - xs) - plogis(mdl.clmm.Int.1$Theta[3] - xs), col = &#39;orange&#39;) lines(xs, plogis(mdl.clmm.Int.1$Theta[5] - xs) - plogis(mdl.clmm.Int.1$Theta[4] - xs), col = &#39;yellow&#39;) lines(xs, plogis(mdl.clmm.Int.1$Theta[6] - xs) - plogis(mdl.clmm.Int.1$Theta[5] - xs), col = &#39;grey&#39;) lines(xs, 1 - (plogis(mdl.clmm.Int.1$Theta[6] - xs)), col = &#39;blue&#39;) abline(v = c(0,mdl.clmm.Int.1$beta),lty = 3) abline(h = 0, lty = &quot;dashed&quot;) abline(h = 0.2, lty = &quot;dashed&quot;) abline(h = 0.4, lty = &quot;dashed&quot;) abline(h = 0.6, lty = &quot;dashed&quot;) abline(h = 0.8, lty = &quot;dashed&quot;) abline(h = 1, lty = &quot;dashed&quot;) legend(par(&#39;usr&#39;)[2], par(&#39;usr&#39;)[4], bty = &#39;n&#39;, xpd = NA, lty = 1, col = c(&quot;black&quot;, &quot;red&quot;, &quot;green&quot;, &quot;orange&quot;, &quot;yellow&quot;, &quot;grey&quot;, &quot;blue&quot;), legend = c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;, &quot;6&quot;, &quot;7&quot;), cex = 0.75) 4.5.2.6.2 With confidence intervals Here is an attempt to add the 97.5% confidence intervals to these plots. This is an experimental attempt and any feedback is welcome! par(oma = c(4, 0, 0, 3), mgp = c(2, 1, 0)) xlim = c(min(mdl.clmm.Int.1$beta), max(mdl.clmm.Int.1$beta)) ylim = c(0, 1) plot(0, 0, xlim = xlim, ylim = ylim, type = &quot;n&quot;, ylab = expression(Probability), xlab = &quot;&quot;, xaxt = &quot;n&quot;, main = &quot;Predicted curves&quot;, cex = 2, cex.lab = 1.5, cex.main = 1.5, cex.axis = 1.5) axis(side = 1, at = mdl.clmm.Int.1$beta, labels = names(mdl.clmm.Int.1$beta), las = 2, cex = 0.75, cex.lab = 0.75, cex.axis = 0.75) xs = seq(xlim[1], xlim[2], length.out = 100) #+CI lines(xs, plogis(mdl.clmm.Int.1$Theta[1]+(summary(mdl.clmm.Int.1)$coefficient[,2][[1]]/1.96) - xs), col=&#39;black&#39;) lines(xs, plogis(mdl.clmm.Int.1$Theta[2]+(summary(mdl.clmm.Int.1)$coefficient[,2][[2]]/1.96) - xs)-plogis(mdl.clmm.Int.1$Theta[1]+(summary(mdl.clmm.Int.1)$coefficient[,2][[1]]/1.96) - xs), col=&#39;red&#39;) lines(xs, plogis(mdl.clmm.Int.1$Theta[3]+(summary(mdl.clmm.Int.1)$coefficient[,2][[3]]/1.96) - xs)-plogis(mdl.clmm.Int.1$Theta[2]+(summary(mdl.clmm.Int.1)$coefficient[,2][[2]]/1.96) - xs), col=&#39;green&#39;) lines(xs, plogis(mdl.clmm.Int.1$Theta[4]+(summary(mdl.clmm.Int.1)$coefficient[,2][[4]]/1.96) - xs)-plogis(mdl.clmm.Int.1$Theta[3]+(summary(mdl.clmm.Int.1)$coefficient[,2][[3]]/1.96) - xs), col=&#39;orange&#39;) lines(xs, plogis(mdl.clmm.Int.1$Theta[5]-(summary(mdl.clmm.Int.1)$coefficient[,2][[5]]/1.96) - xs)-plogis(mdl.clmm.Int.1$Theta[4]-(summary(mdl.clmm.Int.1)$coefficient[,2][[4]]/1.96) - xs), col=&#39;yellow&#39;) lines(xs, plogis(mdl.clmm.Int.1$Theta[6]-(summary(mdl.clmm.Int.1)$coefficient[,2][[6]]/1.96) - xs)-plogis(mdl.clmm.Int.1$Theta[5]-(summary(mdl.clmm.Int.1)$coefficient[,2][[5]]/1.96) - xs), col=&#39;grey&#39;) lines(xs, 1-(plogis(mdl.clmm.Int.1$Theta[6]-(summary(mdl.clmm.Int.1)$coefficient[,2][[6]]/1.96) - xs)), col=&#39;blue&#39;) #-CI lines(xs, plogis(mdl.clmm.Int.1$Theta[1]-(summary(mdl.clmm.Int.1)$coefficient[,2][[1]]/1.96) - xs), col=&#39;black&#39;) lines(xs, plogis(mdl.clmm.Int.1$Theta[2]-(summary(mdl.clmm.Int.1)$coefficient[,2][[2]]/1.96) - xs)-plogis(mdl.clmm.Int.1$Theta[1]-(summary(mdl.clmm.Int.1)$coefficient[,2][[1]]/1.96) - xs), col=&#39;red&#39;) lines(xs, plogis(mdl.clmm.Int.1$Theta[3]-(summary(mdl.clmm.Int.1)$coefficient[,2][[3]]/1.96) - xs)-plogis(mdl.clmm.Int.1$Theta[2]-(summary(mdl.clmm.Int.1)$coefficient[,2][[2]]/1.96) - xs), col=&#39;green&#39;) lines(xs, plogis(mdl.clmm.Int.1$Theta[4]-(summary(mdl.clmm.Int.1)$coefficient[,2][[4]]/1.96) - xs)-plogis(mdl.clmm.Int.1$Theta[3]-(summary(mdl.clmm.Int.1)$coefficient[,2][[3]]/1.96) - xs), col=&#39;orange&#39;) lines(xs, plogis(mdl.clmm.Int.1$Theta[5]-(summary(mdl.clmm.Int.1)$coefficient[,2][[5]]/1.96) - xs)-plogis(mdl.clmm.Int.1$Theta[4]-(summary(mdl.clmm.Int.1)$coefficient[,2][[4]]/1.96) - xs), col=&#39;yellow&#39;) lines(xs, plogis(mdl.clmm.Int.1$Theta[6]-(summary(mdl.clmm.Int.1)$coefficient[,2][[6]]/1.96) - xs)-plogis(mdl.clmm.Int.1$Theta[5]-(summary(mdl.clmm.Int.1)$coefficient[,2][[5]]/1.96) - xs), col=&#39;grey&#39;) lines(xs, 1-(plogis(mdl.clmm.Int.1$Theta[6]-(summary(mdl.clmm.Int.1)$coefficient[,2][[6]]/1.96) - xs)), col=&#39;blue&#39;) ## fill area around CI using c(x, rev(x)), c(y2, rev(y1)) polygon(c(xs, rev(xs)), c(plogis(mdl.clmm.Int.1$Theta[1]+(summary(mdl.clmm.Int.1)$coefficient[,2][[1]]/1.96) - xs), rev(plogis(mdl.clmm.Int.1$Theta[1]-(summary(mdl.clmm.Int.1)$coefficient[,2][[1]]/1.96) - xs))), col = &quot;gray90&quot;) polygon(c(xs, rev(xs)), c(plogis(mdl.clmm.Int.1$Theta[2]+(summary(mdl.clmm.Int.1)$coefficient[,2][[2]]/1.96) - xs)-plogis(mdl.clmm.Int.1$Theta[1]+(summary(mdl.clmm.Int.1)$coefficient[,2][[1]]/1.96) - xs), rev(plogis(mdl.clmm.Int.1$Theta[2]-(summary(mdl.clmm.Int.1)$coefficient[,2][[2]]/1.96) - xs)-plogis(mdl.clmm.Int.1$Theta[1]-(summary(mdl.clmm.Int.1)$coefficient[,2][[1]]/1.96) - xs))), col = &quot;gray90&quot;) polygon(c(xs, rev(xs)), c(plogis(mdl.clmm.Int.1$Theta[3]+(summary(mdl.clmm.Int.1)$coefficient[,2][[3]]/1.96) - xs)-plogis(mdl.clmm.Int.1$Theta[2]+(summary(mdl.clmm.Int.1)$coefficient[,2][[2]]/1.96) - xs), rev(plogis(mdl.clmm.Int.1$Theta[3]-(summary(mdl.clmm.Int.1)$coefficient[,2][[3]]/1.96) - xs)-plogis(mdl.clmm.Int.1$Theta[2]-(summary(mdl.clmm.Int.1)$coefficient[,2][[2]]/1.96) - xs))), col = &quot;gray90&quot;) polygon(c(xs, rev(xs)), c(plogis(mdl.clmm.Int.1$Theta[4]+(summary(mdl.clmm.Int.1)$coefficient[,2][[4]]/1.96) - xs)-plogis(mdl.clmm.Int.1$Theta[3]+(summary(mdl.clmm.Int.1)$coefficient[,2][[3]]/1.96) - xs), rev(plogis(mdl.clmm.Int.1$Theta[4]-(summary(mdl.clmm.Int.1)$coefficient[,2][[4]]/1.96) - xs)-plogis(mdl.clmm.Int.1$Theta[3]-(summary(mdl.clmm.Int.1)$coefficient[,2][[3]]/1.96) - xs))), col = &quot;gray90&quot;) polygon(c(xs, rev(xs)), c(plogis(mdl.clmm.Int.1$Theta[5]+(summary(mdl.clmm.Int.1)$coefficient[,2][[5]]/1.96) - xs)-plogis(mdl.clmm.Int.1$Theta[4]+(summary(mdl.clmm.Int.1)$coefficient[,2][[4]]/1.96) - xs), rev(plogis(mdl.clmm.Int.1$Theta[5]-(summary(mdl.clmm.Int.1)$coefficient[,2][[5]]/1.96) - xs)-plogis(mdl.clmm.Int.1$Theta[4]-(summary(mdl.clmm.Int.1)$coefficient[,2][[4]]/1.96) - xs))), col = &quot;gray90&quot;) polygon(c(xs, rev(xs)), c(plogis(mdl.clmm.Int.1$Theta[6]+(summary(mdl.clmm.Int.1)$coefficient[,2][[6]]/1.96) - xs)-plogis(mdl.clmm.Int.1$Theta[5]+(summary(mdl.clmm.Int.1)$coefficient[,2][[5]]/1.96) - xs), rev(plogis(mdl.clmm.Int.1$Theta[6]-(summary(mdl.clmm.Int.1)$coefficient[,2][[6]]/1.96) - xs)-plogis(mdl.clmm.Int.1$Theta[5]-(summary(mdl.clmm.Int.1)$coefficient[,2][[5]]/1.96) - xs))), col = &quot;gray90&quot;) polygon(c(xs, rev(xs)), c(1-(plogis(mdl.clmm.Int.1$Theta[6]-(summary(mdl.clmm.Int.1)$coefficient[,2][[6]]/1.96) - xs)), rev(1-(plogis(mdl.clmm.Int.1$Theta[6]+(summary(mdl.clmm.Int.1)$coefficient[,2][[6]]/1.96) - xs)))), col = &quot;gray90&quot;) lines(xs, plogis(mdl.clmm.Int.1$Theta[1] - xs), col = &#39;black&#39;) lines(xs, plogis(mdl.clmm.Int.1$Theta[2] - xs) - plogis(mdl.clmm.Int.1$Theta[1] - xs), col = &#39;red&#39;) lines(xs, plogis(mdl.clmm.Int.1$Theta[3] - xs) - plogis(mdl.clmm.Int.1$Theta[2] - xs), col = &#39;green&#39;) lines(xs, plogis(mdl.clmm.Int.1$Theta[4] - xs) - plogis(mdl.clmm.Int.1$Theta[3] - xs), col = &#39;orange&#39;) lines(xs, plogis(mdl.clmm.Int.1$Theta[5] - xs) - plogis(mdl.clmm.Int.1$Theta[4] - xs), col = &#39;yellow&#39;) lines(xs, plogis(mdl.clmm.Int.1$Theta[6] - xs) - plogis(mdl.clmm.Int.1$Theta[5] - xs), col = &#39;grey&#39;) lines(xs, 1 - (plogis(mdl.clmm.Int.1$Theta[6] - xs)), col = &#39;blue&#39;) abline(v = c(0,mdl.clmm.Int.1$beta),lty = 3) abline(h = 0, lty = &quot;dashed&quot;) abline(h = 0.2, lty = &quot;dashed&quot;) abline(h = 0.4, lty = &quot;dashed&quot;) abline(h = 0.6, lty = &quot;dashed&quot;) abline(h = 0.8, lty = &quot;dashed&quot;) abline(h = 1, lty = &quot;dashed&quot;) legend(par(&#39;usr&#39;)[2], par(&#39;usr&#39;)[4], bty = &#39;n&#39;, xpd = NA, lty = 1, col = c(&quot;black&quot;, &quot;red&quot;, &quot;green&quot;, &quot;orange&quot;, &quot;yellow&quot;, &quot;grey&quot;, &quot;blue&quot;), legend = c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;, &quot;6&quot;, &quot;7&quot;), cex = 0.75) Check if the results are different between our initial model (with clm) and our new model (with clmm). "],["4.6-generalised-additive-mixed-effects-models-gamms.html", "4.6 Generalised Additive Mixed-effects Models (GAMMs)", " 4.6 Generalised Additive Mixed-effects Models (GAMMs) Generalised Additive Mixed-effects Models (GAMMs) are currently used for dynamic data. By dynamic data we mean, where the “time” component is accounted for. These can be vowel formants or f0 obtained at 11 intervals; dynamic tongue contours obtained at multiple time points, etc. We first use GAMMs (with random effects) to demonstrate its usage 4.6.1 Loading dataframe dynamicDF &lt;- read_csv(&quot;data/dynamicData.csv&quot;) dynamicDF %&gt;% head(10) ## # A tibble: 10 × 19 ## Speaker Sex Word repetition context vowel Label Duration F2_01 F2_02 F2_03 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 SP01 Male 2aat… rep01 Plain a: V2 176. 1500. 1526. 1498. ## 2 SP01 Male 2aat… rep02 Plain a: V2 143. 1518. 1520. 1512. ## 3 SP01 Male 2aat… rep03 Plain a: V2 108. 1539. 1553. 1556. ## 4 SP01 Male 2aaT… rep01 Pharyn… a: V2 145. 1046. 1107. 1127. ## 5 SP01 Male 2aaT… rep02 Pharyn… a: V2 141. 1229. 1242. 1261. ## 6 SP01 Male 2aaT… rep03 Pharyn… a: V2 108. 1156. 1165. 1171. ## 7 SP01 Male 2iit… rep01 Plain i: V2 184. 2269. 2244. 2281. ## 8 SP01 Male 2iit… rep02 Plain i: V2 192. 2218. 2197. 2219. ## 9 SP01 Male 2iit… rep03 Plain i: V2 172. 2140. 2152. 2182. ## 10 SP01 Male 2iiT… rep01 Pharyn… i: V2 212. 1337. 1442. 1592. ## # ℹ 8 more variables: F2_04 &lt;dbl&gt;, F2_05 &lt;dbl&gt;, F2_06 &lt;dbl&gt;, F2_07 &lt;dbl&gt;, ## # F2_08 &lt;dbl&gt;, F2_09 &lt;dbl&gt;, F2_10 &lt;dbl&gt;, F2_11 &lt;dbl&gt; The dataframe was extracted from a Praat script and comes in a wide format. For it to work properly with GAMMs, we convert it to a long format 4.6.2 Manipulation 4.6.2.1 Wide to Long format dynamicDF &lt;- dynamicDF %&gt;% pivot_longer(-c(1:8), names_sep = &quot;_&quot;, names_to = c(&quot;Correlate&quot;, &quot;Interval&quot;), values_to = &quot;Vals&quot;, names_repair = &quot;minimal&quot;) %&gt;% pivot_wider(names_from = &quot;Correlate&quot;, values_from = &quot;Vals&quot;) %&gt;% unnest() dynamicDF %&gt;% head(10) ## # A tibble: 10 × 10 ## Speaker Sex Word repetition context vowel Label Duration Interval F2 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 SP01 Male 2aataa rep01 Plain a: V2 176. 01 1500. ## 2 SP01 Male 2aataa rep01 Plain a: V2 176. 02 1526. ## 3 SP01 Male 2aataa rep01 Plain a: V2 176. 03 1498. ## 4 SP01 Male 2aataa rep01 Plain a: V2 176. 04 1462. ## 5 SP01 Male 2aataa rep01 Plain a: V2 176. 05 1433. ## 6 SP01 Male 2aataa rep01 Plain a: V2 176. 06 1421. ## 7 SP01 Male 2aataa rep01 Plain a: V2 176. 07 1419. ## 8 SP01 Male 2aataa rep01 Plain a: V2 176. 08 1411. ## 9 SP01 Male 2aataa rep01 Plain a: V2 176. 09 1401. ## 10 SP01 Male 2aataa rep01 Plain a: V2 176. 10 1428. 4.6.2.2 Transforming and arranging dataframe dynamicDF &lt;- dynamicDF %&gt;% mutate(Speaker = as.factor(Speaker), Sex = as.factor(Sex), Word = as.factor(Word), repetition = as.factor(repetition), context = as.factor(context), vowel = as.factor(vowel), Interval = as.numeric(Interval)) %&gt;% arrange(Speaker, Word, context, vowel) dynamicDF %&gt;% head(10) ## # A tibble: 10 × 10 ## Speaker Sex Word repetition context vowel Label Duration Interval F2 ## &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 SP01 Male 2aataa rep01 Plain a: V2 176. 1 1500. ## 2 SP01 Male 2aataa rep01 Plain a: V2 176. 2 1526. ## 3 SP01 Male 2aataa rep01 Plain a: V2 176. 3 1498. ## 4 SP01 Male 2aataa rep01 Plain a: V2 176. 4 1462. ## 5 SP01 Male 2aataa rep01 Plain a: V2 176. 5 1433. ## 6 SP01 Male 2aataa rep01 Plain a: V2 176. 6 1421. ## 7 SP01 Male 2aataa rep01 Plain a: V2 176. 7 1419. ## 8 SP01 Male 2aataa rep01 Plain a: V2 176. 8 1411. ## 9 SP01 Male 2aataa rep01 Plain a: V2 176. 9 1401. ## 10 SP01 Male 2aataa rep01 Plain a: V2 176. 10 1428. 4.6.2.3 Ordering predictors It is important to use an ordered predictor in GAMs. By default, GAMs provides computations similar to an ANOVA (with sum coding). Here, we use a treatment coding to allow for an increase in power. Also, we create an interaction factor; the results are to be modelled as a function of the interaction between the context and the vowel dynamicDF$ContVowInt &lt;- interaction(dynamicDF$context, dynamicDF$vowel) dynamicDF$ContVowInt.ord &lt;- as.ordered(dynamicDF$ContVowInt) contrasts(dynamicDF$ContVowInt.ord) &lt;- &quot;contr.treatment&quot; dynamicDF$Sex.ord &lt;- as.ordered(dynamicDF$Sex) contrasts(dynamicDF$Sex.ord) &lt;- &quot;contr.treatment&quot; 4.6.2.4 Start value for autocorrelation Given that time series are heavily correlated, we need to account for this autocorrelation in any analyses. We add a variable “start” to indicate when the Interval == 1 dynamicDF$start &lt;-dynamicDF$Interval == 1 4.6.3 Model specifications 4.6.3.1 No AR1 model 4.6.3.1.1 Model estimation system.time(mdl.gamm.F2.noAR &lt;- bam(F2 ~ ContVowInt.ord * Sex.ord + ### 1d smooths s(Interval, bs = &quot;cr&quot;, k = 11) + ### 1d smooths * factor s(Interval, bs = &quot;cr&quot;, k = 11, by = ContVowInt.ord) + s(Interval, bs = &quot;cr&quot;, k = 11, by = Sex.ord) + ### random smooths by speaker s(Interval, Speaker, bs = &quot;fs&quot;, k = 11, m = 1, xt=list(bs = &quot;tp&quot;)) + s(Interval, Speaker, bs = &quot;fs&quot;, k = 11, m = 1, xt=list(bs = &quot;tp&quot;), by = ContVowInt.ord) + ### random smooths by word s(Interval, Word, bs = &quot;fs&quot;, k = 11, m = 1, xt=list(bs = &quot;tp&quot;)) + s(Interval, Word, bs = &quot;fs&quot;, k = 11, m = 1, xt=list(bs = &quot;tp&quot;), by = Sex.ord), data = dynamicDF, discrete = TRUE, nthreads = 2)) ## user system elapsed ## 1.20 0.80 0.88 4.6.3.1.1.1 ACF No AR1 acf_resid(mdl.gamm.F2.noAR, main = &quot;Average ACF No.AR F2&quot;,cex.lab=1.5,cex.axis=1.5) 4.6.3.1.1.2 Gam check gam.check(mdl.gamm.F2.noAR) ## ## Method: fREML Optimizer: perf chol ## $grad ## [1] -3.197442e-14 -2.717826e-13 -2.042810e-14 -1.760814e-13 1.976197e-14 ## [6] 3.552714e-15 1.132427e-14 -1.967253e-06 -2.553513e-15 -3.167531e-06 ## [11] 8.881784e-16 5.329071e-15 4.440892e-15 -3.165860e-06 -1.110223e-16 ## [16] -1.110223e-13 -5.107026e-15 -6.195044e-14 -6.439294e-15 -2.561403e-06 ## [21] 1.332268e-15 -3.476698e-06 -6.661338e-15 1.610374e-10 ## ## $hess ## [,1] [,2] [,3] [,4] [,5] ## 1.003880e+00 -9.361499e-02 9.867539e-03 -1.773653e-01 1.813204e-02 ## -9.361499e-02 1.638108e-01 2.307914e-02 -6.348586e-02 -4.914258e-02 ## 9.867539e-03 2.307914e-02 1.193923e+00 1.370215e-02 2.170922e-02 ## -1.773653e-01 -6.348586e-02 1.370215e-02 3.473970e-01 -4.569094e-03 ## 1.813204e-02 -4.914258e-02 2.170922e-02 -4.569094e-03 1.105819e+00 ## 1.869996e-02 -4.161598e-02 1.925866e-02 -1.293336e-03 -5.549452e-02 ## -2.506757e-01 -9.568044e-03 2.012076e-03 3.342137e-02 -3.534940e-02 ## 1.835864e-06 -2.041012e-08 -6.795749e-08 -4.024643e-07 2.384429e-07 ## -2.730578e-27 -6.756815e-29 8.193394e-28 -6.226779e-28 -1.634415e-28 ## 4.388010e-08 2.222766e-07 2.794168e-08 -5.336235e-08 -8.684646e-08 ## 9.693161e-29 -1.761694e-28 -5.650937e-30 1.941036e-29 1.500761e-29 ## -2.094426e-02 -3.873479e-03 6.382315e-02 4.224116e-03 -8.042748e-03 ## -2.162922e-29 7.500641e-30 2.859547e-28 -3.748008e-30 5.800040e-30 ## 2.724867e-08 -2.343219e-08 2.858970e-09 1.451438e-07 2.394565e-08 ## -2.261934e-28 1.530476e-28 -9.640589e-30 -4.665672e-28 7.628354e-29 ## -2.111491e-02 5.202241e-03 -8.566203e-04 1.013440e-03 7.873933e-02 ## 1.053291e-29 -4.541828e-30 -1.572611e-30 7.415223e-31 7.794641e-29 ## -2.067744e-02 3.927096e-03 -9.736665e-04 7.681664e-04 3.362567e-03 ## -1.553246e-30 -9.641952e-31 -9.931864e-31 1.288670e-30 7.046425e-32 ## 1.666934e-06 1.956228e-06 -3.382783e-07 1.774858e-06 7.445482e-07 ## -5.594164e-27 -5.564185e-27 3.659382e-27 -4.671394e-27 -2.151430e-27 ## 3.217140e-08 1.535342e-07 -5.404928e-08 2.378842e-07 -1.894141e-07 ## -3.240826e-28 -3.739453e-28 2.584415e-28 -8.183831e-28 -7.830517e-29 ## d -1.050806e+00 -3.614705e-01 -1.228224e+00 -5.976267e-01 -1.231656e+00 ## [,6] [,7] [,8] [,9] [,10] ## 1.869996e-02 -2.506757e-01 1.835864e-06 -2.901173e-27 4.388010e-08 ## -4.161598e-02 -9.568044e-03 -2.041012e-08 -8.780368e-29 2.222766e-07 ## 1.925866e-02 2.012076e-03 -6.795749e-08 3.489766e-28 2.794168e-08 ## -1.293336e-03 3.342137e-02 -4.024643e-07 -6.408959e-28 -5.336235e-08 ## -5.549452e-02 -3.534940e-02 2.384429e-07 -2.515398e-28 -8.684646e-08 ## 1.608696e+00 -3.333043e-02 1.906263e-07 -4.690757e-28 -7.452219e-08 ## -3.333043e-02 7.405700e-01 2.946194e-06 -6.535006e-28 7.542137e-08 ## 1.906263e-07 2.946194e-06 1.967272e-06 1.266704e-32 8.682268e-13 ## -4.945848e-28 -6.192442e-28 1.183267e-32 2.553513e-15 1.990942e-33 ## -7.452219e-08 7.542137e-08 8.682268e-13 -4.773871e-34 3.167528e-06 ## 1.254846e-29 3.595956e-29 -4.385281e-34 -5.456039e-30 2.103533e-33 ## -7.722929e-03 -1.301421e-01 -1.302448e-06 1.108195e-27 9.333260e-08 ## 1.033146e-29 3.216104e-29 -3.800040e-35 -1.533357e-29 1.144946e-34 ## 2.308512e-08 2.387087e-07 -2.472654e-14 -1.109391e-33 -1.729391e-12 ## 5.574158e-29 8.955897e-30 7.140931e-34 -2.047134e-29 3.381071e-33 ## 3.106205e-03 4.813115e-02 7.265923e-07 1.074583e-27 2.598147e-07 ## 2.375362e-31 -5.368325e-30 2.524986e-35 -4.333108e-30 -8.118414e-35 ## 3.593009e-02 1.859382e-02 2.987398e-07 3.229019e-28 5.042282e-07 ## 2.631607e-29 -3.613058e-30 6.840752e-35 -3.312588e-30 -1.654635e-35 ## 4.889666e-07 -2.577409e-07 1.250788e-12 1.107362e-32 2.557888e-12 ## -1.999660e-27 -8.026339e-28 -1.731001e-33 -6.181632e-29 1.847844e-34 ## -1.251857e-07 8.775859e-08 2.813470e-13 3.039944e-34 -1.753342e-12 ## -2.091530e-28 -2.551649e-28 -1.354550e-33 -2.902629e-29 -3.446669e-34 ## d -1.564357e+00 -1.031287e+00 -8.032182e-06 -9.425570e-24 -2.306632e-06 ## [,11] [,12] [,13] [,14] [,15] ## 9.963755e-29 -2.094426e-02 -2.790592e-29 2.724867e-08 -2.248571e-28 ## -1.705466e-28 -3.873479e-03 4.982743e-30 -2.343219e-08 1.510254e-28 ## -6.311658e-30 6.382315e-02 1.674089e-28 2.858970e-09 -9.951013e-30 ## 1.924186e-29 4.224116e-03 -8.494566e-30 1.451438e-07 -4.646620e-28 ## 1.561495e-29 -8.042748e-03 6.935882e-30 2.394565e-08 7.518078e-29 ## 1.261533e-29 -7.722929e-03 3.971410e-30 2.308512e-08 5.476712e-29 ## 3.644381e-29 -1.301421e-01 2.610475e-29 2.387087e-07 2.932461e-30 ## -6.551478e-34 -1.302448e-06 -1.395738e-34 -2.472654e-14 8.851660e-34 ## -5.456039e-30 1.060046e-27 -1.533357e-29 -1.632496e-33 -2.047134e-29 ## 1.949499e-33 9.333260e-08 3.717677e-35 -1.729391e-12 3.328055e-33 ## -6.661338e-16 -3.945992e-29 -8.231077e-34 -2.092597e-34 -1.356658e-35 ## -4.014206e-29 5.713580e+00 2.122227e-28 -1.406852e-07 1.487500e-28 ## -8.231077e-34 2.531269e-28 -4.662937e-15 1.118899e-35 -1.964088e-35 ## -2.076291e-34 -1.406852e-07 -4.950595e-36 3.165853e-06 -2.821366e-33 ## -1.356658e-35 1.588115e-28 -1.964088e-35 -2.547836e-33 1.110223e-16 ## 1.668849e-28 7.439112e-02 -1.366255e-29 1.100026e-07 -6.271786e-28 ## -5.042019e-35 -4.332341e-30 -5.848313e-34 -1.607665e-35 -7.637864e-34 ## 1.919109e-28 3.620299e-02 -9.014722e-30 3.157134e-08 -6.962854e-28 ## -1.592668e-35 2.977759e-30 -6.033908e-35 1.439979e-35 -2.218691e-34 ## -1.587002e-33 -2.180195e-07 -7.178574e-35 9.876859e-13 -1.466288e-33 ## -3.842188e-29 9.107497e-29 -9.621897e-30 -1.724096e-33 -1.765279e-29 ## 9.237031e-34 1.061986e-07 7.894592e-36 -3.065580e-12 9.212337e-35 ## -1.467374e-29 7.729009e-28 -2.367519e-30 -3.154249e-33 -6.113924e-29 ## d -4.503816e-26 -6.080384e+00 -9.293502e-25 -1.694360e-06 -7.649261e-25 ## [,16] [,17] [,18] [,19] [,20] ## -2.111491e-02 7.921045e-30 -2.067744e-02 4.461691e-31 1.666934e-06 ## 5.202241e-03 -6.041730e-30 3.927096e-03 -1.520265e-30 1.956228e-06 ## -8.566203e-04 -1.475335e-30 -9.736665e-04 -1.000132e-30 -3.382783e-07 ## 1.013440e-03 -5.363083e-31 7.681664e-04 7.712075e-31 1.774858e-06 ## 7.873933e-02 6.900138e-29 3.362567e-03 1.167471e-31 7.445482e-07 ## 3.106205e-03 -7.618732e-33 3.593009e-02 2.767466e-29 4.889666e-07 ## 4.813115e-02 -6.729529e-30 1.859382e-02 -3.981380e-30 -2.577409e-07 ## 7.265923e-07 8.754422e-35 2.987398e-07 3.195273e-35 1.250788e-12 ## 1.304289e-27 -4.333108e-30 2.774213e-28 -3.312588e-30 5.580084e-33 ## 2.598147e-07 -5.164212e-35 5.042282e-07 -9.255486e-36 2.557888e-12 ## 1.641776e-28 -5.042019e-35 1.883513e-28 -1.592668e-35 -1.596458e-33 ## 7.439112e-02 -3.368927e-30 3.620299e-02 3.623521e-30 -2.180195e-07 ## -8.966407e-30 -5.848313e-34 -1.760296e-29 -6.033908e-35 7.933611e-36 ## 1.100026e-07 -1.362678e-35 3.157134e-08 1.552336e-35 9.876859e-13 ## -6.779262e-28 -7.637864e-34 -7.022423e-28 -2.218691e-34 -5.540741e-34 ## 9.728958e-01 -1.787055e-28 -1.056477e-01 -3.262309e-30 -1.796839e-07 ## -1.900524e-28 5.218048e-15 1.477781e-29 -2.428310e-34 2.961089e-35 ## -1.056477e-01 1.074100e-29 1.681829e+00 5.621969e-29 -1.688652e-07 ## -5.007378e-30 -2.428310e-34 4.323387e-29 6.439294e-15 -1.436057e-35 ## -1.796839e-07 1.140911e-35 -1.688652e-07 -7.370104e-36 2.561441e-06 ## 2.397782e-28 -6.577979e-30 2.935087e-28 -5.194243e-29 -8.874990e-32 ## 3.614614e-07 -1.283231e-34 6.800200e-07 4.467465e-35 2.983844e-12 ## -7.477437e-28 -2.758765e-29 -8.403796e-28 -1.958260e-29 -1.612945e-32 ## d -1.725493e+00 -1.430855e-26 -1.827487e+00 -9.258074e-27 -1.206302e-05 ## [,21] [,22] [,23] [,24] ## -5.804970e-27 3.217140e-08 -3.135621e-28 -1.050806e+00 ## -5.413711e-27 1.535342e-07 -3.089810e-28 -3.614705e-01 ## 1.199695e-27 -5.404928e-08 3.960844e-28 -1.228224e+00 ## -4.757450e-27 2.378842e-07 -8.173344e-28 -5.976267e-01 ## -2.151895e-27 -1.894141e-07 -9.844908e-29 -1.231656e+00 ## -1.719631e-27 -1.251857e-07 -1.116546e-28 -1.564357e+00 ## -9.610266e-28 8.775859e-08 -2.566855e-28 -1.031287e+00 ## -2.257838e-33 2.813470e-13 4.615262e-34 -8.032182e-06 ## -6.181632e-29 6.883788e-34 -2.902629e-29 -9.425570e-24 ## -8.141127e-33 -1.753342e-12 -1.549712e-33 -2.306632e-06 ## -3.842188e-29 8.859451e-34 -1.467374e-29 -4.503816e-26 ## -2.860253e-28 1.061986e-07 3.589715e-28 -6.080384e+00 ## -9.621897e-30 -2.119291e-35 -2.367519e-30 -9.293502e-25 ## -5.320247e-34 -3.065580e-12 -3.132259e-33 -1.694360e-06 ## -1.765279e-29 2.866126e-34 -6.113924e-29 -7.649261e-25 ## 3.006186e-28 3.614614e-07 -6.347548e-28 -1.725493e+00 ## -6.577979e-30 -1.108896e-34 -2.758765e-29 -1.430855e-26 ## 7.132233e-29 6.800200e-07 -7.400983e-28 -1.827487e+00 ## -5.194243e-29 1.232255e-35 -1.958260e-29 -9.258074e-27 ## -8.253479e-32 2.983844e-12 -1.585811e-32 -1.206302e-05 ## -1.332268e-15 -6.195006e-33 -7.863392e-29 -2.514588e-23 ## -9.074055e-33 3.476696e-06 -2.481320e-33 -2.851468e-06 ## -7.863392e-29 -1.859022e-33 6.661338e-15 -2.848608e-24 ## d -2.514588e-23 -2.851468e-06 -2.848608e-24 1.885000e+02 ## ## Model rank = 346 / 346 ## ## Basis dimension (k) checking results. Low p-value (k-index&lt;1) may ## indicate that k is too low, especially if edf is close to k&#39;. ## ## k&#39; edf k-index ## s(Interval) 1.00e+01 3.10e+00 1.29 ## s(Interval):ContVowInt.ordPlain.a: 1.00e+01 1.72e+00 1.29 ## s(Interval):ContVowInt.ordPharyngealised.i: 1.00e+01 3.46e+00 1.29 ## s(Interval):ContVowInt.ordPlain.i: 1.00e+01 2.20e+00 1.29 ## s(Interval):ContVowInt.ordPharyngealised.u: 1.00e+01 3.46e+00 1.29 ## s(Interval):ContVowInt.ordPlain.u: 1.00e+01 4.13e+00 1.29 ## s(Interval):Sex.ordMale 1.00e+01 3.06e+00 1.29 ## s(Interval,Speaker) 2.20e+01 2.00e-05 1.29 ## s(Interval,Speaker):ContVowInt.ordPlain.a: 2.20e+01 1.10e-05 1.29 ## s(Interval,Speaker):ContVowInt.ordPharyngealised.i: 2.20e+01 1.22e+01 1.29 ## s(Interval,Speaker):ContVowInt.ordPlain.i: 2.20e+01 9.72e-06 1.29 ## s(Interval,Speaker):ContVowInt.ordPharyngealised.u: 2.20e+01 3.45e+00 1.29 ## s(Interval,Speaker):ContVowInt.ordPlain.u: 2.20e+01 3.65e+00 1.29 ## s(Interval,Word) 6.60e+01 2.92e-05 1.29 ## s(Interval,Word):Sex.ordMale 6.60e+01 1.27e-05 1.29 ## p-value ## s(Interval) 1 ## s(Interval):ContVowInt.ordPlain.a: 1 ## s(Interval):ContVowInt.ordPharyngealised.i: 1 ## s(Interval):ContVowInt.ordPlain.i: 1 ## s(Interval):ContVowInt.ordPharyngealised.u: 1 ## s(Interval):ContVowInt.ordPlain.u: 1 ## s(Interval):Sex.ordMale 1 ## s(Interval,Speaker) 1 ## s(Interval,Speaker):ContVowInt.ordPlain.a: 1 ## s(Interval,Speaker):ContVowInt.ordPharyngealised.i: 1 ## s(Interval,Speaker):ContVowInt.ordPlain.i: 1 ## s(Interval,Speaker):ContVowInt.ordPharyngealised.u: 1 ## s(Interval,Speaker):ContVowInt.ordPlain.u: 1 ## s(Interval,Word) 1 ## s(Interval,Word):Sex.ordMale 1 4.6.3.1.1.3 Estimating Rho rho_est &lt;- start_value_rho(mdl.gamm.F2.noAR) rho_est ## [1] 0.715958 4.6.3.2 AR1 model 4.6.3.2.0.1 Model estimation system.time(mdl.gamm.F2.AR &lt;- bam(F2 ~ ContVowInt.ord * Sex.ord + ### 1d smooths s(Interval, bs = &quot;cr&quot;, k = 11) + ### 1d smooths * factor s(Interval, bs = &quot;cr&quot;, k = 11, by = ContVowInt.ord) + s(Interval, bs = &quot;cr&quot;, k = 11, by = Sex.ord) + ### random smooths by speaker s(Interval, Speaker, bs = &quot;fs&quot;, k = 11, m = 1, xt=list(bs = &quot;tp&quot;)) + s(Interval, Speaker, bs = &quot;fs&quot;, k = 11, m = 1, xt=list(bs = &quot;tp&quot;), by = ContVowInt.ord) + ### random smooths by word s(Interval, Word, bs = &quot;fs&quot;, k = 11, m = 1, xt=list(bs = &quot;tp&quot;)) + s(Interval, Word, bs = &quot;fs&quot;, k = 11, m = 1, xt=list(bs = &quot;tp&quot;), by = Sex.ord), data = dynamicDF, discrete = TRUE, nthreads = 2, AR.start = dynamicDF$start, rho = rho_est)) ## user system elapsed ## 0.80 0.51 0.79 4.6.3.2.0.2 ACF AR1 acf_resid(mdl.gamm.F2.AR, main = &quot;Average ACF AR F2&quot;,cex.lab=1.5,cex.axis=1.5) 4.6.3.2.0.3 Summary summary(mdl.gamm.F2.AR) Family: gaussian Link function: identity Formula: F2 ~ ContVowInt.ord * Sex.ord + s(Interval, bs = “cr”, k = 11) + s(Interval, bs = “cr”, k = 11, by = ContVowInt.ord) + s(Interval, bs = “cr”, k = 11, by = Sex.ord) + s(Interval, Speaker, bs = “fs”, k = 11, m = 1, xt = list(bs = “tp”)) + s(Interval, Speaker, bs = “fs”, k = 11, m = 1, xt = list(bs = “tp”), by = ContVowInt.ord) + s(Interval, Word, bs = “fs”, k = 11, m = 1, xt = list(bs = “tp”)) + s(Interval, Word, bs = “fs”, k = 11, m = 1, xt = list(bs = “tp”), by = Sex.ord) Parametric coefficients: Estimate Std. Error t value (Intercept) 1318.57 17.74 74.322 ContVowInt.ordPlain.a: 259.70 27.35 9.496 ContVowInt.ordPharyngealised.i: 999.04 27.59 36.204 ContVowInt.ordPlain.i: 1244.99 27.44 45.364 ContVowInt.ordPharyngealised.u: -399.49 27.45 -14.553 ContVowInt.ordPlain.u: -266.02 27.50 -9.673 Sex.ordMale -147.62 24.95 -5.916 ContVowInt.ordPlain.a::Sex.ordMale 70.77 38.41 1.842 ContVowInt.ordPharyngealised.i::Sex.ordMale -226.37 38.93 -5.815 ContVowInt.ordPlain.i::Sex.ordMale -135.40 38.59 -3.509 ContVowInt.ordPharyngealised.u::Sex.ordMale 78.25 38.52 2.031 ContVowInt.ordPlain.u::Sex.ordMale 42.06 38.66 1.088 Pr(&gt;|t|) (Intercept) &lt; 2e-16 ContVowInt.ordPlain.a: &lt; 2e-16 ContVowInt.ordPharyngealised.i: &lt; 2e-16 ContVowInt.ordPlain.i: &lt; 2e-16 ContVowInt.ordPharyngealised.u: &lt; 2e-16 ContVowInt.ordPlain.u: &lt; 2e-16 Sex.ordMale 8.34e-09 ContVowInt.ordPlain.a::Sex.ordMale 0.066332 . ContVowInt.ordPharyngealised.i::Sex.ordMale 1.44e-08 ContVowInt.ordPlain.i::Sex.ordMale 0.000513 ** ContVowInt.ordPharyngealised.u::Sex.ordMale 0.043038 ContVowInt.ordPlain.u::Sex.ordMale 0.277405 — Signif. codes: 0 ‘’ 0.001 ’’ 0.01 ’’ 0.05 ‘.’ 0.1 ’ ’ 1 Approximate significance of smooth terms: edf Ref.df F s(Interval) 4.524e+00 5.638 12.737 s(Interval):ContVowInt.ordPlain.a: 2.434e+00 3.185 2.310 s(Interval):ContVowInt.ordPharyngealised.i: 3.507e+00 3.582 11.934 s(Interval):ContVowInt.ordPlain.i: 2.884e+00 3.567 10.334 s(Interval):ContVowInt.ordPharyngealised.u: 5.193e+00 6.419 10.664 s(Interval):ContVowInt.ordPlain.u: 5.735e+00 6.684 19.337 s(Interval):Sex.ordMale 5.009e+00 6.197 14.079 s(Interval,Speaker) 1.242e-05 18.000 0.000 s(Interval,Speaker):ContVowInt.ordPlain.a: 7.557e-06 21.000 0.000 s(Interval,Speaker):ContVowInt.ordPharyngealised.i: 1.547e+01 19.000 13.759 s(Interval,Speaker):ContVowInt.ordPlain.i: 4.679e+00 19.000 0.332 s(Interval,Speaker):ContVowInt.ordPharyngealised.u: 2.548e+00 19.000 0.164 s(Interval,Speaker):ContVowInt.ordPlain.u: 5.691e+00 19.000 0.573 s(Interval,Word) 1.378e-05 60.000 0.000 s(Interval,Word):Sex.ordMale 1.132e-05 62.000 0.000 p-value s(Interval) &lt; 2e-16 s(Interval):ContVowInt.ordPlain.a: 0.0661 . s(Interval):ContVowInt.ordPharyngealised.i: &lt; 2e-16 s(Interval):ContVowInt.ordPlain.i: 7.13e-07 s(Interval):ContVowInt.ordPharyngealised.u: &lt; 2e-16 s(Interval):ContVowInt.ordPlain.u: &lt; 2e-16 s(Interval):Sex.ordMale &lt; 2e-16 s(Interval,Speaker) 0.2584 s(Interval,Speaker):ContVowInt.ordPlain.a: 0.8747 s(Interval,Speaker):ContVowInt.ordPharyngealised.i: &lt; 2e-16 * s(Interval,Speaker):ContVowInt.ordPlain.i: 0.0910 . s(Interval,Speaker):ContVowInt.ordPharyngealised.u: 0.1405 s(Interval,Speaker):ContVowInt.ordPlain.u: 0.0073 s(Interval,Word) 0.7046 s(Interval,Word):Sex.ordMale 0.5256 — Signif. codes: 0 ‘’ 0.001 ’’ 0.01 ’’ 0.05 ‘.’ 0.1 ’ ’ 1 R-sq.(adj) = 0.993 Deviance explained = 99.4% fREML = 1856.4 Scale est. = 1469.1 n = 396 4.6.3.2.0.4 Model’s fit print(tab_model(mdl.gamm.F2.AR, file = paste0(&quot;outputs/mdl.gamm.F2.AR.html&quot;))) webshot(paste0(&quot;outputs/mdl.gamm.F2.AR.html&quot;), paste0(&quot;outputs/mdl.gamm.F2.AR.png&quot;)) Model fit: Generalised Additive Mixed effects model 4.6.4 Significance testing second Autoregressive GAM To test for significance of context, we run a model with a ML as method and evaluate significance through a maximum likelihood estimate. 4.6.4.1 Models We run two models A full model with all predictors (mdl.gamm.F2.AR.ML) A reduced model without any terms associated with the predictor “context” (mdl.gamm.F2.AR.Min.ContVowInt.ord.ML) An intercept only model (=Null) without any terms associated with the predictor “vowel” (mdl.gamm.F2.AR.Min.ContVowInt.ord.Sex.ord.ML) 4.6.4.1.1 Full Model system.time(mdl.gamm.F2.AR.ML &lt;- bam(F2 ~ ContVowInt.ord * Sex.ord + ### 1d smooths s(Interval, bs = &quot;cr&quot;, k = 11) + ### 1d smooths * factor s(Interval, bs = &quot;cr&quot;, k = 11, by = ContVowInt.ord) + s(Interval, bs = &quot;cr&quot;, k = 11, by = Sex.ord) + ### random smooths by speaker s(Interval, Speaker, bs = &quot;fs&quot;, k = 11, m = 1, xt=list(bs = &quot;tp&quot;)) + s(Interval, Speaker, bs = &quot;fs&quot;, k = 11, m = 1, xt=list(bs = &quot;tp&quot;), by = ContVowInt.ord) + ### random smooths by word s(Interval, Word, bs = &quot;fs&quot;, k = 11, m = 1, xt=list(bs = &quot;tp&quot;)) + s(Interval, Word, bs = &quot;fs&quot;, k = 11, m = 1, xt=list(bs = &quot;tp&quot;), by = Sex.ord), data = dynamicDF, discrete = TRUE, nthreads = 2, AR.start = dynamicDF$start, rho = rho_est, method=&quot;ML&quot;)) ## user system elapsed ## 41.98 30.24 29.36 4.6.4.1.2 Model 2 (without ConVowelInt.ord) system.time(mdl.gamm.F2.AR.Min.ContVowInt.ord.ML &lt;- bam(F2 ~ Sex.ord + ### 1d smooths s(Interval, bs = &quot;cr&quot;, k = 11) + ### 1d smooths * factor s(Interval, bs = &quot;cr&quot;, k = 11, by = Sex.ord) + ### random smooths by speaker s(Interval, Speaker, bs = &quot;fs&quot;, k = 11, m = 1, xt=list(bs = &quot;tp&quot;)) + ### random smooths by word s(Interval, Word, bs = &quot;fs&quot;, k = 11, m = 1, xt=list(bs = &quot;tp&quot;)) + s(Interval, Word, bs = &quot;fs&quot;, k = 11, m = 1, xt=list(bs = &quot;tp&quot;), by = Sex.ord), data = dynamicDF, discrete = TRUE, nthreads = 2, AR.start = dynamicDF$start, rho = rho_est, method=&quot;ML&quot;)) ## user system elapsed ## 6.36 4.58 6.28 4.6.4.1.3 Null Model system.time(mdl.gamm.F2.AR.Min.ContVowInt.ord.Sex.ord.ML &lt;- bam(F2 ~ ### 1d smooths s(Interval, bs = &quot;cr&quot;, k = 11) + ### 1d smooths * factor ### random smooths by speaker s(Interval, Speaker, bs = &quot;fs&quot;, k = 11, m = 1, xt=list(bs = &quot;tp&quot;)) + ### random smooths by word s(Interval, Word, bs = &quot;fs&quot;, k = 11, m = 1, xt=list(bs = &quot;tp&quot;)), data = dynamicDF, discrete = TRUE, nthreads = 2, AR.start = dynamicDF$start, rho = rho_est, method=&quot;ML&quot;)) ## user system elapsed ## 1.88 1.70 3.06 4.6.4.2 Testing significance compareML(mdl.gamm.F2.AR.ML, mdl.gamm.F2.AR.Min.ContVowInt.ord.ML) ## mdl.gamm.F2.AR.ML: F2 ~ ContVowInt.ord * Sex.ord + s(Interval, bs = &quot;cr&quot;, k = 11) + ## s(Interval, bs = &quot;cr&quot;, k = 11, by = ContVowInt.ord) + s(Interval, ## bs = &quot;cr&quot;, k = 11, by = Sex.ord) + s(Interval, Speaker, bs = &quot;fs&quot;, ## k = 11, m = 1, xt = list(bs = &quot;tp&quot;)) + s(Interval, Speaker, ## bs = &quot;fs&quot;, k = 11, m = 1, xt = list(bs = &quot;tp&quot;), by = ContVowInt.ord) + ## s(Interval, Word, bs = &quot;fs&quot;, k = 11, m = 1, xt = list(bs = &quot;tp&quot;)) + ## s(Interval, Word, bs = &quot;fs&quot;, k = 11, m = 1, xt = list(bs = &quot;tp&quot;), ## by = Sex.ord) ## ## mdl.gamm.F2.AR.Min.ContVowInt.ord.ML: F2 ~ Sex.ord + s(Interval, bs = &quot;cr&quot;, k = 11) + s(Interval, bs = &quot;cr&quot;, ## k = 11, by = Sex.ord) + s(Interval, Speaker, bs = &quot;fs&quot;, k = 11, ## m = 1, xt = list(bs = &quot;tp&quot;)) + s(Interval, Word, bs = &quot;fs&quot;, ## k = 11, m = 1, xt = list(bs = &quot;tp&quot;)) + s(Interval, Word, ## bs = &quot;fs&quot;, k = 11, m = 1, xt = list(bs = &quot;tp&quot;), by = Sex.ord) ## ## Chi-square test of ML scores ## ----- ## Model Score Edf Difference Df p.value ## 1 mdl.gamm.F2.AR.Min.ContVowInt.ord.ML 2082.786 12 ## 2 mdl.gamm.F2.AR.ML 1930.850 42 151.936 30.000 &lt; 2e-16 ## Sig. ## 1 ## 2 *** ## ## AIC difference: -57.04, model mdl.gamm.F2.AR.ML has lower AIC. compareML(mdl.gamm.F2.AR.ML, mdl.gamm.F2.AR.Min.ContVowInt.ord.Sex.ord.ML) ## mdl.gamm.F2.AR.ML: F2 ~ ContVowInt.ord * Sex.ord + s(Interval, bs = &quot;cr&quot;, k = 11) + ## s(Interval, bs = &quot;cr&quot;, k = 11, by = ContVowInt.ord) + s(Interval, ## bs = &quot;cr&quot;, k = 11, by = Sex.ord) + s(Interval, Speaker, bs = &quot;fs&quot;, ## k = 11, m = 1, xt = list(bs = &quot;tp&quot;)) + s(Interval, Speaker, ## bs = &quot;fs&quot;, k = 11, m = 1, xt = list(bs = &quot;tp&quot;), by = ContVowInt.ord) + ## s(Interval, Word, bs = &quot;fs&quot;, k = 11, m = 1, xt = list(bs = &quot;tp&quot;)) + ## s(Interval, Word, bs = &quot;fs&quot;, k = 11, m = 1, xt = list(bs = &quot;tp&quot;), ## by = Sex.ord) ## ## mdl.gamm.F2.AR.Min.ContVowInt.ord.Sex.ord.ML: F2 ~ s(Interval, bs = &quot;cr&quot;, k = 11) + s(Interval, Speaker, bs = &quot;fs&quot;, ## k = 11, m = 1, xt = list(bs = &quot;tp&quot;)) + s(Interval, Word, ## bs = &quot;fs&quot;, k = 11, m = 1, xt = list(bs = &quot;tp&quot;)) ## ## Chi-square test of ML scores ## ----- ## Model Score Edf Difference Df ## 1 mdl.gamm.F2.AR.Min.ContVowInt.ord.Sex.ord.ML 2150.455 7 ## 2 mdl.gamm.F2.AR.ML 1930.850 42 219.605 35.000 ## p.value Sig. ## 1 ## 2 &lt; 2e-16 *** ## ## AIC difference: -327.87, model mdl.gamm.F2.AR.ML has lower AIC. 4.6.5 Visualising smooths 4.6.5.1 /i:/ plot_smooth(mdl.gamm.F2.AR, view = &quot;Interval&quot;, cond = list(ContVowInt.ord = &quot;Plain.i:&quot;), col = &quot;blue&quot;, ylab = &quot;&quot;, xlab = &quot;&quot;, main = &quot;GAMM smooths in /i:/ &quot;, hide.label = TRUE, cex.axis = 1.3, ylim = c(1700, 2800), rm.ranef = TRUE) ## Summary: ## * ContVowInt.ord : factor; set to the value(s): Plain.i:. ## * Sex.ord : factor; set to the value(s): Female. ## * Interval : numeric predictor; with 30 values ranging from 1.000000 to 11.000000. ## * Speaker : factor; set to the value(s): SP01. (Might be canceled as random effect, check below.) ## * Word : factor; set to the value(s): 2aataa. (Might be canceled as random effect, check below.) ## * NOTE : The following random effects columns are canceled: s(Interval,Speaker),s(Interval,Speaker):ContVowInt.ordPlain.a:,s(Interval,Speaker):ContVowInt.ordPharyngealised.i:,s(Interval,Speaker):ContVowInt.ordPlain.i:,s(Interval,Speaker):ContVowInt.ordPharyngealised.u:,s(Interval,Speaker):ContVowInt.ordPlain.u:,s(Interval,Word),s(Interval,Word):Sex.ordMale ## ## Note: Selection of grouping predictors does not seem to appear in data. Rug of all data is being added. plot_smooth(mdl.gamm.F2.AR, view = &quot;Interval&quot;, cond = list(ContVowInt.ord = &quot;Pharyngealised.i:&quot;), col = &quot;red&quot;, ylab = &quot;&quot;, xlab = &quot;&quot;, hide.label = TRUE, cex.axis = 1.3, ylim = c(1700, 2800), rm.ranef = TRUE, add = TRUE) ## Summary: ## * ContVowInt.ord : factor; set to the value(s): Pharyngealised.i:. ## * Sex.ord : factor; set to the value(s): Female. ## * Interval : numeric predictor; with 30 values ranging from 1.000000 to 11.000000. ## * Speaker : factor; set to the value(s): SP01. (Might be canceled as random effect, check below.) ## * Word : factor; set to the value(s): 2aataa. (Might be canceled as random effect, check below.) ## * NOTE : The following random effects columns are canceled: s(Interval,Speaker),s(Interval,Speaker):ContVowInt.ordPlain.a:,s(Interval,Speaker):ContVowInt.ordPharyngealised.i:,s(Interval,Speaker):ContVowInt.ordPlain.i:,s(Interval,Speaker):ContVowInt.ordPharyngealised.u:,s(Interval,Speaker):ContVowInt.ordPlain.u:,s(Interval,Word),s(Interval,Word):Sex.ordMale ## ## Note: Selection of grouping predictors does not seem to appear in data. Rug of all data is being added. 4.6.5.2 /a:/ plot_smooth(mdl.gamm.F2.AR, view = &quot;Interval&quot;, cond = list(ContVowInt.ord = &quot;Plain.a:&quot;), col = &quot;blue&quot;, ylab = &quot;&quot;, xlab = &quot;&quot;, main = &quot;GAMM smooths in /a:/ &quot;, hide.label = TRUE, cex.axis = 1.3, ylim = c(1000, 1800), rm.ranef = TRUE) ## Summary: ## * ContVowInt.ord : factor; set to the value(s): Plain.a:. ## * Sex.ord : factor; set to the value(s): Female. ## * Interval : numeric predictor; with 30 values ranging from 1.000000 to 11.000000. ## * Speaker : factor; set to the value(s): SP01. (Might be canceled as random effect, check below.) ## * Word : factor; set to the value(s): 2aataa. (Might be canceled as random effect, check below.) ## * NOTE : The following random effects columns are canceled: s(Interval,Speaker),s(Interval,Speaker):ContVowInt.ordPlain.a:,s(Interval,Speaker):ContVowInt.ordPharyngealised.i:,s(Interval,Speaker):ContVowInt.ordPlain.i:,s(Interval,Speaker):ContVowInt.ordPharyngealised.u:,s(Interval,Speaker):ContVowInt.ordPlain.u:,s(Interval,Word),s(Interval,Word):Sex.ordMale ## ## Note: Selection of grouping predictors does not seem to appear in data. Rug of all data is being added. plot_smooth(mdl.gamm.F2.AR, view = &quot;Interval&quot;, cond = list(ContVowInt.ord = &quot;Pharyngealised.a:&quot;), col = &quot;red&quot;, ylab = &quot;&quot;, xlab = &quot;&quot;, hide.label = TRUE, cex.axis = 1.3, ylim = c(1000, 1800), rm.ranef = TRUE, add = TRUE) ## Summary: ## * ContVowInt.ord : factor; set to the value(s): Pharyngealised.a:. ## * Sex.ord : factor; set to the value(s): Female. ## * Interval : numeric predictor; with 30 values ranging from 1.000000 to 11.000000. ## * Speaker : factor; set to the value(s): SP01. (Might be canceled as random effect, check below.) ## * Word : factor; set to the value(s): 2aataa. (Might be canceled as random effect, check below.) ## * NOTE : The following random effects columns are canceled: s(Interval,Speaker),s(Interval,Speaker):ContVowInt.ordPlain.a:,s(Interval,Speaker):ContVowInt.ordPharyngealised.i:,s(Interval,Speaker):ContVowInt.ordPlain.i:,s(Interval,Speaker):ContVowInt.ordPharyngealised.u:,s(Interval,Speaker):ContVowInt.ordPlain.u:,s(Interval,Word),s(Interval,Word):Sex.ordMale ## ## Note: Selection of grouping predictors does not seem to appear in data. Rug of all data is being added. 4.6.5.3 /u:/ plot_smooth(mdl.gamm.F2.AR, view = &quot;Interval&quot;, cond = list(ContVowInt.ord = &quot;Plain.u:&quot;), col = &quot;blue&quot;, ylab = &quot;&quot;, xlab = &quot;&quot;, main = &quot;GAMM smooths in /u:/ &quot;, hide.label = TRUE, cex.axis = 1.3, ylim = c(700, 1500), rm.ranef = TRUE) ## Summary: ## * ContVowInt.ord : factor; set to the value(s): Plain.u:. ## * Sex.ord : factor; set to the value(s): Female. ## * Interval : numeric predictor; with 30 values ranging from 1.000000 to 11.000000. ## * Speaker : factor; set to the value(s): SP01. (Might be canceled as random effect, check below.) ## * Word : factor; set to the value(s): 2aataa. (Might be canceled as random effect, check below.) ## * NOTE : The following random effects columns are canceled: s(Interval,Speaker),s(Interval,Speaker):ContVowInt.ordPlain.a:,s(Interval,Speaker):ContVowInt.ordPharyngealised.i:,s(Interval,Speaker):ContVowInt.ordPlain.i:,s(Interval,Speaker):ContVowInt.ordPharyngealised.u:,s(Interval,Speaker):ContVowInt.ordPlain.u:,s(Interval,Word),s(Interval,Word):Sex.ordMale ## ## Note: Selection of grouping predictors does not seem to appear in data. Rug of all data is being added. plot_smooth(mdl.gamm.F2.AR, view = &quot;Interval&quot;, cond = list(ContVowInt.ord = &quot;Pharyngealised.u:&quot;), col = &quot;red&quot;, ylab = &quot;&quot;, xlab = &quot;&quot;, hide.label = TRUE, cex.axis = 1.3, ylim = c(700, 1500), rm.ranef = TRUE, add = TRUE) ## Summary: ## * ContVowInt.ord : factor; set to the value(s): Pharyngealised.u:. ## * Sex.ord : factor; set to the value(s): Female. ## * Interval : numeric predictor; with 30 values ranging from 1.000000 to 11.000000. ## * Speaker : factor; set to the value(s): SP01. (Might be canceled as random effect, check below.) ## * Word : factor; set to the value(s): 2aataa. (Might be canceled as random effect, check below.) ## * NOTE : The following random effects columns are canceled: s(Interval,Speaker),s(Interval,Speaker):ContVowInt.ordPlain.a:,s(Interval,Speaker):ContVowInt.ordPharyngealised.i:,s(Interval,Speaker):ContVowInt.ordPlain.i:,s(Interval,Speaker):ContVowInt.ordPharyngealised.u:,s(Interval,Speaker):ContVowInt.ordPlain.u:,s(Interval,Word),s(Interval,Word):Sex.ordMale ## ## Note: Selection of grouping predictors does not seem to appear in data. Rug of all data is being added. 4.6.6 Difference smooths 4.6.6.1 /i:/ plot_diff(mdl.gamm.F2.AR, view = &quot;Interval&quot;, comp = list(ContVowInt.ord = c(&quot;Pharyngealised.i:&quot;,&quot;Plain.i:&quot;)), xlab = &quot;&quot;, col = &#39;red&#39;, mark.diff = TRUE, col.diff = &quot;red&quot;, hide.label = TRUE, rm.ranef = TRUE) ## Summary: ## * Sex.ord : factor; set to the value(s): Female. ## * Interval : numeric predictor; with 100 values ranging from 1.000000 to 11.000000. ## * Speaker : factor; set to the value(s): SP01. (Might be canceled as random effect, check below.) ## * Word : factor; set to the value(s): 2aataa. (Might be canceled as random effect, check below.) ## * NOTE : The following random effects columns are canceled: s(Interval,Speaker),s(Interval,Speaker):ContVowInt.ordPlain.a:,s(Interval,Speaker):ContVowInt.ordPharyngealised.i:,s(Interval,Speaker):ContVowInt.ordPlain.i:,s(Interval,Speaker):ContVowInt.ordPharyngealised.u:,s(Interval,Speaker):ContVowInt.ordPlain.u:,s(Interval,Word),s(Interval,Word):Sex.ordMale ## ## ## Interval window(s) of significant difference(s): ## 1.000000 - 6.555556 4.6.6.2 /a:/ plot_diff(mdl.gamm.F2.AR, view = &quot;Interval&quot;, comp = list(ContVowInt.ord = c(&quot;Pharyngealised.a:&quot;,&quot;Plain.a:&quot;)), xlab = &quot;&quot;, col = &#39;red&#39;, mark.diff = TRUE, col.diff = &quot;red&quot;, hide.label = TRUE, rm.ranef = TRUE) ## Summary: ## * Sex.ord : factor; set to the value(s): Female. ## * Interval : numeric predictor; with 100 values ranging from 1.000000 to 11.000000. ## * Speaker : factor; set to the value(s): SP01. (Might be canceled as random effect, check below.) ## * Word : factor; set to the value(s): 2aataa. (Might be canceled as random effect, check below.) ## * NOTE : The following random effects columns are canceled: s(Interval,Speaker),s(Interval,Speaker):ContVowInt.ordPlain.a:,s(Interval,Speaker):ContVowInt.ordPharyngealised.i:,s(Interval,Speaker):ContVowInt.ordPlain.i:,s(Interval,Speaker):ContVowInt.ordPharyngealised.u:,s(Interval,Speaker):ContVowInt.ordPlain.u:,s(Interval,Word),s(Interval,Word):Sex.ordMale ## ## ## Interval window(s) of significant difference(s): ## 1.000000 - 11.000000 4.6.6.3 /u:/ plot_diff(mdl.gamm.F2.AR, view = &quot;Interval&quot;, comp = list(ContVowInt.ord = c(&quot;Pharyngealised.u:&quot;,&quot;Plain.u:&quot;)), xlab = &quot;&quot;, col = &#39;red&#39;, mark.diff = TRUE, col.diff = &quot;red&quot;, hide.label = TRUE, rm.ranef = TRUE) ## Summary: ## * Sex.ord : factor; set to the value(s): Female. ## * Interval : numeric predictor; with 100 values ranging from 1.000000 to 11.000000. ## * Speaker : factor; set to the value(s): SP01. (Might be canceled as random effect, check below.) ## * Word : factor; set to the value(s): 2aataa. (Might be canceled as random effect, check below.) ## * NOTE : The following random effects columns are canceled: s(Interval,Speaker),s(Interval,Speaker):ContVowInt.ordPlain.a:,s(Interval,Speaker):ContVowInt.ordPharyngealised.i:,s(Interval,Speaker):ContVowInt.ordPlain.i:,s(Interval,Speaker):ContVowInt.ordPharyngealised.u:,s(Interval,Speaker):ContVowInt.ordPlain.u:,s(Interval,Word),s(Interval,Word):Sex.ordMale ## ## ## Interval window(s) of significant difference(s): ## 1.000000 - 10.595960 "],["4.7-other-distibutions.html", "4.7 Other distibutions", " 4.7 Other distibutions The code above was using a Linear Mixed Effects Modelling. The outcome was a numeric object. We also used it in the case of Generalised Linear Models with a Binomial distribution and a Cumulative function. In some cases (as we have seen above), we may have: Count data (poisson), Multi-category outcome (multinomial) The code below gives you an idea of how to specify these models ### Poisson family ### lme4::glmer(outcome~predictor(s)+(1|subject)+(1|items)..., data=data, family=poisson) ### Multinomial family ### a bit complicated as there is a need to use Bayesian approaches, see e.g., ### glmmADMB ### mixcat ### MCMCglmm ### see https://gist.github.com/casallas/8263818 "],["4.8-session-info-2.html", "4.8 session info", " 4.8 session info sessionInfo() ## R version 4.4.2 (2024-10-31 ucrt) ## Platform: x86_64-w64-mingw32/x64 ## Running under: Windows 11 x64 (build 26100) ## ## Matrix products: default ## ## ## locale: ## [1] LC_COLLATE=English_United Kingdom.utf8 ## [2] LC_CTYPE=English_United Kingdom.utf8 ## [3] LC_MONETARY=English_United Kingdom.utf8 ## [4] LC_NUMERIC=C ## [5] LC_TIME=English_United Kingdom.utf8 ## ## time zone: Europe/Paris ## tzcode source: internal ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] faux_1.2.1.9002 car_3.1-3 carData_3.0-5 ## [4] lattice_0.22-6 paletteer_1.6.0 ggstatsplot_0.13.0 ## [7] ggstats_0.8.0 itsadug_2.4.1 plotfunctions_1.4 ## [10] mgcv_1.9-1 nlme_3.1-166 lme4_1.1-35.5 ## [13] Matrix_1.7-1 webshot_0.5.5 sjPlot_2.8.17 ## [16] DHARMa_0.4.7 ordinal_2023.12-4.1 psycho_0.6.1 ## [19] PresenceAbsence_1.1.11 ggsignif_0.6.4 emmeans_1.10.5 ## [22] corrplot_0.95 Hmisc_5.2-1 knitr_1.49 ## [25] broom_1.0.7 summarytools_1.0.1 phonR_1.0-7 ## [28] languageR_1.5.0 lubridate_1.9.4 forcats_1.0.0 ## [31] stringr_1.5.1 dplyr_1.1.4 purrr_1.0.2 ## [34] readr_2.1.5 tidyr_1.3.1 tibble_3.2.1 ## [37] ggplot2_3.5.1 tidyverse_2.0.0 ## ## loaded via a namespace (and not attached): ## [1] splines_4.4.2 prismatic_1.1.2 datawizard_1.0.0 ## [4] rpart_4.1.23 lifecycle_1.0.4 Rdpack_2.6.2 ## [7] tcltk_4.4.2 globals_0.16.3 processx_3.8.4 ## [10] vroom_1.6.5 MASS_7.3-61 insight_1.1.0 ## [13] backports_1.5.0 magrittr_2.0.3 sass_0.4.9 ## [16] rmarkdown_2.29 jquerylib_0.1.4 yaml_2.3.10 ## [19] gap_1.6 RColorBrewer_1.1-3 minqa_1.2.8 ## [22] multcomp_1.4-26 abind_1.4-8 nnet_7.3-19 ## [25] TH.data_1.1-2 sandwich_3.1-1 labelled_2.13.0 ## [28] ggrepel_0.9.6 listenv_0.9.1 correlation_0.8.6 ## [31] cards_0.4.0 performance_0.13.0 parallelly_1.40.1 ## [34] codetools_0.2-20 tidyselect_1.2.1 ggeffects_2.0.0 ## [37] farver_2.1.2 broom.mixed_0.2.9.6 effectsize_1.0.0 ## [40] matrixStats_1.4.1 base64enc_0.1-3 broom.helpers_1.17.0 ## [43] jsonlite_1.8.9 Formula_1.2-5 survival_3.7-0 ## [46] tools_4.4.2 pryr_0.1.6 Rcpp_1.0.14 ## [49] glue_1.8.0 gridExtra_2.3 xfun_0.49 ## [52] withr_3.0.2 numDeriv_2016.8-1.1 fastmap_1.2.0 ## [55] boot_1.3-31 fansi_1.0.6 callr_3.7.6 ## [58] digest_0.6.37 timechange_0.3.0 R6_2.5.1 ## [61] estimability_1.5.1 colorspace_2.1-1 utf8_1.2.4 ## [64] generics_0.1.3 data.table_1.16.4 htmlwidgets_1.6.4 ## [67] parameters_0.24.2 pkgconfig_2.0.3 gtable_0.3.6 ## [70] statsExpressions_1.6.2 furrr_0.3.1 htmltools_0.5.8.1 ## [73] bookdown_0.43 scales_1.3.0 rstudioapi_0.17.1 ## [76] tzdb_0.4.0 reshape2_1.4.4 coda_0.19-4.1 ## [79] checkmate_2.3.2 nloptr_2.1.1 cachem_1.1.0 ## [82] zoo_1.8-12 sjlabelled_1.2.0 parallel_4.4.2 ## [85] foreign_0.8-87 pillar_1.9.0 grid_4.4.2 ## [88] vctrs_0.6.5 ucminf_1.2.2 xtable_1.8-4 ## [91] cluster_2.1.6 htmlTable_2.4.3 evaluate_1.0.1 ## [94] zeallot_0.1.0 magick_2.8.5 mvtnorm_1.3-2 ## [97] cli_3.6.3 compiler_4.4.2 rlang_1.1.4 ## [100] crayon_1.5.3 rstantools_2.4.0 labeling_0.4.3 ## [103] rematch2_2.1.2 ps_1.8.1 plyr_1.8.9 ## [106] sjmisc_2.8.10 gap.datasets_0.0.6 stringi_1.8.4 ## [109] pander_0.6.5 munsell_0.5.1 bayestestR_0.15.2 ## [112] sjstats_0.19.0 rapportools_1.1 hms_1.1.3 ## [115] patchwork_1.3.0 bit64_4.5.2 future_1.34.0 ## [118] haven_2.5.4 rbibutils_2.3 RcppParallel_5.1.9 ## [121] bslib_0.8.0 bit_4.5.0.1 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
